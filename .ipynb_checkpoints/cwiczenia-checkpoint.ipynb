{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 1 \n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "Write a program which will find all such numbers which are divisible by 7 but are not a multiple of 5,\n",
    "between 2000 and 3200 (both included).\n",
    "The numbers obtained should be printed in a comma-separated sequence on a single line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002,2009,2016,2023,2037,2044,2051,2058,2072,2079,2086,2093,2107,2114,2121,2128,2142,2149,2156,2163,2177,2184,2191,2198,2212,2219,2226,2233,2247,2254,2261,2268,2282,2289,2296,2303,2317,2324,2331,2338,2352,2359,2366,2373,2387,2394,2401,2408,2422,2429,2436,2443,2457,2464,2471,2478,2492,2499,2506,2513,2527,2534,2541,2548,2562,2569,2576,2583,2597,2604,2611,2618,2632,2639,2646,2653,2667,2674,2681,2688,2702,2709,2716,2723,2737,2744,2751,2758,2772,2779,2786,2793,2807,2814,2821,2828,2842,2849,2856,2863,2877,2884,2891,2898,2912,2919,2926,2933,2947,2954,2961,2968,2982,2989,2996,3003,3017,3024,3031,3038,3052,3059,3066,3073,3087,3094,3101,3108,3122,3129,3136,3143,3157,3164,3171,3178,3192,3199\n",
      "Wall time: 191 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# beter use python list then np arrey to append\n",
    "import numpy as np\n",
    "numbers = []\n",
    "for i in range(2000,3201):\n",
    "    if np.mod(i,7) == 0:\n",
    "        if np.mod(i,5) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            numbers.append(str(i))\n",
    "print(','.join(numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 2 \n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "Write a program which can compute the factorial of a given numbers.\n",
    "The results should be printed in a comma-separated sequence on a single line.\n",
    "Suppose the following input is supplied to the program:\n",
    "8\n",
    "Then, the output should be:\n",
    "40320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "\n",
    "factorials = []\n",
    "def factorial_finder(input_number):\n",
    "    for factorial in range(0,input_number):\n",
    "        if np.mod(input_number, factorial) ==0:\n",
    "            factorials.append(str(factorial))\n",
    "    print(','.join(factorials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,1,2,4,5,10,20,25,50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tensorflow\\Miniconda3\\envs\\gpu\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in remainder\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "factorial_finder(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 3 \n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "With a given integral number n, write a program to generate a dictionary that contains (i, i*i) such that is an integral number between 1 and n (both included). and then the program should print the dictionary.\n",
    "Suppose the following input is supplied to the program:\n",
    "8\n",
    "Then, the output should be:\n",
    "{1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "\n",
    "numbers = dict()\n",
    "def number_dictionary(input_number):\n",
    "    for number in range(1,input_number+1):\n",
    "        numbers[number] = np.power(number, 2)\n",
    "    print(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64}\n"
     ]
    }
   ],
   "source": [
    "number_dictionary(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 6\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "Write a program that calculates and prints the value according to the given formula:\n",
    "\n",
    "Q = Square root of [(2 * C * D)/H]\n",
    "Following are the fixed values of C and H:\n",
    "C is 50. H is 30.\n",
    "D is the variable whose values should be input to your program in a comma-separated sequence.\n",
    "Example\n",
    "Let us assume the following comma separated input sequence is given to the program:\n",
    "\n",
    "100,150,180\n",
    "The output of the program should be:\n",
    "18,22,24\n",
    "\n",
    "Hints:\n",
    "If the output received is in decimal form, it should be rounded off to its nearest value (for example, if the output received is 26.0, it should be printed as 26)\n",
    "In case of input data being supplied to the question, it should be assumed to be a console input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "def cw6_fun(D):\n",
    "    # Q = Square root of [(2 * C * D)/H]\n",
    "    # C is 50. H is 30\n",
    "    numbers = []\n",
    "    D = D.split(\",\")\n",
    "    C = 50.\n",
    "    H = 30.\n",
    "    for d in D:\n",
    "        d = int(d)\n",
    "        q1 = np.multiply(2*C,d)\n",
    "        q2 = np.divide(q1,H)\n",
    "        Q = int(np.sqrt(q2))\n",
    "        numbers.append(str(Q))\n",
    "    print(','.join(numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18,22,24\n",
      "Wall time: 1e+03 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cw6_fun(\"100,150,180\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 7\n",
    "\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "Write a program which takes 2 digits, X,Y as input and generates a 2-dimensional array. The element value in the i-th row and j-th column of the array should be i*j.\n",
    "Note: i=0,1.., X-1; j=0,1,¡­Y-1.\n",
    "Example\n",
    "Suppose the following inputs are given to the program:\n",
    "3,5\n",
    "Then, the output of the program should be:\n",
    "[[0, 0, 0, 0, 0], [0, 1, 2, 3, 4], [0, 2, 4, 6, 8]] \n",
    "\n",
    "Hints:\n",
    "Note: In case of input data being supplied to the question, it should be assumed to be a console input in a comma-separated form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "def cw7(in_number):\n",
    "    # Q = Square root of [(2 * C * D)/H]\n",
    "    # C is 50. H is 30\n",
    "    table = []\n",
    "    in_number = in_number.split(\",\")\n",
    "    # number of rows\n",
    "    in_number[0] = int(in_number[0])\n",
    "    # number of columns\n",
    "    in_number[1] = int(in_number[1])\n",
    "    for num_row in range(0,in_number[0]):\n",
    "        tab_row = []\n",
    "        for num_col in range(0,in_number[1]):\n",
    "            tab_col = num_row * num_col\n",
    "            tab_row.append(tab_col)\n",
    "        table.append(tab_row)\n",
    "    print(table)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 0], [0, 1, 2, 3, 4], [0, 2, 4, 6, 8]]\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cw7(\"3,5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 8\n",
    "\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "Write a program that accepts a comma separated sequence of words as input and prints the words in a comma-separated sequence after sorting them alphabetically.\n",
    "Suppose the following input is supplied to the program:\n",
    "without,hello,bag,world\n",
    "Then, the output should be:\n",
    "bag,hello,without,world\n",
    "\n",
    "Hints:\n",
    "In case of input data being supplied to the question, it should be assumed to be a console input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "def cw8(words):\n",
    "    words=words.split(\",\")\n",
    "    words = sorted(words)\n",
    "    print(','.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dupa,huj,kurwa,pizda\n"
     ]
    }
   ],
   "source": [
    "cw8(\"dupa,kurwa,pizda,huj\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 9\n",
    "\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question\n",
    "Write a program that accepts sequence of lines as input and prints the lines after making all characters in the sentence capitalized.\n",
    "Suppose the following input is supplied to the program:\n",
    "Hello world\n",
    "Practice makes perfect\n",
    "Then, the output should be:\n",
    "HELLO WORLD\n",
    "PRACTICE MAKES PERFECT\n",
    "\n",
    "Hints:\n",
    "In case of input data being supplied to the question, it should be assumed to be a console input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "def cw9(words):\n",
    "    words_upper = []\n",
    "    words=words.split(\" \")\n",
    "    for word in words:\n",
    "        words_upper.append(word.upper())\n",
    "    print(' '.join(words_upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO WORLD PRACTICE MAKES PERFECT\n"
     ]
    }
   ],
   "source": [
    "cw9(\"Hello world Practice makes perfect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 10\n",
    "\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "Write a program that accepts a sequence of whitespace separated words as input and prints the words after removing all duplicate words and sorting them alphanumerically.\n",
    "Suppose the following input is supplied to the program:\n",
    "hello world and practice makes perfect and hello world again\n",
    "Then, the output should be:\n",
    "again and hello makes perfect practice world\n",
    "\n",
    "Hints:\n",
    "In case of input data being supplied to the question, it should be assumed to be a console input.\n",
    "We use set container to remove duplicated data automatically and then use sorted() to sort the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def cw10(words):\n",
    "    words=words.split(\" \")\n",
    "    uniq_words = Counter(words) \n",
    "    uniq_words = sorted(uniq_words)\n",
    "    print(' '.join(uniq_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "again and hello makes perfect practice world\n",
      "Wall time: 2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cw10(\"hello world and practice makes perfect and hello world again\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 11\n",
    "\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "Write a program which accepts a sequence of comma separated 4 digit binary numbers as its input and then check whether they are divisible by 5 or not. The numbers that are divisible by 5 are to be printed in a comma separated sequence.\n",
    "Example:\n",
    "0100,0011,1010,1001\n",
    "Then the output should be:\n",
    "1010\n",
    "Notes: Assume the data is input by console.\n",
    "\n",
    "Hints:\n",
    "In case of input data being supplied to the question, it should be assumed to be a console input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "def cw11(numbers):\n",
    "    numbers = numbers.split(\",\")\n",
    "    int_numbers = []\n",
    "    for number in numbers:\n",
    "        number = int(number, 2)\n",
    "        if number % 5 == 0:\n",
    "            int_numbers.append(str(number))\n",
    "    print(','.join(int_numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "cw11('0100,0011,1010,1001')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 12\n",
    "\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "Write a program, which will find all such numbers between 1000 and 3000 (both included) such that each digit of the number is an even number.\n",
    "The numbers obtained should be printed in a comma-separated sequence on a single line.\n",
    "\n",
    "Hints:\n",
    "In case of input data being supplied to the question, it should be assumed to be a console input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def cw12(numbers):\n",
    "    numbers = numbers.split(\",\")\n",
    "    if len(numbers) !=2:\n",
    "        print(\"huj dawaj 2 liczby stara kurwo\")\n",
    "        return\n",
    "    numbers[0] = int(numbers[0])\n",
    "    numbers[1] = int(numbers[1])\n",
    "    even_numbers = []\n",
    "    for number in range(numbers[0], numbers[1]+1):\n",
    "        if number % 2 == 0:\n",
    "            even_numbers.append(str(number))\n",
    "    print(','.join(even_numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30,32,34,36,38,40,42,44,46,48,50,52,54,56,58,60\n",
      "Wall time: 1e+03 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cw12(\"30,60\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 13\n",
    "\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "Write a program that accepts a sentence and calculate the number of letters and digits.\n",
    "Suppose the following input is supplied to the program:\n",
    "hello world! 123\n",
    "Then, the output should be:\n",
    "LETTERS 10\n",
    "DIGITS 3\n",
    "\n",
    "Hints:\n",
    "In case of input data being supplied to the question, it should be assumed to be a console input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def cw13(thing):\n",
    "    letters = 0\n",
    "    digits = 0\n",
    "    for mark in thing:\n",
    "        if not mark  is \" \":\n",
    "            if mark.isdigit():\n",
    "                digits += 1\n",
    "            else:\n",
    "                letters += 1\n",
    "    print(\"LETTERS\",letters, \"DIGITS\",digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LETTERS 7 DIGITS 4\n"
     ]
    }
   ],
   "source": [
    "cw13(\"dupa huj 1234\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 14\n",
    "\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "Write a program that accepts a sentence and calculate the number of upper case letters and lower case letters.\n",
    "Suppose the following input is supplied to the program:\n",
    "Hello world!\n",
    "Then, the output should be:\n",
    "UPPER CASE 1\n",
    "LOWER CASE 9\n",
    "\n",
    "Hints:\n",
    "In case of input data being supplied to the question, it should be assumed to be a console input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def cw14(words):\n",
    "    lower_case = 0\n",
    "    upper_case = 0\n",
    "    for letter in words:\n",
    "        if not letter is \" \":\n",
    "            if letter.islower():\n",
    "                lower_case += 1\n",
    "            else:\n",
    "                upper_case += 1\n",
    "    print(\"UPPER CASE \",upper_case,\"LOWER CASE\",lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPPER CASE  4 LOWER CASE 7\n"
     ]
    }
   ],
   "source": [
    "cw14(\"dupa huj DUPA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 15\n",
    "\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Question:\n",
    "Write a program that computes the value of a+aa+aaa+aaaa with a given digit as the value of a.\n",
    "Suppose the following input is supplied to the program:\n",
    "9\n",
    "Then, the output should be:\n",
    "11106\n",
    "\n",
    "Hints:\n",
    "In case of input data being supplied to the question, it should be assumed to be a console input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 16\n",
    "\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "Use a list comprehension to square each odd number in a list. The list is input by a sequence of comma-separated numbers.\n",
    "Suppose the following input is supplied to the program:\n",
    "1,2,3,4,5,6,7,8,9\n",
    "Then, the output should be:\n",
    "1,3,5,7,9\n",
    "\n",
    "Hints:\n",
    "In case of input data being supplied to the question, it should be assumed to be a console input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw16(numbers):\n",
    "    numbers = numbers.split(\",\")\n",
    "    odd =[]\n",
    "    for number in numbers:\n",
    "        number = int(number)\n",
    "        if number % 2 == 1:\n",
    "            odd.append(str(number))\n",
    "    print(','.join(odd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,3,5,7,9\n"
     ]
    }
   ],
   "source": [
    "cw16(\"1,2,3,4,5,6,7,8,9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 18\n",
    "\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "A website requires the users to input username and password to register. Write a program to check the validity of password input by users.\n",
    "Following are the criteria for checking the password:\n",
    "1. At least 1 letter between [a-z]\n",
    "2. At least 1 number between [0-9]\n",
    "1. At least 1 letter between [A-Z]\n",
    "3. At least 1 character from [$#@]\n",
    "4. Minimum length of transaction password: 6\n",
    "5. Maximum length of transaction password: 12\n",
    "Your program should accept a sequence of comma separated passwords and will check them according to the above criteria. Passwords that match the criteria are to be printed, each separated by a comma.\n",
    "Example\n",
    "If the following passwords are given as input to the program:\n",
    "ABd1234@1,a F1#,2w3E*,2We3345\n",
    "Then, the output of the program should be:\n",
    "ABd1234@1\n",
    "\n",
    "Hints:\n",
    "In case of input data being supplied to the question, it should be assumed to be a console input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw18(passwords):\n",
    "    passwords = passwords.split(\",\")\n",
    "    good_passwords = []\n",
    "    for password in passwords:\n",
    "        # At least 1 letter between [a-z]\n",
    "        low_case_latter = False\n",
    "        for letter in password:\n",
    "            if letter.islower():\n",
    "                low_case_latter = True\n",
    "        # At least 1 number between [0-9]\n",
    "        number = False\n",
    "        for letter in password:\n",
    "            if letter.isdigit():\n",
    "                number = True\n",
    "        # At least 1 letter between [A-Z]\n",
    "        uper_case_latter = False\n",
    "        for letter in password:\n",
    "            if letter.isupper():\n",
    "                uper_case_latter = True\n",
    "        # At least 1 character from [$#@]\n",
    "        special_latter = False\n",
    "        for letter in password:\n",
    "            if letter is '$' or letter is '#' or letter is '@':\n",
    "                special_latter = True\n",
    "        # Minimum length of transaction password: 6\n",
    "        min_len_word = False\n",
    "        if len(password) > 6:\n",
    "            min_len_word = True\n",
    "        # Maximum length of transaction password: 12\n",
    "        max_len_word = False\n",
    "        if len(password) < 12:\n",
    "            max_len_word = True\n",
    "        # we check all condition\n",
    "        if low_case_latter and number and uper_case_latter and special_latter and min_len_word and max_len_word:\n",
    "            good_passwords.append(password)\n",
    "    print(good_passwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ABd1234@1']\n"
     ]
    }
   ],
   "source": [
    "cw18(\"ABd1234@1,a F1#,2w3E*,2We3345\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 19\n",
    "\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Question:\n",
    "You are required to write a program to sort the (name, age, height) tuples by ascending order where name is string, age and height are numbers. The tuples are input by console. The sort criteria is:\n",
    "1: Sort based on name;\n",
    "2: Then sort based on age;\n",
    "3: Then sort by score.\n",
    "The priority is that name > age > score.\n",
    "If the following tuples are given as input to the program:\n",
    "Tom,19,80\n",
    "John,20,90\n",
    "Jony,17,91\n",
    "Jony,17,93\n",
    "Json,21,85\n",
    "Then, the output of the program should be:\n",
    "[('John', '20', '90'), ('Jony', '17', '91'), ('Jony', '17', '93'), ('Json', '21', '85'), ('Tom', '19', '80')]\n",
    "\n",
    "Hints:\n",
    "In case of input data being supplied to the question, it should be assumed to be a console input.\n",
    "We use itemgetter to enable multiple sort keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "peoples = []\n",
    "def cw19(people):\n",
    "    people = people.split(\",\")\n",
    "    peoples.append(people)\n",
    "    peoples_sorted =[]\n",
    "    peoples_sorted = sorted(peoples, key=itemgetter(0,1,2))\n",
    "    print(peoples_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Tom', '19', '80']]\n",
      "[['John', '20', '90'], ['Tom', '19', '80']]\n",
      "[['John', '20', '90'], ['Jony', '17', '91'], ['Tom', '19', '80']]\n",
      "[['John', '20', '90'], ['Jony', '17', '91'], ['Jony', '17', '93'], ['Tom', '19', '80']]\n",
      "[['John', '20', '90'], ['Jony', '17', '91'], ['Jony', '17', '93'], ['Json', '21', '85'], ['Tom', '19', '80']]\n"
     ]
    }
   ],
   "source": [
    "cw19(\"Tom,19,80\")\n",
    "cw19(\"John,20,90\")\n",
    "cw19(\"Jony,17,91\")\n",
    "cw19(\"Jony,17,93\")\n",
    "cw19(\"Json,21,85\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  cw 20\n",
    "\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "Define a class with a generator which can iterate the numbers, which are divisible by 7, between a given range 0 and n.\n",
    "\n",
    "Hints:\n",
    "Consider use yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw20(number):\n",
    "    my_list = range(0,number)\n",
    "    for num in my_list:\n",
    "        if num % 7 == 0:\n",
    "            yield num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object cw20 at 0x00000000050B84C0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw20(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  cw 21\n",
    "\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question\n",
    "A robot moves in a plane starting from the original point (0,0). The robot can move toward UP, DOWN, LEFT and RIGHT with a given steps. The trace of robot movement is shown as the following:\n",
    "UP 5\n",
    "DOWN 3\n",
    "LEFT 3\n",
    "RIGHT 2\n",
    "¡­\n",
    "The numbers after the direction are steps. Please write a program to compute the distance from current position after a sequence of movement and original point. If the distance is a float, then just print the nearest integer.\n",
    "Example:\n",
    "If the following tuples are given as input to the program:\n",
    "UP 5\n",
    "DOWN 3\n",
    "LEFT 3\n",
    "RIGHT 2\n",
    "Then, the output of the program should be:\n",
    "2\n",
    "\n",
    "Hints:\n",
    "In case of input data being supplied to the question, it should be assumed to be a console input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "position_memory = []\n",
    "def cw21(move):\n",
    "    # we make move\n",
    "    pos = [0,0]\n",
    "    move = move.split(\" \")\n",
    "    # we dicide about move\n",
    "    if move[0] == 'UP':\n",
    "        pos[0] += int(move[1])\n",
    "    if move[0] == 'DOWN':\n",
    "        pos[0] -= int(move[1])\n",
    "    if move[0] == 'RIGHT':\n",
    "        pos[1] += int(move[1])\n",
    "    if move[0] == 'LEFT':\n",
    "        pos[1] -= int(move[1])\n",
    "    # we append move to memory\n",
    "    position_memory.append(pos)\n",
    "    # we make stored moves\n",
    "    position = [0,0]\n",
    "    for positions in position_memory:\n",
    "        position[0] += positions[0]\n",
    "        position[1] += positions[1]\n",
    "    print(\"position: \",position)\n",
    "    # now we calculate how far we go, info:\n",
    "    # http://matematyka.pisz.pl/strona/1248.html\n",
    "    # 2d : d = sqer([(x2-x1)^2]+[(y2-y1)^2])\n",
    "    start_pos = [0,0]\n",
    "    d = math.sqrt(((position[0]-start_pos[0])**2)+((position[1]-start_pos[1])**2))\n",
    "    print(\"How far we go: \",d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position:  [0, -10]\n",
      "How far we go:  10.0\n"
     ]
    }
   ],
   "source": [
    "cw21(\"LEFT 10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "Write a program to compute the frequency of the words from the input. The output should output after sorting the key alphanumerically. \n",
    "Suppose the following input is supplied to the program:\n",
    "New to Python or choosing between Python 2 and Python 3? Read Python 2 or Python 3.\n",
    "Then, the output should be:\n",
    "\n",
    "2:2\n",
    "3.:1\n",
    "3?:1\n",
    "New:1\n",
    "Python:5\n",
    "Read:1\n",
    "and:1\n",
    "between:1\n",
    "choosing:1\n",
    "or:2\n",
    "to:1\n",
    "\n",
    "Hints\n",
    "In case of input data being supplied to the question, it should be assumed to be a console input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw22(words):\n",
    "    words = words.split(\" \")\n",
    "    output = {}\n",
    "    for word in words:\n",
    "        output[word] = output.get(word,0)+1\n",
    "    words = output.keys()\n",
    "    words= sorted(words)\n",
    "    for word in words:\n",
    "        print(\"%s:%d\" % (word,output[word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2:2\n",
      "3:1\n",
      "3?:1\n",
      "New:1\n",
      "Python:5\n",
      "Read:1\n",
      "and:1\n",
      "between:1\n",
      "choosing:1\n",
      "or:2\n",
      "to:1\n"
     ]
    }
   ],
   "source": [
    "cw22(\"New to Python or choosing between Python 2 and Python 3? Read Python 2 or Python 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 16\n",
    "\n",
    "\n",
    "from https://www.practicepython.org/exercise/2014/05/28/16-password-generator.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a password generator in Python. Be creative with how you generate passwords - strong passwords have a mix of lowercase letters, uppercase letters, numbers, and symbols. The passwords should be random, generating a new password every time the user asks for a new password. Include your run-time code in a main method.\n",
    "\n",
    "Extra:\n",
    "\n",
    "    Ask the user how strong they want their password to be. For weak passwords, pick a word or two from a list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def password_generator(number_of_digits, how_strong_password):\n",
    "    import random\n",
    "    import string\n",
    "    password = []\n",
    "    if how_strong_password == \"weak\":\n",
    "        number_of_digits = int(number_of_digits)\n",
    "        password = random.choices(string.ascii_lowercase, k=number_of_digits)\n",
    "        password = ''.join(password)\n",
    "        return password\n",
    "        print(password)\n",
    "    if how_strong_password == \"mid\":\n",
    "        number_of_digits = int(number_of_digits)\n",
    "        password = random.choices(string.digits + string.ascii_lowercase, k=number_of_digits)\n",
    "        password = ''.join(password)\n",
    "        return password\n",
    "        print(password)\n",
    "    if how_strong_password == \"strong\":\n",
    "        number_of_digits = int(number_of_digits)\n",
    "        password = random.choices(string.ascii_uppercase + string.digits + string.ascii_lowercase, k=number_of_digits)\n",
    "        password = ''.join(password)\n",
    "        return password\n",
    "        print(password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KcALSWn1zHAtI9vsQAzCmQCRC'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "password_generator(25,\"strong\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 17\n",
    "\n",
    "from https://www.practicepython.org/exercise/2014/05/28/16-password-generator.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the BeautifulSoup and requests Python packages to print out a list of all the article titles on the New York Times homepage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title_new_york(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    req_for_title = requests.get(url)\n",
    "    req_for_title_html = req_for_title.text\n",
    "    soup = BeautifulSoup(req_for_title_html, \"html5lib\")\n",
    "    output_titles = []\n",
    "    titles = soup.findAll('h2', attrs={'class' : 'story-heading'})\n",
    "    for title in titles:\n",
    "        title = title.text.strip() \n",
    "        output_titles.append(title)\n",
    "    print(output_titles)\n",
    "    return output_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_title_new_york(\"https://www.nytimes.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 18\n",
    "\n",
    "from https://www.practicepython.org/exercise/2014/05/28/16-password-generator.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a program that will play the “cows and bulls” game with the user. The game works like this:\n",
    "\n",
    "Randomly generate a 4-digit number. Ask the user to guess a 4-digit number. For every digit that the user guessed correctly in the correct place, they have a “cow”. For every digit the user guessed correctly in the wrong place is a “bull.” Every time the user makes a guess, tell them how many “cows” and “bulls” they have. Once the user guesses the correct number, the game is over. Keep track of the number of guesses the user makes throughout teh game and tell the user at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cw18():\n",
    "    def __init__(self):\n",
    "        import random\n",
    "        import string\n",
    "        self.password = random.choices(string.digits, k=4)\n",
    "        self.attempts = 0\n",
    "    def check_num(self, user_number):\n",
    "        self.attempts += 1\n",
    "        user_number = str(user_number)\n",
    "        user_number = list(user_number)\n",
    "        if len(user_number) != 4:\n",
    "            return \"del liczbe z 4 cyframi\"\n",
    "        num_cows = 0\n",
    "        num_bulls = 0\n",
    "        if self.password == user_number:\n",
    "            print(\"win w: \", self.attempts)\n",
    "            return \n",
    "        # we itarate over user_number\n",
    "        for digit_user_number in user_number:\n",
    "            # we itarate over password\n",
    "            for digit_password in self.password:\n",
    "                if digit_user_number == digit_password:\n",
    "                    num_cows += 1  \n",
    "        num_bulls = 4 - num_cows\n",
    "        print(\"attempts: \",self.attempts)\n",
    "        print(\"password: \",self.password)          \n",
    "        print(\"num_cows: \",num_cows)\n",
    "        print(\"num_bulls: \",num_bulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cw18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempts:  1\n",
      "password:  ['2', '9', '0', '2']\n",
      "num_cows:  2\n",
      "num_bulls:  2\n"
     ]
    }
   ],
   "source": [
    "x.check_num(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 19\n",
    "https://www.practicepython.org/exercise/2014/07/14/19-decode-a-web-page-two.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the requests and BeautifulSoup Python libraries, print to the screen the full text of the article on this website: http://www.vanityfair.com/society/2014/06/monica-lewinsky-humiliation-culture.\n",
    "\n",
    "The article is long, so it is split up between 4 pages. Your task is to print out the text to the screen so that you can read the full article without having to click any buttons.\n",
    "\n",
    "(Hint: The post here describes in detail how to use the BeautifulSoup and requests libraries through the solution of the exercise posted here.)\n",
    "\n",
    "This will just print the full text of the article to the screen. It will not make it easy to read, so next exercise we will learn how to write this text to a .txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw19(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    req_for_title = requests.get(url)\n",
    "    req_for_title_html = req_for_title.text\n",
    "    soup = BeautifulSoup(req_for_title_html, \"html5lib\")\n",
    "    texts = soup.findAll('p')\n",
    "    output_text = []\n",
    "    for text in texts:\n",
    "        text = text.text.strip()\n",
    "        output_text.append(text)\n",
    "    print(output_text)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cw19(\"https://www.vanityfair.com/style/society/2014/06/monica-lewinsky-humiliation-culture\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 20\n",
    "https://www.practicepython.org/exercise/2014/11/11/20-element-search.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that takes an ordered list of numbers (a list where the elements are in order from smallest to largest) and another number. The function decides whether or not the given number is inside the list and returns (then prints) an appropriate boolean.\n",
    "\n",
    "Extras:\n",
    "\n",
    "    Use binary search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw20(num_list, num):\n",
    "    bol_value = num_list[0] < num and num_list[len(num_list)-1] > num\n",
    "    print(\"inside: \", bol_value)\n",
    "# ndont work\n",
    "def binary_search(num_list, num):\n",
    "    len_list = len(num_list)\n",
    "    left_side = 0\n",
    "    right_side = len_list - 1\n",
    "    while left_side <= right_side:\n",
    "        m = (left_side+right_side)/2\n",
    "        if num_list[m] < num:\n",
    "            left_side = m + 1\n",
    "        elif num_list[m] > num:\n",
    "            left_side = m - 1\n",
    "        else:\n",
    "            return m\n",
    "    return unsuccessful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside:  False\n"
     ]
    }
   ],
   "source": [
    "cw20([1, 3, 5, 30, 42, 43, 500],0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 21\n",
    "\n",
    "https://www.practicepython.org/exercise/2014/11/30/21-write-to-a-file.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the code from the How To Decode A Website exercise (if you didn’t do it or just want to play with some different code, use the code from the solution), and instead of printing the results to a screen, write the results to a txt file. In your code, just make up a name for the file you are saving to.\n",
    "\n",
    "Extras:\n",
    "\n",
    "    Ask the user to specify the name of the output file that will be saved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw21(file_name):\n",
    "    text = cw19(\"https://www.vanityfair.com/style/society/2014/06/monica-lewinsky-humiliation-culture\")\n",
    "    text = str(' '.join(text))\n",
    "    print(text)\n",
    "    with open(file_name, 'w', encoding='utf-8') as open_file:\n",
    "        open_file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['‘How does it feel to be America’s premier blow-job queen?”', 'It was early 2001. I was sitting on the stage of New York’s Cooper Union in the middle of taping a Q&A for an HBO documentary. I was the subject. And I was thunderstruck.', 'Hundreds of people in the audience, mostly students, were staring at me, many with their mouths agape, wondering if I would dare to answer this question.', 'The main reason I had agreed to participate in the program was not to rehash or revise the story line of Interngate but to try to shift the focus to meaningful issues. Many troubling political and judicial questions had been brought to light by the investigation and impeachment of President Bill Clinton. But the most egregious had been generally ignored. People seemed indifferent to the deeper matters at hand, such as the erosion of private life in the public sphere, the balance of power and gender inequality in politics and media, and the erosion of legal protections to ensure that neither a parent nor a child should ever have to testify against each other.', 'How naïve I was.', 'There were gasps and sputters from the audience. Numerous blurred, faceless people called out, “Don’t answer it!”', '“It’s hurtful and it’s insulting,” I said, attempting to gather my wits. “And as insulting as it is to me, it’s even more insulting to my family. I don’t actually know why this whole story became about oral sex. I don’t. It was a mutual relationship.… The fact that it did is maybe a result of a male-dominated society.”', 'The audience laughed. Maybe they were surprised to hear these words coming from me.', 'I looked straight at the smirking guy who had asked the question. “You might be better poised to answer that.” After a pause, I added, “That’s probably cost me another year of therapy.”', 'You could argue that in agreeing to participate in an HBO documentary called Monica in Black and White I had signed up to be shamed and publicly humiliated yet again. You might even think I would have been inured to humiliation. This encounter at Cooper Union, after all, paled in comparison with the 445-page Starr Report, which was the culmination of independent counsel Kenneth Starr’s four-year investigation of the Clinton White House. It included chapter and verse about my intimate sexual activities, along with transcripts of audiotapes that chronicled many of my private conversations. But the “B.J. Queen” question—which was included in the show when it aired on HBO in 2002—sat with me for a long time after the audience left and the taping wrapped.', 'True, this wasn’t the first time I’d been stigmatized for my affair with Bill Clinton. But never had I been so directly confronted, one-on-one, with such a crass characterization. One of the unintended consequences of my agreeing to put myself out there and to try to tell the truth had been that shame would once again be hung around my neck like a scarlet-A albatross. Believe me, once it’s on, it is a bitch to take off.', 'Had that awkward moment at Cooper Union aired only a few years later, with the advent of social media, the humiliation would have been even more devastating. That clip would have gone viral on Twitter, YouTube, Facebook, TMZ, Gawker. It would have become a meme of its own on Tumblr. The viralness itself would have merited mention on the Daily Beast and Huffington Post. As it was, it was viral enough, and, thanks to the all-encompassing nature of the Web, you can, 12 years later, watch it all day long on YouTube if you want to (but I really hope you have better things to do with your time).', 'I know I’m not alone when it comes to public humiliation. No one, it seems, can escape the unforgiving gaze of the Internet, where gossip, half-truths, and lies take root and fester. We have created, to borrow a term from historian Nicolaus Mills, a “culture of humiliation” that not only encourages and revels in Schadenfreude but also rewards those who humiliate others, from the ranks of the paparazzi to the gossip bloggers, the late-night comedians, and the Web “entrepreneurs” who profit from clandestine videos.', 'Yes, we’re all connected now. We can tweet a revolution in the streets or chronicle achievements large and small. But we’re also caught in a feedback loop of defame and shame, one in which we have become both perps and victims. We may not have become a crueler society—although it sure feels as if we have—but the Internet has seismically shifted the tone of our interactions. The ease, the speed, and the distance that our electronic devices afford us can also make us colder, more glib, and less concerned about the consequences of our pranks and prejudice. Having lived humiliation in the most intimate possible way, I marvel at how willingly we have all signed on to this new way of being.', 'In my own case, each easy click of that YouTube link reinforces the archetype, despite my efforts to parry it away: Me, America’s B.J. Queen. That Intern. That Vixen. Or, in the inescapable phrase of our 42nd president, “That Woman.”', 'It may surprise you to learn that I’m actually a person.', 'In 1998, when news of my affair with Bill Clinton broke, I was arguably the most humiliated person in the world. Thanks to the Drudge Report, I was also possibly the first person whose global humiliation was driven by the Internet.', 'For several years I tried my hand in the fashion-accessory business and became involved in various media projects, including the HBO documentary. Then I lay low for the most part. (The last major interview I granted was 10 years ago.) After all, not lying low had exposed me to criticism for trying to “capitalize” on my “notoriety.” Apparently, others talking about me is O.K.; me speaking out for myself is not. I turned down offers that would have earned me more than $10 million, because they didn’t feel like the right thing to do. Over time, the media circus quieted down, but it never quite moved on, even as I attempted to move on.', 'Meanwhile, I watched my friends’ lives move forward. Marriages. Kids. Degrees. (Second marriages. More kids. More degrees.) I decided to turn over a new leaf and attend grad school.', 'I moved to England to study, to challenge myself, to escape scrutiny, and to reimagine my identity. My professors and fellow students at the London School of Economics were wonderful—welcoming and respectful. I had more anonymity in London, perhaps due to the fact that I spent most of my waking hours in class or buried in the library. In 2006, I graduated with a master’s in social psychology. My master’s thesis examined social bias in the courtroom and was titled “In Search of the Impartial Juror: An Exploration of Pretrial Publicity and the Third Person Effect.” I liked to joke that I was trading the blue dress for blue stockings, and the degree provided new scaffolding to hang my life experiences on. It would also prove, so I hoped, to be a gateway to a more normal life.', 'I moved between London, Los Angeles, New York, and Portland, Oregon, interviewing for a variety of jobs that fell under the umbrella of “creative communication” and “branding,” with an emphasis on charity campaigns. Yet, because of what potential employers so tactfully referred to as my “history,” I was never “quite right” for the position. In some cases, I was right for all the wrong reasons, as in “Of course, your job would require you to attend our events.” And, of course, these would be events at which press would be in attendance.', 'In one promising job interview that took place during the run-up to the 2008 primary season, the conversation took an interesting turn. “So here’s the thing, Monica,” the interviewer said. “You’re clearly a bright young woman and affable, but for us—and probably any other organization that relies on grants and other government funding—it’s risky. We would first need a Letter of Indemnification from the Clintons. After all, there is a 25 percent chance that Mrs. Clinton will be the next president.” I gave a fake smile and said, “I understand.”', 'Another job interview, this one typical: walked into the stark, terminally cool reception area of a hip-yet-prestigious advertising agency in Los Angeles, my hometown. As always, I put on my best “I’m friendly, not a diva” smile. “Hi. Monica Lewinsky here to see So-and-So.”', 'The twentysomething receptionist pushed her black-rimmed hipster frames up her nose. “Monica who?”', 'Before I could answer, another twentysomething, in skinny jeans, plaid shirt, and bow tie, rushed over and interrupted: “ Ms. Lewinsky.” Like a maître d’, he continued, “Pleasure to have you here. I’ll let So-and-So know you’ve arrived. Soy latte? Green tea? Filtered water?”', 'I found myself sitting at a small round table, face-to-face with So-and-So, the agency’s head of strategy and planning. We talked. She kept wincing. This was not going well. I tried to keep myself from getting flustered. Now she was not only wincing but also clearing her throat. Was that perspiration on her brow? It hit me: she was nervous, in full-tic mode.', 'I’ve had to become adept at handling any number of reactions in social situations and job interviews. I get it: it must be disconcerting to sit across from “That Woman.” Needless to say, I didn’t get the position.', 'I eventually came to realize that traditional employment might not be an option for me. I’ve managed to get by (barely, at times) with my own projects, usually with start-ups that I have participated in, or with loans from friends and family.', 'In another job interview I was asked, “If you were a brand, which brand would you be?” Let me tell you, when you’re Monica Lewinsky, that is one loaded question.', 'In September of 2010, the culmination of these experiences began to snap into a broader context for me. A phone conversation with my mother shifted the lens through which I viewed my world. We were discussing the tragic death of Tyler Clementi. Tyler, you will recall, was an 18-year-old Rutgers freshman who was secretly streamed via Webcam kissing another man. Days later, after being derided and humiliated on social media, he committed suicide by jumping off the George Washington Bridge.', 'My mom wept. Sobbing, she kept repeating over and over, “How his parents must feel … his poor parents.”', 'It was an unbearably tragic event, and while hearing of it brought me to tears, too, I couldn’t quite grasp why my mom was so distraught. And then it dawned on me: she was reliving 1998, when she wouldn’t let me out of her sight. She was replaying those weeks when she stayed by my bed, night after night, because I, too, was suicidal. The shame, the scorn, and the fear that had been thrown at her daughter left her afraid that I would take my own life—a fear that I would be literally humiliated to death. (I have never actually attempted suicide, but I had strong suicidal temptations several times during the investigations and during one or two periods after.)', 'I would never be so presumptuous as to equate my own story with Tyler Clementi’s. After all, my public humiliation had been the result of my involvement with a world-renowned public figure—that is, a consequence of my own poor choices. But in that moment, when I felt the depths of my mother’s anguish, I wished I could have had a chance to have spoken to Tyler about how my love life, my sex life, my most private moments, my most sensitive secrets, had been broadcast around the globe. I wished I had been able to say to him that I knew a little of how it might have felt for him to be exposed before the world. And, as hard as it is to imagine surviving it, it is possible.', 'In the wake of Tyler’s tragedy, my own suffering took on a different meaning. Perhaps by sharing my story, I reasoned, I might be able to help others in their darkest moments of humiliation. The question became: How do I find and give a purpose to my past? It was my Prufrockian moment: “Do I dare / Disturb the universe?” Or, in my case, the Clinton universe.', 'Despite a decade of self-imposed silence, I have been periodically resuscitated as part of the national conversation, almost always in connection with the Clintons. For instance, in January and February of this year, Rand Paul, the Kentucky senator and a possible 2016 Republican presidential aspirant, managed to drag me into the pre-election muck. He fought back against the Democrats’ charges of a G.O.P. “war on women” by arguing that Bill Clinton had committed workplace “violence” and acted in a “predatory” manner against “a 20-year-old girl who was there from college.”', 'Sure, my boss took advantage of me, but I will always remain firm on this point: it was a consensual relationship. Any “abuse” came in the aftermath, when I was made a scapegoat in order to protect his powerful position.', 'So, trying to disappear has not kept me out of the fray. I am, for better or for worse, presumed to be a known quantity. Every day I am recognized. Every day. Sometimes a person will walk past me again and again, as if I wouldn’t notice. (Thankfully, 99.9 percent of the time when strangers do say something to me they are supportive and respectful.) Every day someone mentions me in a tweet or a blog post, and not altogether kindly. Every day, it seems, my name shows up in an op-ed column or a press clip or two—mentioned in passing in articles on subjects as disparate as millennials, Scandal, and French president François Hollande’s love life. Miley Cyrus references me in her twerking stage act, Eminem raps about me, and Beyoncé’s latest hit gives me a shout-out. Thanks, Beyoncé, but if we’re verbing, I think you meant “Bill Clinton’d all on my gown,” not “Monica Lewinsky’d.”', 'With every man I date (yes, I date!), I go through some degree of 1998 whiplash. I need to be extremely circumspect about what it means to be “public” with someone. In the early years post-impeachment, I once left a front-row seat along the third-base line at a Yankees game when I learned that my date—a guy whose company I thoroughly enjoyed—was actually in another relationship. It was only a green-card marriage, but I freaked that we could be photographed together and someone might call the gossip rags. I’ve become adept at figuring out when men are interested in me for the wrong reason. Thankfully, those have been few and far between. But every man that has been special to me over the past 16 years has helped me find another piece of myself—the self that was shattered in 1998. And so, no matter the heartbreak, tears, or disenchantment, I’ll always be grateful to them.', 'In February of this year, around the same time Senator Paul put me back into the unwanted spotlight, I became the “narcissistic loony toon,” the latest twist on Me as Archetype.', 'A snapshot of a scenario I’ve grown all too accustomed to, even as I attempt to move on with my life: A shrill ring interrupts the rhythms of my day. The call—from the doorman of the apartment building where I’m staying in New York—leads me to an exasperated “What? Again?” They’ve reappeared: the paparazzi, like swallows, have returned to the sidewalk outside, pacing and circling and pacing some more.', 'I hit the computer. Time for a little self-Google. (Oh, dear reader, please do not judge.) My heart sinks. There’s an explosion on Google News. I know what this means. Whatever day I’ve planned has been jettisoned. To leave the house—and risk a photo—only ensures that the story will stay alive.', 'The cameras have returned because of the headlines: a conservative Web site has gone poking around the University of Arkansas archive of one of Hillary Clinton’s closest friends and admirers, Diane Blair, and has unearthed a cache of memos from the 1990s. In some of them, Blair, who died in 2000, quotes the former First Lady about her husband’s relationship with me. Though Hillary, according to Blair’s notes, claimed to find her husband’s “lapse” inexcusable, she praised him for trying to “manage someone who was clearly a ‘narcissistic loony toon.’ ”', 'My first thought, as I was getting up to speed: If that’s the worst thing she said, I should be so lucky. Mrs. Clinton, I read, had supposedly confided to Blair that, in part, she blamed herself for her husband’s affair (by being emotionally neglectful) and seemed to forgive him. Although she regarded Bill as having engaged in “gross inappropriate behavior,” the affair was, nonetheless, “consensual (was not a power relationship).”', 'I field the usual calls from friends who lend moral support whenever these volcanic media stories erupt. They diffuse the tension with good-natured teasing: “So, are we changing your monogram to NLT?” I try to ignore the former First Lady’s long-buried comments. Given my experiences with Linda Tripp, I know better than anyone what it’s like to have a conversation with a girlfriend exposed and scrutinized, taken out of context. But, even so, it begins to gnaw at me. I realize that Hillary Clinton was—unlike me when Tripp was prying loose my innermost secrets and insecurities and recording them surreptitiously—fully aware of this documentation: she’s the one who, according to the memos, asked Blair to keep a record or diary of their discussions for archival purposes.', 'Yes, I get it. Hillary Clinton wanted it on record that she was lashing out at her husband’s mistress. She may have faulted her husband for being inappropriate, but I find her impulse to blame the Woman—not only me, but herself—troubling. And all too familiar: with every marital indiscretion that finds its way into the public sphere—many of which involve male politicians—it always seems like the woman conveniently takes the fall. Sure, the Anthony Weiners and Eliot Spitzers do what they need to do to look humiliated on cable news. They bow out of public life for a while, but they inevitably return, having put it all behind them. The women in these imbroglios return to lives that are not so easily repaired.', 'But there is another layer here that is making me bristle: Narcissist? Loony?', 'You might remember that just five days before the world had ever heard my name the F.B.I.—after my friend Linda Tripp approached Special Prosecutor Kenneth Starr’s office with information about my affair with the president—entrapped me in a terrifying “sting” in the Pentagon City mall. At age 24, cornered in a hotel room on January 16, 1998, with mainly male interrogators taking orders from Starr, I was discouraged from contacting my attorney and threatened with 27 years in jail for filing an affidavit denying the affair with Clinton, among other alleged crimes. I was offered immunity from that threat if I agreed to place monitored calls and wear a wire in conversations with two of the president’s confidants and possibly the president himself. I refused. Confiding in Linda Tripp turned into an unintended betrayal. But this? The mother of all betrayals. That, I couldn’t do. Courageous or foolish, maybe, but narcissistic and loony?', 'These 16-year-old descriptions of me triggered memories of past anguish, particularly in the area of women lobbing derision at one another. So where, you might be wondering, were the feminists back then?', 'It’s a question that troubles me to this day.', 'I sorely wished for some sign of understanding from the feminist camp. Some good, old-fashioned, girl-on-girl support was much in need. None came. Given the issues at play—gender politics, sex in the workplace—you’d think they would have spoken up. They didn’t. I understood their dilemma: Bill Clinton had been a president “friendly” to women’s causes.', 'It also didn’t help that my case was not one of conventional “sexual harassment”; that charge against Bill Clinton had been made by Paula Jones, who brought a colossal lawsuit against him. My name surfaced only because, thanks to newly won advances by feminists, investigations of such cases were now allowed to cast a wider net. The Jones case became a stick that the right wing used to strike back at the Clinton-supporting feminists: Why wouldn’t they enthusiastically support an investigation into a case of sexual harassment? What if the president had been a Republican? Charges of hypocrisy flew.', 'A handful of representatives of the modern feminist movement did chime in, obliquely. Yet, instead of any meaningful engagement, we got this: January 30, 1998. Day Nine of the scandal. Cocktails at Le Bernardin, in Manhattan. In attendance: writers Erica Jong, Nancy Friday, Katie Roiphe, and Elizabeth Benedict; Saturday Night Live writer Patricia Marx; Marisa Bowe, the editor of Word, an online magazine; fashion designer Nicole Miller; former dominatrix Susan Shellogg; and their host, Le Bernardin co-owner Maguy Le Coze. The New York Observer brought this coven together to trade Interngate insights, to be recorded by Francine Prose. (Sadly, the gal who would really make this coven complete is missing: Maureen Dowd, or Moremean Dowdy, as I used to refer to her. Today, I’d meet her for a drink.)', 'Oh, to have been at that cocktail party:', 'Marisa Bowe: His whole life is about having to be in control and really intelligent all the time. And his wife is really intelligent and in control all the time. And the idea of just having stupid sex with some not-brilliant woman in the Oval Office, I can see the appeal in that.', 'Imaginary Me: I’m not saying I’m brilliant, but how do you know I’m not? My first job out of college was at the White House.', 'Susan Shellogg: And do you think it’s tremendously selfish? Selfish and demanding, having oral sex and not reciprocating? I mean … she didn’t say, “Well, you know he satisfied me.”', 'Me: And where exactly “didn’t” I say this? In which public statement that I didn’t make? In which testimony that’s not been released?', 'Katie Roiphe: I think what people are outraged about is the way that [Monica Lewinsky] looks, which is interesting. Because we like to think of our presidents as sort of godlike, and so if J.F.K. has an affair with Marilyn Monroe, it’s all in the realm of the demigods…. I mean, the thing I kept hearing over and over again was Monica Lewinsky’s not that pretty.', 'Me: Well, thanks. The first picture that surfaced was a passport photo. Would you like to have a passport photo splattered across publications around the world as the picture that defines you?', 'What you are also saying here is that the primary quality that would qualify a woman to have an intimate relationship with a powerful man is physical attractiveness. If that’s not setting the movement back, I don’t know what is.', 'Erica Jong: My dental hygienist pointed out that she had third-stage gum disease.', 'Shellogg: What do you think will happen to [her]? I mean, she’ll just fade out quietly or write a book? Or people will forget about her six months from now?', 'Nancy Friday: She can rent out her mouth.', 'Me: (Speechless.)', 'Jong: But, you know, men do like to get close to the mouth that has been close to power. Think of the fantasy in the man’s mind as she’s going down on him and he’s thinking, “Oh my God.”', 'Elizabeth Benedict: Do for me what you did to the President. Do that.', 'Me: (Still speechless.)', 'Jong: I think it’s a tribute to how far we’ve come that we’re not trashing Monica Lewinsky.', 'The catty confab appeared under the headline SUPERGALS LOVE THAT NAUGHTY PREZ. (Writing in Vanity Fair, Marjorie Williams called it “the most embarrassing thing I had read in a long time.”) To me, it illustrates a perplexing aspect of the culture of humiliation, one that Phyllis Chesler recognized in her book Woman’s Inhumanity to Woman: that women themselves are not immune to certain kinds of misogyny. We see it today in how the “mean girls” at school lurk on the modern playground of the Web (or around a pundit’s roundtable on TV or at a French restaurant), ever eager to pile on.', 'I still have deep respect for feminism and am thankful for the great strides the movement has made in advancing women’s rights over the past few decades. But, given my experience of being passed around like gender-politics cocktail food, I don’t identify myself as a Feminist, capital F. The movement’s leaders failed in articulating a position that was not essentially anti-woman during the witch hunt of 1998. In the case of the New York Supergals, it should not have been that hard for them to swoon over the president without attacking and shaming me. Instead, they joined the humiliation derby.', 'I , myself, deeply regret what happened between me and President Clinton. Let me say it again: I. Myself. Deeply. Regret. What. Happened. At the time—at least from my point of view—it was an authentic connection, with emotional intimacy, frequent visits, plans made, phone calls and gifts exchanged. In my early 20s, I was too young to understand the real-life consequences, and too young to see that I would be sacrificed for political expediency. I look back now, shake my head in disbelief, and wonder: what was I—what were we—thinking? I would give anything to go back and rewind the tape.', 'Like many other Americans, I’ve been thinking about Hillary Clinton. What might happen, I’ve wondered, if she does run in 2016? And what if she wins—and then wins a second term?', 'But when I think about these matters, there’s a dimension at play for me other than just the fact that we might finally have a woman in the White House. We all remember the second-wave feminist rallying cry The personal is political. Many people (myself included) proclaimed that my relationship with Bill Clinton was a personal matter, not one to be used in a high-stakes political war. When I hear of Hillary’s prospective candidacy, I cannot help but fear the next wave of paparazzi, the next wave of “Where is she now?” stories, the next reference to me in Fox News’s coverage of the primaries. I’ve begun to find it debilitating to plot out the cycle of my life based, to some degree, on the political calendar. For me, it’s a scenario in which the personal and the political are impossible to separate.', 'In 2008, when Hillary was running for president, I remained virtually reclusive, despite being inundated with press requests. I put off announcing several media projects in 2012 until after the election. (They were subsequently canceled—and, no, I wasn’t offered $12 million for a salacious tell-all book, contrary to press reports.) And recently I’ve found myself gun-shy yet again, fearful of “becoming an issue” should she decide to ramp up her campaign. But should I put my life on hold for another 8 to 10 years?', 'Being a conscientious Democrat—and aware that I could be used as a tool for the left or the right—I have remained silent for 10 years. So silent, in fact, that the buzz in some circles has been that the Clintons must have paid me off; why else would I have refrained from speaking out? I can assure you that nothing could be further from the truth.', 'So why speak now? Because it is time.', 'I turned 40 last year, and it is time to stop tiptoeing around my past—and other people’s futures. I am determined to have a different ending to my story. I’ve decided, finally, to stick my head above the parapet so that I can take back my narrative and give a purpose to my past. (What this will cost me, I will soon find out.) Despite what some headlines will falsely report about this piece, this is not about Me versus the Clintons. Their lives have moved on; they occupy important and powerful places on the global stage. I wish them no ill. And I fully understand that what has happened to me and the issue of my future do not matter to either of them.', 'It also goes back to the personal and the political. I have lived many of the questions that have become central to our national discourse since 1998. How far should we allow the government into our bedrooms? How do we reconcile the right to privacy with the need to expose sexual indiscretion? How do we guard against an overzealous government demanding our private data and information? And, most important to me personally, how do we cope with the shame game as it’s played in the Internet Age? (My current goal is to get involved with efforts on behalf of victims of online humiliation and harassment and to start speaking on this topic in public forums.)', 'So far, That Woman has never been able to escape the shadow of that first depiction. I was the Unstable Stalker (a phrase disseminated by the Clinton White House), the Dimwit Floozy, the Poor Innocent who didn’t know any better. The Clinton administration, the special prosecutor’s minions, the political operatives on both sides of the aisle, and the media were able to brand me. And that brand stuck, in part because it was imbued with power. I became a social representation, a social canvas on which anybody could project their confusion about women, sex, infidelity, politics, and body issues.', 'Unlike the other parties involved, I was so young that I had no established identity to which I could return. I didn’t “let this define” me—I simply hadn’t had the life experience to establish my own identity in 1998. If you haven’t figured out who you are, it’s hard not to accept the horrible image of you created by others. (Thus, my compassion for young people who find themselves shamed on the Web.) Despite much self-searching and therapy and exploring of different paths, I remained “stuck” for far too many years.', 'No longer. It’s time to burn the beret and bury the blue dress. And move forward.', 'Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement.', 'Condé Nast', '© 2018 Condé Nast. All rights reserved.', 'Use of and/or registration on any portion of this site constitutes acceptance of our User Agreement (updated 5/28/18) and Privacy Policy and Cookie Statement (updated 5/28/18).', 'Your CA Privacy Rights.', 'The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.', 'Ad Choices']\n",
      "‘How does it feel to be America’s premier blow-job queen?” It was early 2001. I was sitting on the stage of New York’s Cooper Union in the middle of taping a Q&A for an HBO documentary. I was the subject. And I was thunderstruck. Hundreds of people in the audience, mostly students, were staring at me, many with their mouths agape, wondering if I would dare to answer this question. The main reason I had agreed to participate in the program was not to rehash or revise the story line of Interngate but to try to shift the focus to meaningful issues. Many troubling political and judicial questions had been brought to light by the investigation and impeachment of President Bill Clinton. But the most egregious had been generally ignored. People seemed indifferent to the deeper matters at hand, such as the erosion of private life in the public sphere, the balance of power and gender inequality in politics and media, and the erosion of legal protections to ensure that neither a parent nor a child should ever have to testify against each other. How naïve I was. There were gasps and sputters from the audience. Numerous blurred, faceless people called out, “Don’t answer it!” “It’s hurtful and it’s insulting,” I said, attempting to gather my wits. “And as insulting as it is to me, it’s even more insulting to my family. I don’t actually know why this whole story became about oral sex. I don’t. It was a mutual relationship.… The fact that it did is maybe a result of a male-dominated society.” The audience laughed. Maybe they were surprised to hear these words coming from me. I looked straight at the smirking guy who had asked the question. “You might be better poised to answer that.” After a pause, I added, “That’s probably cost me another year of therapy.” You could argue that in agreeing to participate in an HBO documentary called Monica in Black and White I had signed up to be shamed and publicly humiliated yet again. You might even think I would have been inured to humiliation. This encounter at Cooper Union, after all, paled in comparison with the 445-page Starr Report, which was the culmination of independent counsel Kenneth Starr’s four-year investigation of the Clinton White House. It included chapter and verse about my intimate sexual activities, along with transcripts of audiotapes that chronicled many of my private conversations. But the “B.J. Queen” question—which was included in the show when it aired on HBO in 2002—sat with me for a long time after the audience left and the taping wrapped. True, this wasn’t the first time I’d been stigmatized for my affair with Bill Clinton. But never had I been so directly confronted, one-on-one, with such a crass characterization. One of the unintended consequences of my agreeing to put myself out there and to try to tell the truth had been that shame would once again be hung around my neck like a scarlet-A albatross. Believe me, once it’s on, it is a bitch to take off. Had that awkward moment at Cooper Union aired only a few years later, with the advent of social media, the humiliation would have been even more devastating. That clip would have gone viral on Twitter, YouTube, Facebook, TMZ, Gawker. It would have become a meme of its own on Tumblr. The viralness itself would have merited mention on the Daily Beast and Huffington Post. As it was, it was viral enough, and, thanks to the all-encompassing nature of the Web, you can, 12 years later, watch it all day long on YouTube if you want to (but I really hope you have better things to do with your time). I know I’m not alone when it comes to public humiliation. No one, it seems, can escape the unforgiving gaze of the Internet, where gossip, half-truths, and lies take root and fester. We have created, to borrow a term from historian Nicolaus Mills, a “culture of humiliation” that not only encourages and revels in Schadenfreude but also rewards those who humiliate others, from the ranks of the paparazzi to the gossip bloggers, the late-night comedians, and the Web “entrepreneurs” who profit from clandestine videos. Yes, we’re all connected now. We can tweet a revolution in the streets or chronicle achievements large and small. But we’re also caught in a feedback loop of defame and shame, one in which we have become both perps and victims. We may not have become a crueler society—although it sure feels as if we have—but the Internet has seismically shifted the tone of our interactions. The ease, the speed, and the distance that our electronic devices afford us can also make us colder, more glib, and less concerned about the consequences of our pranks and prejudice. Having lived humiliation in the most intimate possible way, I marvel at how willingly we have all signed on to this new way of being. In my own case, each easy click of that YouTube link reinforces the archetype, despite my efforts to parry it away: Me, America’s B.J. Queen. That Intern. That Vixen. Or, in the inescapable phrase of our 42nd president, “That Woman.” It may surprise you to learn that I’m actually a person. In 1998, when news of my affair with Bill Clinton broke, I was arguably the most humiliated person in the world. Thanks to the Drudge Report, I was also possibly the first person whose global humiliation was driven by the Internet. For several years I tried my hand in the fashion-accessory business and became involved in various media projects, including the HBO documentary. Then I lay low for the most part. (The last major interview I granted was 10 years ago.) After all, not lying low had exposed me to criticism for trying to “capitalize” on my “notoriety.” Apparently, others talking about me is O.K.; me speaking out for myself is not. I turned down offers that would have earned me more than $10 million, because they didn’t feel like the right thing to do. Over time, the media circus quieted down, but it never quite moved on, even as I attempted to move on. Meanwhile, I watched my friends’ lives move forward. Marriages. Kids. Degrees. (Second marriages. More kids. More degrees.) I decided to turn over a new leaf and attend grad school. I moved to England to study, to challenge myself, to escape scrutiny, and to reimagine my identity. My professors and fellow students at the London School of Economics were wonderful—welcoming and respectful. I had more anonymity in London, perhaps due to the fact that I spent most of my waking hours in class or buried in the library. In 2006, I graduated with a master’s in social psychology. My master’s thesis examined social bias in the courtroom and was titled “In Search of the Impartial Juror: An Exploration of Pretrial Publicity and the Third Person Effect.” I liked to joke that I was trading the blue dress for blue stockings, and the degree provided new scaffolding to hang my life experiences on. It would also prove, so I hoped, to be a gateway to a more normal life. I moved between London, Los Angeles, New York, and Portland, Oregon, interviewing for a variety of jobs that fell under the umbrella of “creative communication” and “branding,” with an emphasis on charity campaigns. Yet, because of what potential employers so tactfully referred to as my “history,” I was never “quite right” for the position. In some cases, I was right for all the wrong reasons, as in “Of course, your job would require you to attend our events.” And, of course, these would be events at which press would be in attendance. In one promising job interview that took place during the run-up to the 2008 primary season, the conversation took an interesting turn. “So here’s the thing, Monica,” the interviewer said. “You’re clearly a bright young woman and affable, but for us—and probably any other organization that relies on grants and other government funding—it’s risky. We would first need a Letter of Indemnification from the Clintons. After all, there is a 25 percent chance that Mrs. Clinton will be the next president.” I gave a fake smile and said, “I understand.” Another job interview, this one typical: walked into the stark, terminally cool reception area of a hip-yet-prestigious advertising agency in Los Angeles, my hometown. As always, I put on my best “I’m friendly, not a diva” smile. “Hi. Monica Lewinsky here to see So-and-So.” The twentysomething receptionist pushed her black-rimmed hipster frames up her nose. “Monica who?” Before I could answer, another twentysomething, in skinny jeans, plaid shirt, and bow tie, rushed over and interrupted: “ Ms. Lewinsky.” Like a maître d’, he continued, “Pleasure to have you here. I’ll let So-and-So know you’ve arrived. Soy latte? Green tea? Filtered water?” I found myself sitting at a small round table, face-to-face with So-and-So, the agency’s head of strategy and planning. We talked. She kept wincing. This was not going well. I tried to keep myself from getting flustered. Now she was not only wincing but also clearing her throat. Was that perspiration on her brow? It hit me: she was nervous, in full-tic mode. I’ve had to become adept at handling any number of reactions in social situations and job interviews. I get it: it must be disconcerting to sit across from “That Woman.” Needless to say, I didn’t get the position. I eventually came to realize that traditional employment might not be an option for me. I’ve managed to get by (barely, at times) with my own projects, usually with start-ups that I have participated in, or with loans from friends and family. In another job interview I was asked, “If you were a brand, which brand would you be?” Let me tell you, when you’re Monica Lewinsky, that is one loaded question. In September of 2010, the culmination of these experiences began to snap into a broader context for me. A phone conversation with my mother shifted the lens through which I viewed my world. We were discussing the tragic death of Tyler Clementi. Tyler, you will recall, was an 18-year-old Rutgers freshman who was secretly streamed via Webcam kissing another man. Days later, after being derided and humiliated on social media, he committed suicide by jumping off the George Washington Bridge. My mom wept. Sobbing, she kept repeating over and over, “How his parents must feel … his poor parents.” It was an unbearably tragic event, and while hearing of it brought me to tears, too, I couldn’t quite grasp why my mom was so distraught. And then it dawned on me: she was reliving 1998, when she wouldn’t let me out of her sight. She was replaying those weeks when she stayed by my bed, night after night, because I, too, was suicidal. The shame, the scorn, and the fear that had been thrown at her daughter left her afraid that I would take my own life—a fear that I would be literally humiliated to death. (I have never actually attempted suicide, but I had strong suicidal temptations several times during the investigations and during one or two periods after.) I would never be so presumptuous as to equate my own story with Tyler Clementi’s. After all, my public humiliation had been the result of my involvement with a world-renowned public figure—that is, a consequence of my own poor choices. But in that moment, when I felt the depths of my mother’s anguish, I wished I could have had a chance to have spoken to Tyler about how my love life, my sex life, my most private moments, my most sensitive secrets, had been broadcast around the globe. I wished I had been able to say to him that I knew a little of how it might have felt for him to be exposed before the world. And, as hard as it is to imagine surviving it, it is possible. In the wake of Tyler’s tragedy, my own suffering took on a different meaning. Perhaps by sharing my story, I reasoned, I might be able to help others in their darkest moments of humiliation. The question became: How do I find and give a purpose to my past? It was my Prufrockian moment: “Do I dare / Disturb the universe?” Or, in my case, the Clinton universe. Despite a decade of self-imposed silence, I have been periodically resuscitated as part of the national conversation, almost always in connection with the Clintons. For instance, in January and February of this year, Rand Paul, the Kentucky senator and a possible 2016 Republican presidential aspirant, managed to drag me into the pre-election muck. He fought back against the Democrats’ charges of a G.O.P. “war on women” by arguing that Bill Clinton had committed workplace “violence” and acted in a “predatory” manner against “a 20-year-old girl who was there from college.” Sure, my boss took advantage of me, but I will always remain firm on this point: it was a consensual relationship. Any “abuse” came in the aftermath, when I was made a scapegoat in order to protect his powerful position. So, trying to disappear has not kept me out of the fray. I am, for better or for worse, presumed to be a known quantity. Every day I am recognized. Every day. Sometimes a person will walk past me again and again, as if I wouldn’t notice. (Thankfully, 99.9 percent of the time when strangers do say something to me they are supportive and respectful.) Every day someone mentions me in a tweet or a blog post, and not altogether kindly. Every day, it seems, my name shows up in an op-ed column or a press clip or two—mentioned in passing in articles on subjects as disparate as millennials, Scandal, and French president François Hollande’s love life. Miley Cyrus references me in her twerking stage act, Eminem raps about me, and Beyoncé’s latest hit gives me a shout-out. Thanks, Beyoncé, but if we’re verbing, I think you meant “Bill Clinton’d all on my gown,” not “Monica Lewinsky’d.” With every man I date (yes, I date!), I go through some degree of 1998 whiplash. I need to be extremely circumspect about what it means to be “public” with someone. In the early years post-impeachment, I once left a front-row seat along the third-base line at a Yankees game when I learned that my date—a guy whose company I thoroughly enjoyed—was actually in another relationship. It was only a green-card marriage, but I freaked that we could be photographed together and someone might call the gossip rags. I’ve become adept at figuring out when men are interested in me for the wrong reason. Thankfully, those have been few and far between. But every man that has been special to me over the past 16 years has helped me find another piece of myself—the self that was shattered in 1998. And so, no matter the heartbreak, tears, or disenchantment, I’ll always be grateful to them. In February of this year, around the same time Senator Paul put me back into the unwanted spotlight, I became the “narcissistic loony toon,” the latest twist on Me as Archetype. A snapshot of a scenario I’ve grown all too accustomed to, even as I attempt to move on with my life: A shrill ring interrupts the rhythms of my day. The call—from the doorman of the apartment building where I’m staying in New York—leads me to an exasperated “What? Again?” They’ve reappeared: the paparazzi, like swallows, have returned to the sidewalk outside, pacing and circling and pacing some more. I hit the computer. Time for a little self-Google. (Oh, dear reader, please do not judge.) My heart sinks. There’s an explosion on Google News. I know what this means. Whatever day I’ve planned has been jettisoned. To leave the house—and risk a photo—only ensures that the story will stay alive. The cameras have returned because of the headlines: a conservative Web site has gone poking around the University of Arkansas archive of one of Hillary Clinton’s closest friends and admirers, Diane Blair, and has unearthed a cache of memos from the 1990s. In some of them, Blair, who died in 2000, quotes the former First Lady about her husband’s relationship with me. Though Hillary, according to Blair’s notes, claimed to find her husband’s “lapse” inexcusable, she praised him for trying to “manage someone who was clearly a ‘narcissistic loony toon.’ ” My first thought, as I was getting up to speed: If that’s the worst thing she said, I should be so lucky. Mrs. Clinton, I read, had supposedly confided to Blair that, in part, she blamed herself for her husband’s affair (by being emotionally neglectful) and seemed to forgive him. Although she regarded Bill as having engaged in “gross inappropriate behavior,” the affair was, nonetheless, “consensual (was not a power relationship).” I field the usual calls from friends who lend moral support whenever these volcanic media stories erupt. They diffuse the tension with good-natured teasing: “So, are we changing your monogram to NLT?” I try to ignore the former First Lady’s long-buried comments. Given my experiences with Linda Tripp, I know better than anyone what it’s like to have a conversation with a girlfriend exposed and scrutinized, taken out of context. But, even so, it begins to gnaw at me. I realize that Hillary Clinton was—unlike me when Tripp was prying loose my innermost secrets and insecurities and recording them surreptitiously—fully aware of this documentation: she’s the one who, according to the memos, asked Blair to keep a record or diary of their discussions for archival purposes. Yes, I get it. Hillary Clinton wanted it on record that she was lashing out at her husband’s mistress. She may have faulted her husband for being inappropriate, but I find her impulse to blame the Woman—not only me, but herself—troubling. And all too familiar: with every marital indiscretion that finds its way into the public sphere—many of which involve male politicians—it always seems like the woman conveniently takes the fall. Sure, the Anthony Weiners and Eliot Spitzers do what they need to do to look humiliated on cable news. They bow out of public life for a while, but they inevitably return, having put it all behind them. The women in these imbroglios return to lives that are not so easily repaired. But there is another layer here that is making me bristle: Narcissist? Loony? You might remember that just five days before the world had ever heard my name the F.B.I.—after my friend Linda Tripp approached Special Prosecutor Kenneth Starr’s office with information about my affair with the president—entrapped me in a terrifying “sting” in the Pentagon City mall. At age 24, cornered in a hotel room on January 16, 1998, with mainly male interrogators taking orders from Starr, I was discouraged from contacting my attorney and threatened with 27 years in jail for filing an affidavit denying the affair with Clinton, among other alleged crimes. I was offered immunity from that threat if I agreed to place monitored calls and wear a wire in conversations with two of the president’s confidants and possibly the president himself. I refused. Confiding in Linda Tripp turned into an unintended betrayal. But this? The mother of all betrayals. That, I couldn’t do. Courageous or foolish, maybe, but narcissistic and loony? These 16-year-old descriptions of me triggered memories of past anguish, particularly in the area of women lobbing derision at one another. So where, you might be wondering, were the feminists back then? It’s a question that troubles me to this day. I sorely wished for some sign of understanding from the feminist camp. Some good, old-fashioned, girl-on-girl support was much in need. None came. Given the issues at play—gender politics, sex in the workplace—you’d think they would have spoken up. They didn’t. I understood their dilemma: Bill Clinton had been a president “friendly” to women’s causes. It also didn’t help that my case was not one of conventional “sexual harassment”; that charge against Bill Clinton had been made by Paula Jones, who brought a colossal lawsuit against him. My name surfaced only because, thanks to newly won advances by feminists, investigations of such cases were now allowed to cast a wider net. The Jones case became a stick that the right wing used to strike back at the Clinton-supporting feminists: Why wouldn’t they enthusiastically support an investigation into a case of sexual harassment? What if the president had been a Republican? Charges of hypocrisy flew. A handful of representatives of the modern feminist movement did chime in, obliquely. Yet, instead of any meaningful engagement, we got this: January 30, 1998. Day Nine of the scandal. Cocktails at Le Bernardin, in Manhattan. In attendance: writers Erica Jong, Nancy Friday, Katie Roiphe, and Elizabeth Benedict; Saturday Night Live writer Patricia Marx; Marisa Bowe, the editor of Word, an online magazine; fashion designer Nicole Miller; former dominatrix Susan Shellogg; and their host, Le Bernardin co-owner Maguy Le Coze. The New York Observer brought this coven together to trade Interngate insights, to be recorded by Francine Prose. (Sadly, the gal who would really make this coven complete is missing: Maureen Dowd, or Moremean Dowdy, as I used to refer to her. Today, I’d meet her for a drink.) Oh, to have been at that cocktail party: Marisa Bowe: His whole life is about having to be in control and really intelligent all the time. And his wife is really intelligent and in control all the time. And the idea of just having stupid sex with some not-brilliant woman in the Oval Office, I can see the appeal in that. Imaginary Me: I’m not saying I’m brilliant, but how do you know I’m not? My first job out of college was at the White House. Susan Shellogg: And do you think it’s tremendously selfish? Selfish and demanding, having oral sex and not reciprocating? I mean … she didn’t say, “Well, you know he satisfied me.” Me: And where exactly “didn’t” I say this? In which public statement that I didn’t make? In which testimony that’s not been released? Katie Roiphe: I think what people are outraged about is the way that [Monica Lewinsky] looks, which is interesting. Because we like to think of our presidents as sort of godlike, and so if J.F.K. has an affair with Marilyn Monroe, it’s all in the realm of the demigods…. I mean, the thing I kept hearing over and over again was Monica Lewinsky’s not that pretty. Me: Well, thanks. The first picture that surfaced was a passport photo. Would you like to have a passport photo splattered across publications around the world as the picture that defines you? What you are also saying here is that the primary quality that would qualify a woman to have an intimate relationship with a powerful man is physical attractiveness. If that’s not setting the movement back, I don’t know what is. Erica Jong: My dental hygienist pointed out that she had third-stage gum disease. Shellogg: What do you think will happen to [her]? I mean, she’ll just fade out quietly or write a book? Or people will forget about her six months from now? Nancy Friday: She can rent out her mouth. Me: (Speechless.) Jong: But, you know, men do like to get close to the mouth that has been close to power. Think of the fantasy in the man’s mind as she’s going down on him and he’s thinking, “Oh my God.” Elizabeth Benedict: Do for me what you did to the President. Do that. Me: (Still speechless.) Jong: I think it’s a tribute to how far we’ve come that we’re not trashing Monica Lewinsky. The catty confab appeared under the headline SUPERGALS LOVE THAT NAUGHTY PREZ. (Writing in Vanity Fair, Marjorie Williams called it “the most embarrassing thing I had read in a long time.”) To me, it illustrates a perplexing aspect of the culture of humiliation, one that Phyllis Chesler recognized in her book Woman’s Inhumanity to Woman: that women themselves are not immune to certain kinds of misogyny. We see it today in how the “mean girls” at school lurk on the modern playground of the Web (or around a pundit’s roundtable on TV or at a French restaurant), ever eager to pile on. I still have deep respect for feminism and am thankful for the great strides the movement has made in advancing women’s rights over the past few decades. But, given my experience of being passed around like gender-politics cocktail food, I don’t identify myself as a Feminist, capital F. The movement’s leaders failed in articulating a position that was not essentially anti-woman during the witch hunt of 1998. In the case of the New York Supergals, it should not have been that hard for them to swoon over the president without attacking and shaming me. Instead, they joined the humiliation derby. I , myself, deeply regret what happened between me and President Clinton. Let me say it again: I. Myself. Deeply. Regret. What. Happened. At the time—at least from my point of view—it was an authentic connection, with emotional intimacy, frequent visits, plans made, phone calls and gifts exchanged. In my early 20s, I was too young to understand the real-life consequences, and too young to see that I would be sacrificed for political expediency. I look back now, shake my head in disbelief, and wonder: what was I—what were we—thinking? I would give anything to go back and rewind the tape. Like many other Americans, I’ve been thinking about Hillary Clinton. What might happen, I’ve wondered, if she does run in 2016? And what if she wins—and then wins a second term? But when I think about these matters, there’s a dimension at play for me other than just the fact that we might finally have a woman in the White House. We all remember the second-wave feminist rallying cry The personal is political. Many people (myself included) proclaimed that my relationship with Bill Clinton was a personal matter, not one to be used in a high-stakes political war. When I hear of Hillary’s prospective candidacy, I cannot help but fear the next wave of paparazzi, the next wave of “Where is she now?” stories, the next reference to me in Fox News’s coverage of the primaries. I’ve begun to find it debilitating to plot out the cycle of my life based, to some degree, on the political calendar. For me, it’s a scenario in which the personal and the political are impossible to separate. In 2008, when Hillary was running for president, I remained virtually reclusive, despite being inundated with press requests. I put off announcing several media projects in 2012 until after the election. (They were subsequently canceled—and, no, I wasn’t offered $12 million for a salacious tell-all book, contrary to press reports.) And recently I’ve found myself gun-shy yet again, fearful of “becoming an issue” should she decide to ramp up her campaign. But should I put my life on hold for another 8 to 10 years? Being a conscientious Democrat—and aware that I could be used as a tool for the left or the right—I have remained silent for 10 years. So silent, in fact, that the buzz in some circles has been that the Clintons must have paid me off; why else would I have refrained from speaking out? I can assure you that nothing could be further from the truth. So why speak now? Because it is time. I turned 40 last year, and it is time to stop tiptoeing around my past—and other people’s futures. I am determined to have a different ending to my story. I’ve decided, finally, to stick my head above the parapet so that I can take back my narrative and give a purpose to my past. (What this will cost me, I will soon find out.) Despite what some headlines will falsely report about this piece, this is not about Me versus the Clintons. Their lives have moved on; they occupy important and powerful places on the global stage. I wish them no ill. And I fully understand that what has happened to me and the issue of my future do not matter to either of them. It also goes back to the personal and the political. I have lived many of the questions that have become central to our national discourse since 1998. How far should we allow the government into our bedrooms? How do we reconcile the right to privacy with the need to expose sexual indiscretion? How do we guard against an overzealous government demanding our private data and information? And, most important to me personally, how do we cope with the shame game as it’s played in the Internet Age? (My current goal is to get involved with efforts on behalf of victims of online humiliation and harassment and to start speaking on this topic in public forums.) So far, That Woman has never been able to escape the shadow of that first depiction. I was the Unstable Stalker (a phrase disseminated by the Clinton White House), the Dimwit Floozy, the Poor Innocent who didn’t know any better. The Clinton administration, the special prosecutor’s minions, the political operatives on both sides of the aisle, and the media were able to brand me. And that brand stuck, in part because it was imbued with power. I became a social representation, a social canvas on which anybody could project their confusion about women, sex, infidelity, politics, and body issues. Unlike the other parties involved, I was so young that I had no established identity to which I could return. I didn’t “let this define” me—I simply hadn’t had the life experience to establish my own identity in 1998. If you haven’t figured out who you are, it’s hard not to accept the horrible image of you created by others. (Thus, my compassion for young people who find themselves shamed on the Web.) Despite much self-searching and therapy and exploring of different paths, I remained “stuck” for far too many years. No longer. It’s time to burn the beret and bury the blue dress. And move forward. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement. Condé Nast © 2018 Condé Nast. All rights reserved. Use of and/or registration on any portion of this site constitutes acceptance of our User Agreement (updated 5/28/18) and Privacy Policy and Cookie Statement (updated 5/28/18). Your CA Privacy Rights. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast. Ad Choices\n"
     ]
    }
   ],
   "source": [
    "cw21(\"dupa.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 22\n",
    "\n",
    "https://www.practicepython.org/exercise/2014/12/06/22-read-from-file.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a .txt file that has a list of a bunch of names, count how many of each name there are in the file, and print out the results to the screen. I have a .txt file for you, if you want to use it!\n",
    "\n",
    "Extra:\n",
    "\n",
    "    Instead of using the .txt file from above (or instead of, if you want the challenge), take this .txt file, and count how many of each “category” of each image there are. This text file is actually a list of files corresponding to the SUN database scene recognition database, and lists the file directory hierarchy for the images. Once you take a look at the first line or two of the file, it will be clear which part represents the scene category. To do this, you’re going to have to remember a bit about string parsing in Python 3. I talked a little bit about it in this post.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cw22():\n",
    "    def __init__(self):\n",
    "        self.file_name = \"\"\n",
    "    def save_file(self, file_name, text):\n",
    "        text = str(' '.join(text))\n",
    "        with open(file_name, 'w', encoding='utf-8') as open_file:\n",
    "            open_file.write(text)\n",
    "    def count_names(self, file_name):\n",
    "        from collections import Counter\n",
    "        with open(file_name, 'r+', encoding='utf-8') as open_file:\n",
    "            all_text = open_file.read()\n",
    "        names = all_text.split(\" \")\n",
    "        print(Counter(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Lea': 1, 'Luke': 1, 'Darth': 1, 'kornel': 1, 'korneliusz': 1})\n"
     ]
    }
   ],
   "source": [
    "names=[\"Lea\", 'Luke', 'Darth', 'kornel', 'korneliusz']\n",
    "x = cw22()\n",
    "x.save_file(\"dupa.txt\", names)\n",
    "x.count_names(\"dupa.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 23\n",
    "https://www.practicepython.org/exercise/2014/12/14/23-file-overlap.html|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given two .txt files that have lists of numbers in them, find the numbers that are overlapping. One .txt file has a list of all prime numbers under 1000, and the other .txt file has a list of happy numbers up to 1000.\n",
    "\n",
    "(If you forgot, prime numbers are numbers that can’t be divided by any other number. And yes, happy numbers are a real thing in mathematics - you can look it up on Wikipedia. The explanation is easier with an example, which I will describe below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cw22():\n",
    "    def prime_gen(self, n):\n",
    "        s=[True]*int(n/2)\n",
    "        for i in range(int((n/2-1)/2) >> 1):\n",
    "            for j in range((i*(i+3)<<1)+3,int(n/2),(i<<1)+3): s[j]=False\n",
    "        return [2] + [((i<<1)+3) for i in range(int(n/2)) if (s[i])]\n",
    "    \n",
    "    def happy_gen(self):\n",
    "        return[1, 7, 10, 13, 19, 23, 28, 31, 32, 44, 49, 68, 70, 79,\n",
    "                82, 86, 91, 94, 97, 100, 103, 109, 129, 130, 133, 139,\n",
    "                167, 176, 188, 190, 192, 193, 203, 208, 219, 226, 230,\n",
    "                236, 239, 262, 263, 280, 291, 293, 301, 302, 310, 313,\n",
    "                319, 320, 326, 329, 331, 338, 356, 362, 365, 367, 368,\n",
    "                376, 379, 383, 386, 391, 392, 397, 404, 409, 440, 446,\n",
    "                464, 469, 478, 487, 490, 496, 536, 556, 563, 565, 566,\n",
    "                608, 617, 622, 623, 632, 635, 637, 638, 644, 649, 653,\n",
    "                655, 656, 665, 671, 673, 680, 683, 694, 700, 709, 716,\n",
    "                736, 739, 748, 761, 763, 784, 790, 793, 802, 806, 818,\n",
    "                820, 833, 836, 847, 860, 863, 874, 881, 888, 899, 901,\n",
    "                904, 907, 910, 912, 913, 921, 923, 931, 932, 937, 940,\n",
    "                946, 964, 970, 973, 989, 998, 1000]\n",
    "    \n",
    "    def save_files(self):\n",
    "        text = x.prime_gen( 1000)\n",
    "        text = ','.join(str(e) for e in text)\n",
    "        with open(\"prim.txt\", 'w', encoding='utf-8') as open_file:\n",
    "            open_file.write(text)\n",
    "        text = cw22.happy_gen(self)\n",
    "        text = ','.join(str(e) for e in text)\n",
    "        with open(\"happy.txt\", 'w', encoding='utf-8') as open_file:\n",
    "            open_file.write(text)\n",
    "            \n",
    "    def overlapping_numbers(self):\n",
    "        overlapping =[]\n",
    "        with open(\"prim.txt\", 'r+', encoding='utf-8') as open_file:\n",
    "            all_num1 = open_file.read()\n",
    "        all_num1 = all_num1.split(\",\")\n",
    "        with open(\"happy.txt\", 'r+', encoding='utf-8') as open_file:\n",
    "            all_num2 = open_file.read()\n",
    "        all_num2 = all_num2.split(\",\")\n",
    "        for num1 in all_num1:\n",
    "            for num2 in all_num2:\n",
    "                if num1 == num2:\n",
    "                    overlapping.append(num1)\n",
    "        return overlapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cw22()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7',\n",
       " '13',\n",
       " '19',\n",
       " '23',\n",
       " '31',\n",
       " '79',\n",
       " '97',\n",
       " '103',\n",
       " '109',\n",
       " '139',\n",
       " '167',\n",
       " '193',\n",
       " '239',\n",
       " '263',\n",
       " '293',\n",
       " '313',\n",
       " '331',\n",
       " '367',\n",
       " '379',\n",
       " '383',\n",
       " '397',\n",
       " '409',\n",
       " '487',\n",
       " '563',\n",
       " '617',\n",
       " '653',\n",
       " '673',\n",
       " '683',\n",
       " '709',\n",
       " '739',\n",
       " '761',\n",
       " '863',\n",
       " '881',\n",
       " '907',\n",
       " '937']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.overlapping_numbers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 24\n",
    "https://www.practicepython.org/exercise/2014/12/27/24-draw-a-game-board.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "his exercise is Part 1 of 4 of the Tic Tac Toe exercise series. The other exercises are: Part 2, Part 3, and Part 4.\n",
    "\n",
    "Time for some fake graphics! Let’s say we want to draw game boards that look like this:\n",
    ":\n",
    "     --- --- --- \n",
    "    |   |   |   | \n",
    "     --- --- ---  \n",
    "    |   |   |   | \n",
    "     --- --- ---  \n",
    "    |   |   |   | \n",
    "     --- --- --- \n",
    "\n",
    "This one is 3x3 (like in tic tac toe). Obviously, they come in many other sizes (8x8 for chess, 19x19 for Go, and many more).\n",
    "\n",
    "Ask the user what size game board they want to draw, and draw it for them to the screen using Python’s print statement.\n",
    "\n",
    "Remember that in Python 3, printing to the screen is accomplished by\n",
    "\n",
    "  print(\"Thing to show on screen\")\n",
    "\n",
    "Hint: this requires some use of functions, as were discussed previously on this blog and elsewhere on the Internet, like this TutorialsPoint link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw24(number_x, number_y):\n",
    "    up_line = \" ---\"\n",
    "    mid_line = \"|   \"\n",
    "    for i in range(number_y):\n",
    "        graph = ''.join(up_line for i in range(number_x))\n",
    "        print(graph)\n",
    "        graph = ''.join(mid_line for i in range(number_x+1))\n",
    "        print(graph)\n",
    "        if i == number_y-1:\n",
    "            graph = ''.join(up_line for i in range(number_x))\n",
    "            print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- --- --- --- ---\n",
      "|   |   |   |   |   |   \n",
      " --- --- --- --- ---\n",
      "|   |   |   |   |   |   \n",
      " --- --- --- --- ---\n",
      "|   |   |   |   |   |   \n",
      " --- --- --- --- ---\n",
      "|   |   |   |   |   |   \n",
      " --- --- --- --- ---\n",
      "|   |   |   |   |   |   \n",
      " --- --- --- --- ---\n"
     ]
    }
   ],
   "source": [
    "cw24(5,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 25 \n",
    "https://www.practicepython.org/exercise/2015/11/01/25-guessing-game-two.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a previous exercise, we’ve written a program that “knows” a number and asks a user to guess it.\n",
    "\n",
    "This time, we’re going to do exactly the opposite. You, the user, will have in your head a number between 0 and 100. The program will guess a number, and you, the user, will say whether it is too high, too low, or your number.\n",
    "\n",
    "At the end of this exchange, your program should print out how many guesses it took to get your number.\n",
    "\n",
    "As the writer of this program, you will have to choose how your program will strategically guess. A naive strategy can be to simply start the guessing at 1, and keep going (2, 3, 4, etc.) until you hit the number. But that’s not an optimal guessing strategy. An alternate strategy might be to guess 50 (right in the middle of the range), and then increase / decrease by 1 as needed. After you’ve written the program, try to find the optimal strategy! (We’ll talk about what is the optimal one next week with the solution.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cw25():\n",
    "    def __init__(self):\n",
    "        import random\n",
    "        import string\n",
    "        self.attempts = 0\n",
    "        self.prediction = []\n",
    "        for number in range(0,101):\n",
    "            self.prediction.append(number)\n",
    "    def pred(self):\n",
    "        self.attempts += 1\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cw25()\n",
    "x.pred()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 26\n",
    "https://www.practicepython.org/exercise/2015/11/16/26-check-tic-tac-toe.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have guessed, we are trying to build up to a full tic-tac-toe board. However, this is significantly more than half an hour of coding, so we’re doing it in pieces.\n",
    "\n",
    "Today, we will simply focus on checking whether someone has WON a game of Tic Tac Toe, not worrying about how the moves were made.\n",
    "\n",
    "If a game of Tic Tac Toe is represented as a list of lists, like so:\n",
    "\n",
    "game = [[1, 2, 0],\n",
    "\t[2, 1, 0],\n",
    "\t[2, 1, 1]]\n",
    "\n",
    "where a 0 means an empty square, a 1 means that player 1 put their token in that space, and a 2 means that player 2 put their token in that space.\n",
    "\n",
    "Your task this week: given a 3 by 3 list of lists that represents a Tic Tac Toe game board, tell me whether anyone has won, and tell me which player won, if any. A Tic Tac Toe win is 3 in a row - either in a row, a column, or a diagonal. Don’t worry about the case where TWO people have won - assume that in every board there will only be one winner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw26(game_state):\n",
    "    # we check --- type win\n",
    "    for state in game_state:\n",
    "        if state[0] == state[1] and state[0] == state[2]:\n",
    "            return state[0]\n",
    "    # we check | type win\n",
    "    for col in range(0,3):\n",
    "        if game_state[0][col]==game_state[1][col] and game_state[0][col]==game_state[2][col]:\n",
    "            return game_state[0][col] \n",
    "    # we check X type win\n",
    "    if game_state[0][0]==game_state[1][1] and game_state[0][0]==game_state[2][2]:\n",
    "            return game_state[0][0]\n",
    "    if game_state[0][2]==game_state[1][1] and game_state[0][2]==game_state[2][0]:\n",
    "            return game_state[0][2]\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_state = [[1, 0, 2],\n",
    "            [2,1, 0],\n",
    "            [2, 1, 1]]\n",
    "cw26(game_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 27\n",
    "https://www.practicepython.org/exercise/2015/11/26/27-tic-tac-toe-draw.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cw27():\n",
    "    def __init__(self):\n",
    "        self.game_state = [[0, 0, 0],\n",
    "                        [0, 0, 0],\n",
    "                        [0, 0, 0]]\n",
    "        self.move_count = 0\n",
    "    def game_move(self, player_move):\n",
    "        self.move_count += 1\n",
    "        player_move = player_move.split(\",\")\n",
    "        player_move[0] = int(player_move[0])\n",
    "        player_move[1] = int(player_move[1])\n",
    "        print(player_move)\n",
    "        # we check if field is free\n",
    "        if self.game_state[player_move[0]][player_move[1]] != 0:\n",
    "            return \"not free position\"\n",
    "        if self.move_count % 2 ==1:\n",
    "            # player 1\n",
    "            self.game_state[player_move[0]][player_move[1]] = 1\n",
    "        if self.move_count % 2 ==0:\n",
    "            # player 2\n",
    "            self.game_state[player_move[0]][player_move[1]] = 2\n",
    "        print(self.game_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cw27()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n",
      "[[0, 0, 0], [0, 0, 1], [0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "x.game_move(\"1,2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 28\n",
    "https://www.practicepython.org/exercise/2016/03/27/28-max-of-three.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw28(var1, var2, var3):\n",
    "    # we save values for later\n",
    "    p_var1 = var1\n",
    "    p_var2 = var2\n",
    "    p_var3 = var3\n",
    "    # we make list form str\n",
    "    var1 = list(str(var1))\n",
    "    var2 = list(str(var2))\n",
    "    var3 = list(str(var3))\n",
    "    # we take len for str\n",
    "    var1 = len(var1)\n",
    "    var2 = len(var2)\n",
    "    var3 = len(var3)\n",
    "    # we return longest str\n",
    "    if var1 > var2:\n",
    "        return p_var1\n",
    "    else:\n",
    "        return p_var2\n",
    "    if var1 > var3:\n",
    "        return p_var1\n",
    "    else:\n",
    "        return p_var3\n",
    "    if var2 > var3:\n",
    "        return p_var2\n",
    "    else:\n",
    "        return p_var3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12aa54674'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw28(1235,\"12aa54674\",\"324325afeasgtwery26\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 29\n",
    "https://www.practicepython.org/exercise/2016/08/03/29-tic-tac-toe-game.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cw29_tic_tac_toe_game():\n",
    "    def __init__(self):\n",
    "        self.game_state = [[0, 0, 0],\n",
    "                        [0, 0, 0],\n",
    "                        [0, 0, 0]]\n",
    "        self.turn_count = 0\n",
    "        \n",
    "    def game(self):\n",
    "        print(\" game start we weit for muve \")\n",
    "        for game_turn in range(9):\n",
    "            player_move = input()\n",
    "            self.turn_count += 1\n",
    "            self.game_move(player_move)\n",
    "            self.scratch_board(self.game_state)\n",
    "            self.win_checker(self.game_state)\n",
    "            \n",
    "    def game_move(self, player_move):\n",
    "        player_move = player_move.split(\",\")\n",
    "        player_move[0] = int(player_move[0])\n",
    "        player_move[1] = int(player_move[1])\n",
    "        # we check if field is free\n",
    "        if self.game_state[player_move[0]][player_move[1]] != 0:\n",
    "            return \"not free position\"\n",
    "        if self.turn_count % 2 == 1:\n",
    "            # player 1\n",
    "            self.game_state[player_move[0]][player_move[1]] = 1\n",
    "        if self.turn_count % 2 == 0:\n",
    "            # player 2\n",
    "            self.game_state[player_move[0]][player_move[1]] = 2\n",
    "        #print(self.game_state)\n",
    "        \n",
    "    def scratch_board(self, game_state):\n",
    "        print(str(game_state[0][0]) + \" | \" + str(game_state[0][1]) + \" | \" + str(game_state[0][2]))\n",
    "        print(str(game_state[1][0]) + \" | \" + str(game_state[1][1]) + \" | \" + str(game_state[1][2]))\n",
    "        print(str(game_state[2][0]) + \" | \" + str(game_state[2][1]) + \" | \" + str(game_state[2][2]))\n",
    "        \n",
    "        \n",
    "    \n",
    "    def win_checker(self, game_state):\n",
    "        # we check --- type win\n",
    "        for state in self.game_state:\n",
    "            if state[0] == state[1] and state[0] == state[2]:\n",
    "                return state[0]\n",
    "        # we check | type win\n",
    "        for col in range(0,3):\n",
    "            if self.game_state[0][col]==self.game_state[1][col] and self.game_state[0][col]==self.game_state[2][col]:\n",
    "                return self.game_state[0][col] \n",
    "        # we check X type win\n",
    "        if self.game_state[0][0]==self.game_state[1][1] and self.game_state[0][0]==self.game_state[2][2]:\n",
    "                return self.game_state[0][0]\n",
    "        if self.game_state[0][2]==self.game_state[1][1] and self.game_state[0][2]==self.game_state[2][0]:\n",
    "                return self.game_state[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cw29_tic_tac_toe_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " game start we weit for muve \n"
     ]
    }
   ],
   "source": [
    "x.game()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 30\n",
    "https://www.practicepython.org/solution/2016/10/15/30-pick-word-solutions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw30():\n",
    "    import random\n",
    "    with open('sowpods.txt') as file:\n",
    "        words = list(file)\n",
    "    print(random.choice(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw30()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Pandas Data Series [4 exercises with solution] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.w3resource.com/python-exercises/pandas/index.php"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cw1 Write a Python program to create and display a one-dimensional array-like object containing an array of data using Pandas module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw1(number):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    arrey = pd.Series(np.random.randn(number))\n",
    "    print(arrey)\n",
    "    return arrey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cw1(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cw2 Write a Python program to convert a Panda module Series to Python list and it's type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw2(pn_module_series):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    pylist = pn_module_series.tolist()\n",
    "    print(pylist)\n",
    "    return pylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = cw2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Write a Python program to add, subtract, multiple and divide two Pandas Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw3(pn_series1, pn_series2, operator):\n",
    "    # operator = \"add\",\"subtract\",\"multiply\",\"divide\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    if operator is \"add\":\n",
    "        pn_series1 = pn_series1.add(pn_series2)\n",
    "        print(pn_series1)\n",
    "    if operator is \"subtract\":\n",
    "        pn_series1 = pn_series1.subtract(pn_series2)\n",
    "        print(pn_series1)\n",
    "    if operator is \"multiply\":\n",
    "        pn_series1 = pn_series1.multiply(pn_series2)\n",
    "        print(pn_series1)\n",
    "    if operator is \"divide\":\n",
    "        pn_series1 = pn_series1.divide(pn_series2, fill_value=0)\n",
    "        print(pn_series1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we do pandas series form list\n",
    "import pandas as pd\n",
    "pn_series1 = [2, 4, 6, 8, 10]\n",
    "pn_series1 = pd.Series(pn_series1)\n",
    "pn_series2 = [1, 3, 5, 7, 9]\n",
    "pn_series2 = pd.Series(pn_series2)\n",
    "x = cw3(pn_series1, pn_series2, \"divide\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Write a Python program to get the largest integer smaller or equal to the division of the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw4(series1, series2):\n",
    "    series3 = series1.divide(series2,fill_value=0)\n",
    "    series3 = series3.round()\n",
    "    return series3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we do pandas series form list\n",
    "import pandas as pd\n",
    "pn_series1 = [2, 4, 6, 8, 10]\n",
    "pn_series1 = pd.Series(pn_series1)\n",
    "pn_series2 = [1, 3, 5, 7, 9]\n",
    "pn_series2 = pd.Series(pn_series2)\n",
    "cw4(pn_series1, pn_series2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naprężenia w reaktorze zbiornikowym z mieszadłem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE\n",
    "Aglomeraty komórek o wielkości 120 μm hodowane są w reaktorze o objętości \n",
    "3,5 L wyposażonym w mieszadło Rushtonao średnicy 6 cm. Aglomeraty maja gęstość 1010 kg/m3 oraz   lepkość 1,3x10-3Pas.\n",
    "Oszacuj maksymalną dopuszczalna szybkość mieszania zapobiegającą niszczeniu komórek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw_bio_1(d, v, D):\n",
    "    # Skala Kołmogorowa mikrowirówmniejsza niż ½ -2/3 średnicy cząstki powoduje niszczenie komórek. \n",
    "    # Wielkość skali Kołmogorowa wynosi:\n",
    "    lambdaa = (2/3)*d\n",
    "    # Moc mieszadła powodująca tworzenie się takich wirów można policzyć z zależności:\n",
    "    lepkosc_dynamiczna = 1.3*(10**(-3))\n",
    "    gestosc = 1010\n",
    "    lepkosc_kinematyczna = lepkosc_dynamiczna/gestosc\n",
    "    dysypacja_mocy = (lepkosc_kinematyczna**3)/(lambdaa**4)\n",
    "    moc_mieszania = dysypacja_mocy*gestosc*(D**3)\n",
    "    print(moc_mieszania)\n",
    "    return moc_mieszania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_bio_1(120,3.5,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Web Scraping [25 exercises with solution] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a Python program to test if a given page is found or not on the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw1(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    from urllib.request import urlopen\n",
    "    from urllib.error import HTTPError\n",
    "    from urllib.error import URLError\n",
    "    try:\n",
    "        html = urlopen(url)\n",
    "    except HTTPError as e:\n",
    "        print(\"HTTP error\")\n",
    "    except URLError as e:\n",
    "        print(\"Server not found!\")\n",
    "    else:\n",
    "        print(html.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw1(\"https://www.google.pl/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw2(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    req_for_robot = requests.get(url)\n",
    "    req_for_robot_html = req_for_robot.text\n",
    "    req_for_robot_html = BeautifulSoup(req_for_robot_html, \"html5lib\")\n",
    "    return req_for_robot_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw2(\"https://en.wikipedia.org/wiki/Robots_exclusion_standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw3(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    req_for_robot = requests.get(url)\n",
    "    req_for_robot_html = req_for_robot.text\n",
    "    req_for_robot_html = BeautifulSoup(req_for_robot_html, \"html5lib\")\n",
    "    req_for_robot = req_for_robot_html.findAll('p')\n",
    "    output_text = []\n",
    "    for text in req_for_robot:\n",
    "        text = text.text.strip()\n",
    "        if len(text)>0:\n",
    "            output_text.append(text)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw3(\"https://www.data.gov/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Write a Python program to convert an address (like \"1600 Amphitheatre Parkway, Mountain View, CA\") into geographic coordinates (like latitude 37.423021 and longitude -122.083739)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw4(address):\n",
    "    import requests\n",
    "    url = 'https://maps.googleapis.com/maps/api/geocode/json'\n",
    "    params = {'sensor': 'false', 'address': address}\n",
    "    r = requests.get(url, params=params)\n",
    "    results = r.json()['results']\n",
    "    location = results[0]['geometry']['location']\n",
    "    return location['lat'], location['lng']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw4('1600 Amphitheatre Parkway, Mountain View, CA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Write a Python program to display the name of the most recently added dataset on data.gov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw5(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    req_for_robot = requests.get(url)\n",
    "    req_for_robot_html = req_for_robot.text\n",
    "    req_for_robot_html = BeautifulSoup(req_for_robot_html, \"html5lib\")\n",
    "    req_for_robot = req_for_robot_html.findAll('h2')\n",
    "    output_text = []\n",
    "    for text in req_for_robot:\n",
    "        text = text.text.strip()\n",
    "        if len(text)>0:\n",
    "            output_text.append(text)\n",
    "    return output_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw5(\"https://www.data.gov/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Write a Python program to extract h1 tag from example.com. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw6(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    req_for_robot = requests.get(url)\n",
    "    req_for_robot_html = req_for_robot.text\n",
    "    req_for_robot_html = BeautifulSoup(req_for_robot_html, \"html5lib\")\n",
    "    req_for_robot = req_for_robot_html.findAll('h1')\n",
    "    output_text = []\n",
    "    for text in req_for_robot:\n",
    "        text = text.text.strip()\n",
    "        if len(text)>0:\n",
    "            output_text.append(text)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw6(\"http://www.example.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Write a Python program to extract and display all the header tags from en.wikipedia.org/wiki/Main_Page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw7(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    req_for_robot = requests.get(url)\n",
    "    req_for_robot_html = req_for_robot.text\n",
    "    req_for_robot_html = BeautifulSoup(req_for_robot_html, \"html5lib\")\n",
    "    all_headers=[]\n",
    "    req_for_h1 = req_for_robot_html.findAll('h1')\n",
    "    all_headers.append(req_for_h1)\n",
    "    req_for_h2 = req_for_robot_html.findAll('h2')\n",
    "    all_headers.append(req_for_h2)\n",
    "    req_for_h3 = req_for_robot_html.findAll('h3')\n",
    "    all_headers.append(req_for_h3)\n",
    "    output_text =[]\n",
    "    for header in all_headers:\n",
    "        for text in header:\n",
    "            text = text.text.strip()\n",
    "            if len(text)>0:\n",
    "                output_text.append(text)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw7(\"https://en.wikipedia.org/wiki/Main_Page\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Write a Python program to extract and display all the image links from en.wikipedia.org/wiki/Peter_Jeffrey_(RAAF_officer). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw8(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    requests = requests.get(url)\n",
    "    requests = requests.text\n",
    "    requests = BeautifulSoup(requests, \"html5lib\")\n",
    "    all_photos = []\n",
    "    requests = requests.findAll('img', {'src':re.compile('.jpg')})\n",
    "    for img in requests:\n",
    "        print(img['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw8(\"https://en.wikipedia.org/wiki/Peter_Jeffrey_(RAAF_officer)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Write a Python program to get 90 days of visits broken down by browser for all sites on data.gov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw9(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    requests = requests.get(url)\n",
    "    return requests.json()['totals']['browser']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw9(\"https://analytics.usa.gov/data/live/browsers.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Write a Python program to that retrieves an arbitary Wikipedia page of \"Python\" and creates a list of links on that page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw10(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    requests = requests.get(url)\n",
    "    requests = requests.text\n",
    "    requests = BeautifulSoup(requests, \"html5lib\")\n",
    "    requests = requests.findAll('a')\n",
    "    for request in requests:\n",
    "        if 'href' in request.attrs:\n",
    "            print(request.attrs['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw10(\"https://en.wikipedia.org/wiki/Main_Page\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Write a Python program to check whether a page contains a title or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw11(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    requests = requests.get(url)\n",
    "    requests = requests.text\n",
    "    requests = BeautifulSoup(requests, \"html5lib\")\n",
    "    requests = requests.findAll('title')\n",
    "    if not requests:\n",
    "        print(\"no title on page\")\n",
    "    if requests:\n",
    "        print(\"title on page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw11(\"https://pl.wikipedia.org/wiki/Wikipedia:Strona_g%C5%82%C3%B3wna\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Write a Python program to list all language names and number of related articles in the order they appear in wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw12(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    requests = requests.get(url)\n",
    "    requests = requests.text\n",
    "    requests = BeautifulSoup(requests, \"html5lib\")\n",
    "    numbers = requests.findAll('bdi', {'dir' : \"ltr\"})[:10]\n",
    "    output =[]\n",
    "    for i in range(1,11):\n",
    "        class_adress =  'central-featured-lang lang'+str(i)\n",
    "        text = requests.findAll('strong')\n",
    "        output.append(text)\n",
    "    output = output[:1]\n",
    "    return output ,numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw12(\"https://www.wikipedia.org/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Write a Python program to get the number of people visiting a U.S. government website right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw13(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    requests = requests.get(url)\n",
    "    return requests.json()['query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"https://analytics.usa.gov/data/live/realtime.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw13(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Write a Python program get the number of security alerts issued by US-CERT in the current year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw14(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    requests = requests.get(url)\n",
    "    requests = requests.text\n",
    "    requests = BeautifulSoup(requests, \"html5lib\")\n",
    "    requests = requests.findAll('div', {'class' : \"item-list\"})\n",
    "    for request in requests:\n",
    "        request = request.text.strip()\n",
    "        print(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw14(\"https://www.us-cert.gov/ncas/alerts/2018\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Write a Python program to get the number of Pinterest accounts maintained by U.S. State Department embassies and missions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw15(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    requests = requests.get(url)\n",
    "    requests = requests.text\n",
    "    requests = BeautifulSoup(requests, \"html5lib\")\n",
    "    requests = requests.findAll('a')\n",
    "    for request in requests:\n",
    "        request = request.text.strip()\n",
    "        print(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw15(\"https://www.state.gov/r/pa/ode/socialmedia/#fb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Write a Python program to get the number of followers of a given twitter account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw16(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    requests = requests.get(url)\n",
    "    requests = requests.text\n",
    "    requests = BeautifulSoup(requests, \"html5lib\")\n",
    "    follow_box = requests.find('li',{'class':'ProfileNav-item ProfileNav-item--followers'})\n",
    "    requests = follow_box.find('a').find('span',{'class':'ProfileNav-value'})\n",
    "    requests = requests.text.strip()\n",
    "    print(requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw16(\"https://twitter.com/elonmusk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. Write a Python program to get the number of following on Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw17(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    requests = requests.get(url)\n",
    "    requests = requests.text\n",
    "    requests = BeautifulSoup(requests, \"html5lib\")\n",
    "    follow_box = requests.find('li',{'class':'ProfileNav-item ProfileNav-item--followers'})\n",
    "    requests = follow_box.find('a').find('span',{'class':'ProfileNav-value'})\n",
    "    requests = requests.text.strip()\n",
    "    print(requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw17(\"https://twitter.com/elonmusk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. Write a Python program to get the number of post on Twitter liked by a given account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw18(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    requests = requests.get(url)\n",
    "    requests = requests.text\n",
    "    requests = BeautifulSoup(requests, \"html5lib\")\n",
    "    follow_box = requests.find('li',{'class':'ProfileNav-item ProfileNav-item--favorites'})\n",
    "    requests = follow_box.find('a').find('span',{'class':'ProfileNav-value'})\n",
    "    requests = requests.text.strip()\n",
    "    print(requests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cw18(\"https://twitter.com/elonmusk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21. Write a Python program to find the live weather report (temperature, wind speed, description and weather) of a given city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw23(city):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    try:\n",
    "        query ='q='+city\n",
    "        request = requests.get('http://api.openweathermap.org/data/2.5/weather?'+query+'&APPID=b35975e18dc93725acb092f7272cc6b8&units=metric')\n",
    "        request = request.json()\n",
    "        print(\"temp:\",request['main']['temp'])\n",
    "        print(\"wind speed:\",request['wind']['speed'])\n",
    "        print(\"weather:\",request['weather'][0]['description'])\n",
    "        print(\"Weather:\",request['weather'][0]['main'])\n",
    "    except:\n",
    "        print('City name not found...')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw23('Warszawa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a Python program to check if a given positive integer is a power of two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ch1(integer):\n",
    "    import math\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        if 2 == math.pow(integer,(1/i)):\n",
    "            print(True)\n",
    "            break\n",
    "        if i == integer*10000:\n",
    "            print(False)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "ch1(1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write a Python program to check if a given positive integer is a power of three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ch2(integer):\n",
    "    import math\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        if 3 == math.pow(integer,(1/i)):\n",
    "            print(True)\n",
    "            break\n",
    "        if i == integer*10:\n",
    "            print(False)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "ch2(59049)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Write a Python program to check if a given positive integer is a power of four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ch3(integer):\n",
    "    import math\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        if 4 == math.pow(integer,(1/i)):\n",
    "            print(True)\n",
    "            break\n",
    "        if i == integer*10:\n",
    "            print(False)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "ch3(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Write a Python program to check if a number is a perfect square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ch4(integer):\n",
    "    import math\n",
    "    integer_sqrt = math.sqrt(integer)\n",
    "    if integer_sqrt.is_integer():\n",
    "        print(True)\n",
    "    else:\n",
    "        print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "ch4(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Write a Python program to check if an integer is the power of another integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ch5(integer):\n",
    "    import math\n",
    "    for i in range(2,integer):\n",
    "        integer_sqrt = math.pow(integer,1/i)\n",
    "        if integer_sqrt.is_integer():\n",
    "            print(True)\n",
    "            return\n",
    "        if i == integer-1:\n",
    "            print(False)\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "ch5(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Write a Python program to check if a number is a power of a given base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ch6(power, base):\n",
    "    import math\n",
    "    for i in range(1000):\n",
    "        if math.pow(base, i) == power:\n",
    "            print(True)\n",
    "            return\n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "ch6(0,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Write a Python program to find a missing number from a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ch7(list_num):\n",
    "    import math\n",
    "    for i in range(1,len(list_num)+1):\n",
    "        if not i == list_num[i-1]:\n",
    "            print(i)\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "ch7([1,2,3,4,6,7,8,9,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Write a Python program to create and display a DataFrame from a specified dictionary data which has the index labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "      <th>attempts</th>\n",
       "      <th>qualify</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>Anastasia</td>\n",
       "      <td>12.5</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>Dima</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>Katherine</td>\n",
       "      <td>16.5</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>James</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>Emily</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>Michael</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>Matthew</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>Laura</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>Kevin</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>j</th>\n",
       "      <td>Jonas</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name  score  attempts qualify\n",
       "a  Anastasia   12.5         1     yes\n",
       "b       Dima    9.0         3      no\n",
       "c  Katherine   16.5         2     yes\n",
       "d      James    NaN         3      no\n",
       "e      Emily    9.0         2      no\n",
       "f    Michael   20.0         3     yes\n",
       "g    Matthew   14.5         1     yes\n",
       "h      Laura    NaN         1      no\n",
       "i      Kevin    8.0         2      no\n",
       "j      Jonas   19.0         1     yes"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "exam_data = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
    "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "df = pd.DataFrame(exam_data, index=labels)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw1(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    requests = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw1(\"http://192.168.1.101/stream\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# python/tf/keras exercises basic mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.core import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the type of X_train?\n",
    "# traing data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the type of y_train?\n",
    "# label for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the dimension of X_train?. What does that mean?\n",
    "# 60000 x 28 x 28 x 1\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = pyplot.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "imgplot = ax.imshow(x_train[10], cmap=mpl.cm.Greys)\n",
    "imgplot.set_interpolation('nearest')\n",
    "ax.xaxis.set_ticks_position('top')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# make arreys\n",
    "x_train= x_train.reshape(60000,784)\n",
    "x_test= x_test.reshape(10000,784)\n",
    "x_train= x_train.astype(\"float32\")\n",
    "x_test= x_test.astype(\"float32\")\n",
    "# grey scaling \n",
    "x_train /=255\n",
    "x_test /=255\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "batch_size = 128\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.001), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 15000 samples\n",
      "Epoch 1/10\n",
      "45000/45000 [==============================] - 5s 110us/step - loss: 1.4432 - acc: 0.5429 - val_loss: 0.6193 - val_acc: 0.8133\n",
      "Epoch 2/10\n",
      "45000/45000 [==============================] - 4s 81us/step - loss: 0.6768 - acc: 0.7860 - val_loss: 0.4467 - val_acc: 0.8707\n",
      "Epoch 3/10\n",
      "45000/45000 [==============================] - 4s 79us/step - loss: 0.5312 - acc: 0.8338 - val_loss: 0.3786 - val_acc: 0.8899\n",
      "Epoch 4/10\n",
      "45000/45000 [==============================] - 4s 78us/step - loss: 0.4599 - acc: 0.8569 - val_loss: 0.3389 - val_acc: 0.9023\n",
      "Epoch 5/10\n",
      "45000/45000 [==============================] - 4s 80us/step - loss: 0.4129 - acc: 0.8731 - val_loss: 0.3119 - val_acc: 0.9095\n",
      "Epoch 6/10\n",
      "45000/45000 [==============================] - 3s 78us/step - loss: 0.3830 - acc: 0.8816 - val_loss: 0.2913 - val_acc: 0.9158\n",
      "Epoch 7/10\n",
      "45000/45000 [==============================] - 4s 79us/step - loss: 0.3617 - acc: 0.8895 - val_loss: 0.2757 - val_acc: 0.9198\n",
      "Epoch 8/10\n",
      "45000/45000 [==============================] - 3s 77us/step - loss: 0.3420 - acc: 0.8953 - val_loss: 0.2622 - val_acc: 0.9233\n",
      "Epoch 9/10\n",
      "45000/45000 [==============================] - 4s 78us/step - loss: 0.3221 - acc: 0.9021 - val_loss: 0.2510 - val_acc: 0.9267\n",
      "Epoch 10/10\n",
      "45000/45000 [==============================] - 4s 78us/step - loss: 0.3093 - acc: 0.9060 - val_loss: 0.2419 - val_acc: 0.9290\n"
     ]
    }
   ],
   "source": [
    "network_history = model.fit(x_train, y_train,\n",
    "                            batch_size=batch_size, \n",
    "                            epochs=epochs,\n",
    "                            verbose=1,\n",
    "                            validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xl4XNWd5vHvT/u+lrwvsi0BXpBtIcximSUQGkhiIKEBB0ITFjckgWToTDedSU8yZDJDMt0ESJMFCNDdIbgJBHBolm4SEmzMZoNtsA14t4Vsa7GtfdeZP26ptFibLZWupHo/z1NPVd26deunAuvVOeeec805h4iICECU3wWIiMjooVAQEZEQhYKIiIQoFEREJEShICIiIQoFEREJUSiIiEiIQkFEREIUCiIiEhLjdwHHKxAIuNzcXL/LEBEZUzZs2FDhnMsZaL8xFwq5ubmsX7/e7zJERMYUM9s7mP3UfSQiIiEKBRERCVEoiIhIyJgbUxCR8aOlpYWSkhIaGxv9LmXcSEhIYNq0acTGxp7Q+xUKIuKbkpISUlNTyc3Nxcz8LmfMc85RWVlJSUkJs2bNOqFjqPtIRHzT2NhIdna2AmGYmBnZ2dlDankpFETEVwqE4TXU7zNiQuGTQzX87xe20tjS5ncpIiKjVsSEQsmReh5Zu5v1e474XYqIjBKVlZUsWrSIRYsWMWnSJKZOnRp63tzcPKhjfPWrX+Xjjz/ud58HH3yQJ554YjhKDruIGWg+Y1Y2MVHG2h0VFOcH/C5HREaB7OxsNm7cCMD3v/99UlJS+Pa3v91tH+cczjmionr/G/qxxx4b8HO+/vWvD73YERIxLYXk+BgKZ2Sydke536WIyCi3Y8cOFixYwK233kphYSEHDhxg5cqVFBUVMX/+fO6+++7QvsXFxWzcuJHW1lYyMjK46667WLhwIWeddRZlZWUAfPe73+W+++4L7X/XXXexZMkSTj75ZNatWwdAXV0dX/rSl1i4cCErVqygqKgoFFgjKWJaCgDF+QF+8uonHK5rJis5zu9yRKSL//X7LWwtrR7WY86bksb3vjD/hN67detWHnvsMX7xi18AcM8995CVlUVrayvnn38+V155JfPmzev2nqqqKs4991zuuece7rzzTh599FHuuuuuY47tnOOdd95h9erV3H333bz88sv89Kc/ZdKkSTzzzDNs2rSJwsLCE6p7qMLWUjCzR82szMw+HGC/082szcyuDFctHYrzAzgH63ZWhPujRGSMmzNnDqeffnro+ZNPPklhYSGFhYVs27aNrVu3HvOexMRELrnkEgBOO+009uzZ0+uxv/jFLx6zz9q1a7nmmmsAWLhwIfPnn1iYDVU4WwqPA/8M/GtfO5hZNPAj4JUw1hFSMDWd1IQY1m6v4PMFU0biI0VkkE70L/pwSU5ODj3evn07999/P++88w4ZGRlcd911vc4FiIvr7IGIjo6mtbW112PHx8cfs49zbjjLP2Fhayk4514HDg+w2+3AM0BZuOroKiY6irNmZ7Nme8Wo+Q8gIqNfdXU1qamppKWlceDAAV55Zfj/ji0uLuapp54C4IMPPui1JTISfBtTMLOpwBXAZ4DTB9h3JbASYMaMGUP63GX5Af5z6yH2VtaTG0ge+A0iEvEKCwuZN28eCxYsYPbs2SxdunTYP+P222/n+uuvp6CggMLCQhYsWEB6evqwf85ALJx/MZtZLvCCc25BL6/9Fvgn59xbZvZ4cL+nBzpmUVGRG8pFdnaV1/KZf/ozP7h8AV85c+YJH0dEhm7btm3MnTvX7zJGhdbWVlpbW0lISGD79u1cdNFFbN++nZiY4//bvbfv1cw2OOeKBnqvn2cfFQGrglOyA8ClZtbqnHsunB86K5DM1IxE3theoVAQkVGjtraWCy64gNbWVpxz/PKXvzyhQBgq30LBORdawq9LSyGsgRD8LIrzArz04QHa2h3RUVp3RUT8l5GRwYYNG/wuI6ynpD4JvAmcbGYlZnaTmd1qZreG6zMHa2l+gOrGVjaXHPW7FBGRUSVsLQXn3Irj2PeGcNXRm6VzsgF4Y0cFi2dkjuRHi4iMahGzzEVX2SnxzJ+SxprtmsQmItJVRIYCQHFegPf2HaGuqffJJSIikShyQyE/QEub4509A82vE5Hx6rzzzjtmItp9993H1772tT7fk5KSAkBpaSlXXtn76jznnXceA506f99991FfXx96fumll3L0qP/jnBEbCqfnZhEXE8VadSGJRKwVK1awatWqbttWrVrFihUDD4lOmTKFp58ecGpVn3qGwosvvkhGRsYJH2+4RGwoJMRGc3pupkJBJIJdeeWVvPDCCzQ1NQGwZ88eSktLWbRoERdccAGFhYWceuqpPP/888e8d8+ePSxY4M3LbWho4JprrqGgoICrr76ahoaG0H633XZbaMnt733vewA88MADlJaWcv7553P++ecDkJubS0WF9/vo3nvvZcGCBSxYsCC05PaePXuYO3cut9xyC/Pnz+eiiy7q9jnDJaKWzu6pOC+HH738EWU1jUxITfC7HJHI9tJdcPCD4T3mpFPhknv6fDk7O5slS5bw8ssvc9lll7Fq1SquvvpqEhMTefbZZ0lLS6OiooIzzzyT5cuX93n945///OckJSWxefNmNm/e3G3Z6x/+8IdkZWXR1tbGBRdcwObNm7njjju49957ee211wgEul/0a8OGDTz22GO8/fbbOOc444wzOPfcc8nMzGT79u08+eSTPPzww1x11VU888wzXHfddcPzXQVFbEsBvMFm8E5NFZHI1LULqaPryDnHd77zHQoKCrjwwgv59NNPOXToUJ/HeP3110O/nAsKCigoKAi99tRTT1FYWMjixYvZsmXLgAvdrV27liuuuILk5GRSUlL44he/yJo1awCYNWsWixYtAvpfmnsoIrqlMH9KGplJsazdXskVi6f5XY5IZOvnL/pwuvzyy7nzzjt57733aGhooLCwkMcff5zy8nI2bNhAbGwsubm5vS6V3VVvrYjdu3fzj//4j7z77rtkZmZyww03DHic/taj61hyG7xlt8PRfRTRLYWoKOPsvABrd5RrKW2RCJWSksJ5553HjTfeGBpgrqqqYsKECcTGxvLaa6+xd+/efo9xzjnn8MQTTwDw4YcfsnnzZsBbcjs5OZn09HQOHTrESy+9FHpPamoqNTU1vR7rueeeo76+nrq6Op599lmWLVs2XD/ugCI6FMDrQjpU3cSOslq/SxERn6xYsYJNmzaFrnx27bXXsn79eoqKinjiiSc45ZRT+n3/bbfdRm1tLQUFBfz4xz9myZIlgHcFtcWLFzN//nxuvPHGbktur1y5kksuuSQ00NyhsLCQG264gSVLlnDGGWdw8803s3jx4mH+ifsW1qWzw2GoS2f3tP9wPct+/Brf+8I8vrp01sBvEJFho6Wzw2MoS2dHfEthelYSudlJOjVVRASFAgBL8wK8tauSlrZ2v0sREfGVQgHvEp11zW1s3O//FHORSDPWurBHu6F+nwoF4KzZAaIMrZoqMsISEhKorKxUMAwT5xyVlZUkJJz4ZNyInqfQIT0pllOnZbB2ezl3fvYkv8sRiRjTpk2jpKSE8vJyv0sZNxISEpg27cTnXSkUgpblBfj5n3dS3dhCWkKs3+WIRITY2FhmzdJZf6OJuo+CivMDtLU73tpZ6XcpIiK+USgELZ6RQWJsNGu1DpKIRDCFQlB8TDRnzM5SKIhIRFModFGcF2BXeR2lR4d/kSkRkbFAodBFcb63lLZmN4tIpFIodHHyxFQCKfHqQhKRiKVQ6MLMKM7L5o0dFbS3azKNiESesIWCmT1qZmVm9mEfr19rZpuDt3VmtjBctRyP4vwcKuua+ejgseuci4iMd+FsKTwOXNzP67uBc51zBcAPgIfCWMugdVyic+0OzbAUkcgTtlBwzr0OHO7n9XXOuSPBp28Bo+J6mJPSE8ibkKJ1kEQkIo2WMYWbgJf6etHMVprZejNbPxJrpBTnBXh3z2EaW9rC/lkiIqOJ76FgZufjhcLf9bWPc+4h51yRc64oJycn7DUtyw/Q2NLOe3uPDLyziMg44msomFkB8AhwmXNu1Cw6dMbsbGKijDU6NVVEIoxvoWBmM4DfAV9xzn3iVx29SYmPYfGMDN5QKIhIhAnnKalPAm8CJ5tZiZndZGa3mtmtwV3+J5AN/MzMNprZ+nDVciKK83L44NMqjtQ1+12KiMiICdv1FJxzKwZ4/Wbg5nB9/lAV52fzk1dh3c5KPlcw2e9yRERGhO8DzaPVwmkZpMbHaMkLEYkoCoU+xERHceacbE1iE5GIolDoR3FegP2HG9hbWed3KSIiI0Kh0I/QUtrqQhKRCKFQ6MfsQDJT0hN0fQURiRgKhX6YGUvzAqzbWUmbltIWkQigUBhAcX6AqoYWPvy0yu9SRETCTqEwgKV5GlcQkcihUBhAICWeuZPTWLNdp6aKyPinUBiEZfkB3tt7lPrmVr9LEREJK4XCICzNC9Dc1s47u/u8ZpCIyLigUBiEJblZxEVHadVUERn3FAqDkBgXTVFupi7RKSLjnkJhkJbmBfjoYA3lNU1+lyIiEjYKhUFaFlzyYt1OtRZEZPxSKAzS/CnpZCTFqgtJRMY1hcIgRUcZZ8/JZu32CpzTkhciMj4pFI5DcV4OB6sb2VmupbRFZHxSKByHjnGFtZrdLCLjlELhOEzPSmJGVpLWQRKRcUuhcJyK8wO8teswLW3tfpciIjLsFArHaVlegNqmVjbtP+p3KSIiw06hcJzOmpONGTo1VUTGJYXCccpIiqNgarrWQRKRcSlsoWBmj5pZmZl92MfrZmYPmNkOM9tsZoXhqmW4FecHeH//UWoaW/wuRURkWIWzpfA4cHE/r18C5AdvK4Gfh7GWYbU0L0Bbu+OtXVpKW0TGl7CFgnPudaC/35qXAf/qPG8BGWY2OVz1DKfTZmaSGButLiQRGXf8HFOYCuzv8rwkuO0YZrbSzNab2frycv8njsXHRLNkVpYu0Ski446foWC9bOt1USHn3EPOuSLnXFFOTk6Yyxqc4rwAO8vrOFDV4HcpIiLDxs9QKAGmd3k+DSj1qZbjVhxa8kJdSCIyfvgZCquB64NnIZ0JVDnnDvhYz3E5eWIqgZQ4LXkhIuNKTLgObGZPAucBATMrAb4HxAI4534BvAhcCuwA6oGvhquWcIiKMpbmBXhjh7eUtllvvWEiImNL2ELBObdigNcd8PVwff5IKM4L8PzGUj46WMPcyWl+lyMiMmSa0TwEGlcQkfFGoTAEk9MTmZOTrHEFERk3FApDtCw/h7d3V9LU2uZ3KSIiQ6ZQGKKleQEaW9rZsPeI36WIiAyZQmGIzpydRXSUackLERkXFApDlJoQy+LpGRpsFpFxQaEwDJbmBdj8aRVH65v9LkVEZEgUCsNgWX4A5+DNnZV+lyIiMiQKhWGwcHoGKfExrNG4goiMcQqFYRAbHcWZs7M0riAiY55CYZgU5wXYd7iefZX1fpciInLCBhUKZjbHzOKDj88zszvMLCO8pY0txfnedR40u1lExrLBthSeAdrMLA/4FTAL+E3YqhqD5uQkMyktQfMVRGRMG2wotDvnWoErgPucc/8NGBPXUx4pZkZxfoA3dlbQ1t7rBeREREa9wYZCi5mtAP4KeCG4LTY8JY1dy/IDHK1vYUtpld+liIickMGGwleBs4AfOud2m9ks4NfhK2tsOntOcCltdSGJyBg1qFBwzm11zt3hnHvSzDKBVOfcPWGubczJSY3nlEmpOjVVRMaswZ599CczSzOzLGAT8JiZ3Rve0sam4rwA6/ccoaFZS2mLyNgz2O6jdOdcNfBF4DHn3GnAheEra+wqzg/Q3NbOu3sO+12KiMhxG2woxJjZZOAqOgeapRdLZmURFx2lcQURGZMGGwp3A68AO51z75rZbGB7+Moau5LiYiicmcEajSuIyBg02IHm3zrnCpxztwWf73LOfSm8pY1dy/Jz2HagmoraJr9LERE5LoMdaJ5mZs+aWZmZHTKzZ8xsWriLG6uK87xTUzW7WUTGmsF2Hz0GrAamAFOB3we39cvMLjazj81sh5nd1cvrM8zsNTN738w2m9mlx1P8aLVgajrpibE6NVVExpzBhkKOc+4x51xr8PY4kNPfG8wsGngQuASYB6wws3k9dvsu8JRzbjFwDfCz46p+lIqOMs6ek80bOypwTkteiMjYMdhQqDCz68wsOni7DhjoMmNLgB3B8YdmYBVwWY99HJAWfJwOlA628NGuOD9AaVUjuyrq/C5FRGTQBhsKN+KdjnoQOABcibf0RX+mAvu7PC8Jbuvq+8B1ZlYCvAjcPsh6Rr2OcQV1IYnIWDLYs4/2OeeWO+dynHMTnHOX401k64/1dqgez1cAjzvnpgGXAv9mZsfUZGYrzWy9ma0vLy8fTMm+m5mdzPSsRM1XEJExZShXXrtzgNdLgOldnk/j2O6hm4CnAJxzbwIJQKDngZxzDznnipxzRTk5/Q5ljCrFeTm8tbOS1rZ2v0sRERmUoYRCby2Brt4F8s1slpnF4Q0kr+6xzz7gAgAzm4sXCmOjKTAIxXkBappa2VSipbRFZGwYSij0e1pN8KI838CbCb0N7yyjLWZ2t5ktD+72N8AtZrYJeBK4wY2j03XOnpONmcYVRGTsiOnvRTOrofdf/gYkDnRw59yLeAPIXbf9zy6PtwJLB1XpGJSZHMepU9NZu6Ocb16Y73c5IiID6rel4JxLdc6l9XJLdc71GyjiWZoX4P19R6ltavW7FBGRAQ2l+0gGYVlegNZ2x9u7BprWISLiP4VCmBXOzCQhNkqrporImKBQCLOE2GhOz83S4ngiMiYoFEbAsvwA28tqOVjV6HcpIiL9UiiMgKUdS16otSAio5xCYQTMnZRGdnKcupBEZNRTKIyAqChjaV6AtVpKW0RGOYXCCCnOC1Be08THh2r8LkVEpE8KhRFSnK+ltEVk9FMojJApGYnMzknWYLOIjGoKhRFUnBfg7V2HaWpt87sUEZFeKRRGUHFegIaWNt7fd9TvUkREeqVQGEFnzskmOso0riAio5ZCYQSlJcSycFo6a7aX69RUERmVFAoj7C/mT2JTSRVfe+I9jtY3+12OiEg3CoURdsuy2fz9Jafw6rZDXHzfGs1yFpFRRaEwwqKijL8+dw7Pfm0pyfHRXPvI2/zwP7bqjCQRGRUUCj5ZMDWdF25fxlfOnMnDa3Zz+YPr2K7ZziLiM4WCjxLjovnB5Qv41V8VUVbdyOd/upZ/WbdHg9Ai4huFwihwwdyJvPytczhrTjbfW72FGx9/l/KaJr/LEpEIpFAYJXJS43nshtO5+7L5rNtZycX3vc4fth3yuywRiTAKhVHEzLj+rFxeuL2YCWkJ3PQv6/nucx/Q0KxBaBEZGZEVCg1jY3mJ/ImpPPf1s1l5zmx+/dY+Pv/TNXz4aZXfZYlIBAhrKJjZxWb2sZntMLO7+tjnKjPbamZbzOw3YSvm45fg/oWw4w9h+4jhFB8TzXcuncuvbzqD2qZWrvjZG/zizztpb9cgtIiET9hCwcyigQeBS4B5wAozm9djn3zg74Glzrn5wLfCVQ8TF0D6NHjiL+Gdh8P2McOtOD/Ay988hwvnTuSelz7i2kfepvRog99licg4Fc6WwhJgh3Nul3OuGVgFXNZjn1uAB51zRwCcc2VhqyZjOtz4MuRfBC9+G/7j29DWGraPG06ZyXH87NpCfnxlAZtKjnLxfa/zwuZSv8sSkXEonKEwFdjf5XlJcFtXJwEnmdkbZvaWmV0cxnogPhWueQLOvgPefRh+85djZpzBzLiqaDov3rGM2TkpfOM37/M3T22iprHF79JEZBwJZyhYL9t6dojHAPnAecAK4BEzyzjmQGYrzWy9ma0vLy8fWlVR0XDRD2D5P8Pu1+FXn4XDu4Z2zBGUG0jmt7eexR2fyePZ90u49IE1bNh7xO+yRGScCGcolADTuzyfBvTs8ygBnnfOtTjndgMf44VEN865h5xzRc65opycnOGprvArcP3zUFcOD18Ae94YnuOOgNjoKO686GSe+uuzcA6u+uWb/OS/PqG1rd3v0kRkjAtnKLwL5JvZLDOLA64BVvfY5zngfAAzC+B1J43cn+25xXDzHyA5AP96Gbz/6xH76OFQlJvFS99cxmWLpnD/H7bzl798k72VdX6XJSJjWNhCwTnXCnwDeAXYBjzlnNtiZneb2fLgbq8AlWa2FXgN+O/Oucpw1dSr7Dlw0395AfH81+E//wHax85ksdSEWO69ahE/XbGYHWW1XHr/Gn67fr/WTxKRE2Jj7ZdHUVGRW79+/fAfuK0VXv47ePcROPlS+OLDEJ8y/J8TRp8ebeDOf9/I27sP87lTJ/PDKxaQkRTnd1kiMgqY2QbnXNFA+0XWjOb+RMfA5/4JLvl/8MnL8OjFcHT/wO8bRaZmJPKbW87kby8+mVe2HOTi+9awThfxEZHjoFDo6YyVcO1v4eheePgzUBKGVkkYRUcZXzsvj2e/tpSk+Giu/dXb/N8Xt+kiPiIyKAqF3uRd6I0zxCXBY5fCB0/7XdFxO3VaOi/cXsyXl8zgl6/v4ooH17GjTBfxEZH+KRT6MuEUuPmPMPU0eOYmeO3/wBgbf0mKi+GHV5zKw9cXcbC6kc89sJZ/e1MX8RGRvikU+pOcDdc/B4uuhT//CJ7+KrSMvXWHPjtvIi9/axlnzM7mH57fwk3/sl4X8RGRXikUBhITD5c9CJ+9G7Y8B49/DmoO+l3VcZuQmsDjN5zO974wj7U7Krjk/td5fuOnNLZorEFEOumU1OPx0X/AMzdDYiasWAWTC/ypY4g+PljDN1e9z0cHa0iJj+GieRP5wqIpFOcFiI3W3wki49FgT0lVKByvA5vhyWu8hfS+9DCc8jn/ahmCtnbHW7sqWb2xlJc+PEB1YyuZSbFceupkvrBwCktys4iK6m35KhEZixQK4VRzEFZ9GT59Dy78Piz9JtjY/QXa1NrG659U8PtNpfzX1kM0tLQxKS2BzxdMZvmiKZw6NR0bwz+fiCgUwq+lAZ77Gmz5nTcQ/fmfeOMPY1x9cyuvbitj9cZS/vxJGS1tjtzsJL6wcArLF04hf2Kq3yWKyAlQKIwE5+BP98Cf74EZZ8PVv/bOWBonqupbeGXLQVZvKmXdzgraHZwyKTUUENOzkvwuUUQGSaEwkj542ms1pE6CLz/lzXEYZ8pqGnnpAy8gOq7fsHhGBl8omMLnCyYzIS3B5wpFpD8KhZFWsh6eXAGtjXDlY5B/od8VhU3JkXpe2HyA1RtL2XqgmiiDM2dns3zhFC5eMEmL8ImMQgoFPxzd7wVD2Ra4+EfeOkrj3I6yWlZvKuX3m0rZXVFHbLRxTn4OyxdN4cK5E0mOj/G7RBFBoeCfplr43S3w8Ytw+s1w8T0QHet3VWHnnGNLaXUoIA5UNZIQG8UFcyeyfOEUzjs5h/iYaL/LFIlYCgU/tbfBq9+HdQ/A7PPgL/8FEo+59PS41d7u2LDvCKs3lvLiBweorGsmNSGGv5g/ieULp3D2nGxiNElOZEQpFEaD938Nv/8WZObCl//du8pbhGlta+eNnZX8flMpr3x4kJqmVgIpcaFJcqfNyNQkOZERoFAYLfa8Af9+rff4qn+DWcv8rcdHjS1t/Onjcn6/qZRXtx2iqbWdKekJnH/KBIpyMzltRhbTsxI1UU4kDBQKo8nhXfCbq737z/8ECq/3uyLf1Ta18urWQ7ywuZS3dh2mtqkVgJzUeE6bkemFxMxM5k9JJy5GXU0iQ6VQGG0ajnpLb+/8IxTdBGf8NeSc7HdVo0Jbu+OTQzWs33uE9/YeYf3ew+w/7C1RHh8TxcJpGRTOzKRoZiaFMzPJStYpryLHS6EwGrW1wivfgXceAhzknALzLof5l8OEuX5XN6qUVTeyYe8RNuw9wvq9R9hSWkVLm/f/6uycZIpmei2J02ZmMScnWV1OIgNQKIxm1Qdg2+9h63Owdx3gIHCyFw7zggGhX3LdNLa0sbmkivV7D/NeMCyO1LcAkJEUy2kzMkOtiYXTM0iI1emvIl0pFMaKmoNeQGx5Dva+gRcQJ8G8y7yAmDhfAdEL5xw7y+tC3U0b9h5hZ3kdADFRxvyp6aHWRNHMTC3DIRFPoTAW1RyCj7oEhGuH7LzOLqaJCxQQ/Thc1+y1IvYdYcOeI2wqOUpTazsA07MSOW1GJqflZnHajExOnpRKtE6FlQgyKkLBzC4G7geigUecc/f0sd+VwG+B051z/f7GH9eh0FVtWbCL6XnYs8YLiKw5Xgti/uUwqUABMYDm1na2lFZ1G5vouDZ1SnwMi2dkBMclMlk8I5MULckh45jvoWBm0cAnwGeBEuBdYIVzbmuP/VKB/wDigG8oFHpRV9E5BrF7Dbg2yJwVHIO4DCYvUkAMgnOOkiMNoe6m9XuO8PGhGpyDKIOpmYnMCqQwKzuJ3EAyuYFkZgeSmZqRqBnYMuaNhlA4C/i+c+4vgs//HsA593977Hcf8CrwbeDbCoUB1FXCRy94AbHrz8GAyO0cg5iyWAFxHGoaW3h/31He2+eNSeypqGN3RV1o3gRAbLQxPTOJWcGg6AiL3EAyk9MSNCNbxoTBhkI428tTgf1dnpcAZ3TdwcwWA9Odcy+Y2bfDWMv4kZwNp/2Vd6s/HAyI5+HNB+GN+yFjZmdATC1UQAwgNSGWc07K4ZyTckLbnHNU1Dazp7KO3eV17K7sDIs3dlbQ2NIe2jc+Jorc7GRyA0mdYZGdzKxAMjmp8TpVVsaccIZCb/8aQs0SM4sCfgLcMOCBzFYCKwFmzJgxTOWNA0lZ3uzowuu9gPj4RW+Q+q2feYvxpc+Aecth/hUw9TQFxCCZGTmp8eSkxnN6bla319rbHYdqGtkdDAkvLOrZUVbLHz8qC82lAEiOiw61LGYFgyI34N1nJsUqMGRU8q37yMzSgZ1AbfAtk4DDwPL+upAivvtoMBqOwEcvei2InX+E9hZIm9Y5SD21CKLURz7c2todpUcb2FXR2bLYU+ndlxxpoK29899aemJsMCySQkHRERppCeN/qXUZeaMqRpYeAAANYklEQVRhTCEGb6D5AuBTvIHmLzvntvSx/5/QmMLwazgKH7/kjUHs/CO0NUPaVC8g8i+CyQu9FoeEVXNrOyVH6jtbGJUdLY16Sqsa6PrPMDkumonpCUxMTWBiWnzo8aT04PO0BCakJmhNKDkuvo8pOOdazewbwCt4p6Q+6pzbYmZ3A+udc6vD9dnSRWIGLFrh3Rqr4OOXvYB49xGvmwm8bqbJBV5ATArep05Sd9MwiouJYnZOCrNzUo55rbGljX2H69lVXsfeyjoOVTdxqLqRQ9WNrN97hLLqJprb2o95X3ZyHBPSvKCYlJbAhLQEJqV1BsfEtASyk+M0EC7HRZPXIlVjNXy6AQ5uhgOb4MBmqNxBaNgnOad7SEwu8E6DVVCMOOccR+pbOFTdyMHqRsqqGzlU3RR6fDD4vKK2iZ7/nGOijAmp8QO2PFLiYzTGMc753n0ULgqFMGqqhUMfdobEgU1Qvg3ag6dnxqfDpFM7Q2LyQsjOh2hN+hoNWtraqaht4mBVY7fWRtfHB6sbqWlsPea9SXHRwdZGZytjQnCwPSc1ngmpCeSkxpOWoPAYqxQKMjxam6Bsa2dIHNwMBz+EVm9pa2ISvOU3unY/TZgHsVpraLSqb27tERq9tzyaW4/tsoqPiQqGRPew6Pk8kBKnCX+jjEJBwqet1etq6giJjpZFU5X3elSMtyx41+6nSQsgPtXfumXQnHNUN7ZSXtNIWU0T5cFbWei+MfT8aHC12q7MICsp7piWxoTUeCakxZOTEs+ENG+blhcZGQoFGVnOwZE93UPiwCaoKwvuYN41qicVdGlVLPQm48mY1tTaRkVtM2XVjT2CoyNMvO3ltU3d5nF0SIqL7rW10Rko3jYNmg+NQkFGh5qDXUJioxcaR/d1vp42DXJO8pbqyJjp3WfmQuZMSMz0qWgJh/Z2R1VDS6+tjZ7Pexv3iI4yAilx3VsdqfHkBMc/vFZIAoGUOOJjdD2Nnnw/JVUE8E5tTZ0EJ/1F57b6w3Dwg87up8odULoRGg53f29Cepeg6BIYGbmQMR1i4kfu55Ahi4oyMpPjyEyO4+RJ/XclNra0HRMUZdXe87IabzB9c0kVlXXHnnEF3oWXOloYXnB0Pg61SIJnXUl3ainI6NFYBUf2wtG9XlfUkY77PV7roq2py84GaVN6b2Fk5kLKRJ0+GwFa29qprGumrLqJ8trGYHAEw6O6qdt4SG9zPZLiokPh4QXHseMfE1ITyEiMHfNdV2opyNiTkB4cbyg49rX2dqg92CMogo93/QlqSrvvH5MQDIuuLYwurQ4Neo8LMdFRoVNoIb3P/ZxzHK1voby2e4uj6+OtpdX8qbqRuua2Y95vBqnxMaQlxpKWEEtaYgypCZ2PvftY0hK675MW3CclIWbMXNRJoSBjQ1SU1zJImwIzzzr29ZZGqNrfGRhdg2PfW9BU3X3/pOxju6bSpnpdXSmTvNe1PtS4YdbZdXXSxP7/IKhrau3ssgq2OI7WN1Pd2Ep1QwvVjS1UN7Sy/3A9NcFtNU3HjoH01BEqqb0GRy/bujxPiY8ZsVN8FQoyPsQmQCDfu/XknLdIYM8WxpG9UPo+bFvdOUGvQ1SMFw6pEyF1cmdYpE4KPg9uT8xSeIwzyfExJMfHkBtIHvR72todtY2tVDe2UBUMjppQiHQPE+++hdKjDXx0sCUUKgP15CfHRXPLObP51oUnDfEn7J9CQcY/M2/Rv6Qs7xoTPbW1et1P1Qe8Lqqag1BzwLtmds0BqNzpXTO74cix742KDQbGxGMDIxQkk73P1hjHuBUdZaQnxZKeFMv0E3h/e7ujtjkYHsHgqOklTOZP6buLbLgoFESiYyBjhnfrT0tjl9DoEh61HeGxA/ashcajvXxGXJfg6KPVkTrZOw1X4RFxoqIsNP6Az2diKxREBis2oXPQuj8tDV5gdIRFzxCp2A67X/fOtuopOs7rkkrK7mzddHue3eV5pncfn6YgkWGjUBAZbrGJkDXLu/WnIzx6tjjqD3u3hsNQtq3zsTv2lErAG/9IzOoSGpl9hEiX1xMyNBYivVIoiPhlsOEB3im5TVWdgVFf6QVFfWWP54e9MZD973jPew6gd7CozvDo2fLoCJiEDO96HAnpnY/jUhUm45xCQWQsiAr+Ek/M9NaQGgznvFNxO1oa/QXK0b1Q+p73uK2572NaVDAkugRFQjA4Oh73DJKEDK/u+DQtsz4G6L+QyHhl1vkLnEG0RsALkuY6LzQaq7zLuTYe7bzvbVt1aefj/gIFvJbGoIMkuC0+1bvFJquVMgIUCiLSyQziU7zb8XLOGyfpKzx623Z4V+fjlvqBiusMiF5vaYPbFpeqFks/9M2IyPAwg7gk75Y25fjf39rsBUfPIGmq6eVW7d03VkPVp53bm2sG91mxSYMMleD2uGTvPXHJxz6OSRxXLRiFgoiMDjFxkJLj3U5Uezs013q3ngHSW6h0vR3Z0317X4P0vekIib6CY7Cv93wcHTfipxsrFERk/IiKgoQ07zYUzkFrY5cWSK031tJcDy11wcd1XpdXf4/rD3fZP/jevk4t7o1FQ1yK1/qKTYKiG+HsbwztZxuAQkFEpCcz75Th2ERImTB8x+0Im27hUu+FzkAB01znzYoPM4WCiMhI6Ro2jM5L0Y6f0RERERmysIaCmV1sZh+b2Q4zu6uX1+80s61mttnM/mBmM8NZj4iI9C9soWBm0cCDwCXAPGCFmc3rsdv7QJFzrgB4GvhxuOoREZGBhbOlsATY4Zzb5ZxrBlYBl3XdwTn3mnOuY8bKW8C0MNYjIiIDCGcoTAX2d3leEtzWl5uAl8JYj4iIDCCcZx/1NuOi1wvOmdl1QBFwbh+vrwRWAsyYMcCFUERE5ISFs6VQAt2uTDcNKO25k5ldCPwPYLlzrqm3AznnHnLOFTnninJyhjDbUURE+hXOUHgXyDezWWYWB1wDrO66g5ktBn6JFwhlYaxFREQGwZzrtUdneA5udilwHxANPOqc+6GZ3Q2sd86tNrNXgVOBA8G37HPOLR/gmOXA3hMsKQBUnOB7xyN9H93p++ik76K78fB9zHTODdjVEtZQGG3MbL1zrsjvOkYLfR/d6fvopO+iu0j6PjSjWUREQhQKIiISEmmh8JDfBYwy+j660/fRSd9FdxHzfUTUmIKIiPQv0loKIiLSj4gJhYFWbI0kZjbdzF4zs21mtsXMvul3TX4zs2gze9/MXvC7Fr+ZWYaZPW1mHwX/HznL75r8Ymb/Lfhv5EMze9LMEvyuKdwiIhQGuWJrJGkF/sY5Nxc4E/h6hH8fAN8EtvldxChxP/Cyc+4UYCER+r2Y2VTgDryVnBfgzbe6xt+qwi8iQoFBrNgaSZxzB5xz7wUf1+D9o+9vscJxzcymAZ8DHvG7Fr+ZWRpwDvArAOdcs3PuqL9V+SoGSDSzGCCJXpbqGW8iJRSOd8XWiGFmucBi4G1/K/HVfcDfAsdxRfVxazZQDjwW7E57xMyS/S7KD865T4F/BPbhrbpQ5Zz7T3+rCr9ICYVBr9gaScwsBXgG+JZzrtrvevxgZp8HypxzG/yuZZSIAQqBnzvnFgN1QESOwZlZJl6PwixgCpAcXNF5XIuUUBjUiq2RxMxi8QLhCefc7/yux0dLgeVmtgevW/EzZvZrf0vyVQlQ4pzraDk+jRcSkehCYLdzrtw51wL8Djjb55rCLlJCYcAVWyOJmRlen/E259y9ftfjJ+fc3zvnpjnncvH+v/ijc27c/zXYF+fcQWC/mZ0c3HQBsNXHkvy0DzjTzJKC/2YuIAIG3cN5kZ1RwznXambfAF6hc8XWLT6X5aelwFeAD8xsY3Dbd5xzL/pYk4wetwNPBP+A2gV81ed6fOGce9vMngbewztj730iYGazZjSLiEhIpHQfiYjIICgUREQkRKEgIiIhCgUREQlRKIiISIhCQSTIzNrMbGOX27DN5DWzXDP7cLiOJxIuETFPQWSQGpxzi/wuQsRPaimIDMDM9pjZj8zsneAtL7h9ppn9wcw2B+9nBLdPNLNnzWxT8NaxNEK0mT0cXJ//P80sMbj/HWa2NXicVT79mCKAQkGkq8Qe3UdXd3mt2jm3BPhnvFVVCT7+V+dcAfAE8EBw+wPAn51zC/HWDeqYPZ8PPOicmw8cBb4U3H4XsDh4nFvD9cOJDIZmNIsEmVmtcy6ll+17gM8453YFFxI86JzLNrMKYLJzriW4/YBzLmBm5cA051xTl2PkAv/lnMsPPv87INY597/N7GWgFngOeM45VxvmH1WkT2opiAyO6+NxX/v0pqnL4zY6x/Q+h3dlwNOADcELuoj4QqEgMjhXd7l/M/h4HZ2XZ7wWWBt8/AfgNghd+zmtr4OaWRQw3Tn3Gt6FfjKAY1orIiNFf5GIdErssmoseNcp7jgtNd7M3sb7Q2pFcNsdwKNm9t/xrlbWsZroN4GHzOwmvBbBbXhX7upNNPBrM0vHuxjUTyL88pfiM40piAwgOKZQ5Jyr8LsWkXBT95GIiISopSAiIiFqKYiISIhCQUREQhQKIiISolAQEZEQhYKIiIQoFEREJOT/A7wSrxFkre0EAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_history(network_history):\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(network_history.history['loss'])\n",
    "    plt.plot(network_history.history['val_loss'])\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.plot(network_history.history['acc'])\n",
    "    plt.plot(network_history.history['val_acc'])\n",
    "    plt.legend(['Training', 'Validation'], loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "plot_history(network_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 673,802\n",
      "Trainable params: 671,754\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Input Tensors:  Tensor(\"dense_3_input:0\", shape=(?, 784), dtype=float32)\n",
      "\n",
      "Layers - Network Configuration:\n",
      "\n",
      "dense_3 True\n",
      "Layer Configuration:\n",
      "{'name': 'dense_3', 'trainable': True, 'batch_input_shape': (None, 784), 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "----------------------------------------\n",
      "batch_normalization_1 True\n",
      "Layer Configuration:\n",
      "{'name': 'batch_normalization_1', 'trainable': True, 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}\n",
      "----------------------------------------\n",
      "dropout_17 True\n",
      "Layer Configuration:\n",
      "{'name': 'dropout_17', 'trainable': True, 'rate': 0.2, 'noise_shape': None, 'seed': None}\n",
      "----------------------------------------\n",
      "dense_4 True\n",
      "Layer Configuration:\n",
      "{'name': 'dense_4', 'trainable': True, 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "----------------------------------------\n",
      "batch_normalization_2 True\n",
      "Layer Configuration:\n",
      "{'name': 'batch_normalization_2', 'trainable': True, 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}\n",
      "----------------------------------------\n",
      "dropout_18 True\n",
      "Layer Configuration:\n",
      "{'name': 'dropout_18', 'trainable': True, 'rate': 0.2, 'noise_shape': None, 'seed': None}\n",
      "----------------------------------------\n",
      "dense_5 True\n",
      "Layer Configuration:\n",
      "{'name': 'dense_5', 'trainable': True, 'units': 10, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "----------------------------------------\n",
      "Model Output Tensors:  Tensor(\"dense_5/Softmax:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print('Model Input Tensors: ', model.input, end='\\n\\n')\n",
    "print('Layers - Network Configuration:', end='\\n\\n')\n",
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable)\n",
    "    print('Layer Configuration:')\n",
    "    print(layer.get_config(), end='\\n{}\\n'.format('----'*10))\n",
    "print('Model Output Tensors: ', model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You called `set_weights(weights)` on layer \"dropout_19\" with a  weight list of length 4, but the layer was expecting 0 weights. Provided weights: [array([0.9992495 , 0.99866   , 1.0011771 , 0.9998...",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-160-d212d77078ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_truncated\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m model_truncated.compile(loss='categorical_crossentropy', optimizer=SGD(), \n",
      "\u001b[1;32m~\\Miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m   1045\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m                              \u001b[1;34m' weights. Provided weights: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1047\u001b[1;33m                              str(weights)[:50] + '...')\n\u001b[0m\u001b[0;32m   1048\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You called `set_weights(weights)` on layer \"dropout_19\" with a  weight list of length 4, but the layer was expecting 0 weights. Provided weights: [array([0.9992495 , 0.99866   , 1.0011771 , 0.9998..."
     ]
    }
   ],
   "source": [
    "model_truncated = Sequential()\n",
    "model_truncated.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model_truncated.add(Dropout(0.2))\n",
    "model_truncated.add(Dense(512, activation='relu'))\n",
    "\n",
    "for i, layer in enumerate(model_truncated.layers):\n",
    "    layer.set_weights(model.layers[i].get_weights())\n",
    "\n",
    "model_truncated.compile(loss='categorical_crossentropy', optimizer=SGD(), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(model_truncated.layers[0].get_weights()[0] == model.layers[0].get_weights()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_features = model_truncated.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "X_tsne = tsne.fit_transform(hidden_features[:1000]) ## Reduced for computational issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_map = np.argmax(y_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tsne.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(colors_map==6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.array([x for x in 'b-g-r-c-m-y-k-purple-coral-lime'.split('-')])\n",
    "colors_map = colors_map[:1000]\n",
    "plt.figure(figsize=(10,10))\n",
    "for cl in range(n_classes):\n",
    "    indices = np.where(colors_map==cl)\n",
    "    plt.scatter(X_tsne[indices,0], X_tsne[indices, 1], c=colors[cl], label=cl)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# python/tf/keras exercises basic Matrix Factorisation in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://nipunbatra.github.io/blog/2017/recommend-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE LOAD DATASET\n",
    "dataset = pd.read_csv(r'C:\\Users\\tensorflow\\Desktop\\iloraz_inteligencji\\python cwiczenia\\data\\ml-100k\\u.data',sep='\\t',names=\"user_id,item_id,rating,timestamp\".split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.user_id.unique()), len(dataset.item_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.user_id = dataset.user_id.astype('category').cat.codes.values\n",
    "dataset.item_id = dataset.item_id.astype('category').cat.codes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195</td>\n",
       "      <td>241</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>376</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>243</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165</td>\n",
       "      <td>345</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      195      241       3  881250949\n",
       "1      185      301       3  891717742\n",
       "2       21      376       1  878887116\n",
       "3      243       50       2  880606923\n",
       "4      165      345       1  886397596"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train test data 20 %\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test = train_test_split(dataset, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from IPython.display import SVG\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users, n_movies = len(dataset.user_id.unique()), len(dataset.item_id.unique())\n",
    "n_latent_factors = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_input = keras.layers.Input(shape=[1], name='Item')\n",
    "movie_embedding = keras.layers.Embedding(n_movies+1, n_latent_factors, name='Movie-Embedding')(movie_input)\n",
    "movie_vec = keras.layers.Flatten(name='FlattenMovies')(movie_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'User_1:0' shape=(?, 1) dtype=float32>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = keras.layers.Input(shape=[1],name='User')\n",
    "user_vec = keras.layers.Flatten(name='FlattenUsers')(keras.layers.Embedding(n_users + 1, n_latent_factors,name='User-Embedding')(user_input))\n",
    "user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = keras.layers.merge.dot([movie_vec, user_vec],axes=-1,name='DotProduct')\n",
    "model = keras.Model([user_input, movie_input], prod)\n",
    "model.compile('adam', 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"304pt\" viewBox=\"0.00 0.00 679.50 304.00\" width=\"680pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 300)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-300 675.5,-300 675.5,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 279643472 -->\n",
       "<g class=\"node\" id=\"node1\"><title>279643472</title>\n",
       "<polygon fill=\"none\" points=\"48,-249.5 48,-295.5 283,-295.5 283,-249.5 48,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"102.5\" y=\"-268.8\">Item: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"157,-249.5 157,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"185\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"157,-272.5 213,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"185\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"213,-249.5 213,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248\" y=\"-280.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"213,-272.5 283,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248\" y=\"-257.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 276432096 -->\n",
       "<g class=\"node\" id=\"node3\"><title>276432096</title>\n",
       "<polygon fill=\"none\" points=\"0,-166.5 0,-212.5 331,-212.5 331,-166.5 0,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"95.5\" y=\"-185.8\">Movie-Embedding: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"191,-166.5 191,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"219\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"191,-189.5 247,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"219\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"247,-166.5 247,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"289\" y=\"-197.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"247,-189.5 331,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"289\" y=\"-174.3\">(None, 1, 5)</text>\n",
       "</g>\n",
       "<!-- 279643472&#45;&gt;276432096 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>279643472-&gt;276432096</title>\n",
       "<path d=\"M165.5,-249.366C165.5,-241.152 165.5,-231.658 165.5,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"169,-222.607 165.5,-212.607 162,-222.607 169,-222.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 279643864 -->\n",
       "<g class=\"node\" id=\"node2\"><title>279643864</title>\n",
       "<polygon fill=\"none\" points=\"392.5,-249.5 392.5,-295.5 628.5,-295.5 628.5,-249.5 392.5,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"447.5\" y=\"-268.8\">User: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"502.5,-249.5 502.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"530.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"502.5,-272.5 558.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"530.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"558.5,-249.5 558.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"593.5\" y=\"-280.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"558.5,-272.5 628.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"593.5\" y=\"-257.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 279936696 -->\n",
       "<g class=\"node\" id=\"node4\"><title>279936696</title>\n",
       "<polygon fill=\"none\" points=\"349.5,-166.5 349.5,-212.5 671.5,-212.5 671.5,-166.5 349.5,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"440.5\" y=\"-185.8\">User-Embedding: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"531.5,-166.5 531.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"559.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"531.5,-189.5 587.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"559.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"587.5,-166.5 587.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"629.5\" y=\"-197.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"587.5,-189.5 671.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"629.5\" y=\"-174.3\">(None, 1, 5)</text>\n",
       "</g>\n",
       "<!-- 279643864&#45;&gt;279936696 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>279643864-&gt;279936696</title>\n",
       "<path d=\"M510.5,-249.366C510.5,-241.152 510.5,-231.658 510.5,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"514,-222.607 510.5,-212.607 507,-222.607 514,-222.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 276432320 -->\n",
       "<g class=\"node\" id=\"node5\"><title>276432320</title>\n",
       "<polygon fill=\"none\" points=\"50.5,-83.5 50.5,-129.5 330.5,-129.5 330.5,-83.5 50.5,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.5\" y=\"-102.8\">FlattenMovies: Flatten</text>\n",
       "<polyline fill=\"none\" points=\"190.5,-83.5 190.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"190.5,-106.5 246.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"246.5,-83.5 246.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288.5\" y=\"-114.3\">(None, 1, 5)</text>\n",
       "<polyline fill=\"none\" points=\"246.5,-106.5 330.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288.5\" y=\"-91.3\">(None, 5)</text>\n",
       "</g>\n",
       "<!-- 276432096&#45;&gt;276432320 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>276432096-&gt;276432320</title>\n",
       "<path d=\"M172.331,-166.366C174.894,-158.062 177.861,-148.451 180.644,-139.434\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"184.072,-140.194 183.677,-129.607 177.383,-138.13 184.072,-140.194\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 279642856 -->\n",
       "<g class=\"node\" id=\"node6\"><title>279642856</title>\n",
       "<polygon fill=\"none\" points=\"362,-83.5 362,-129.5 633,-129.5 633,-83.5 362,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"427.5\" y=\"-102.8\">FlattenUsers: Flatten</text>\n",
       "<polyline fill=\"none\" points=\"493,-83.5 493,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"521\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"493,-106.5 549,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"521\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"549,-83.5 549,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"591\" y=\"-114.3\">(None, 1, 5)</text>\n",
       "<polyline fill=\"none\" points=\"549,-106.5 633,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"591\" y=\"-91.3\">(None, 5)</text>\n",
       "</g>\n",
       "<!-- 279936696&#45;&gt;279642856 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>279936696-&gt;279642856</title>\n",
       "<path d=\"M506.948,-166.366C505.629,-158.152 504.106,-148.658 502.672,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"506.089,-138.926 501.048,-129.607 499.177,-140.035 506.089,-138.926\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 279935912 -->\n",
       "<g class=\"node\" id=\"node7\"><title>279935912</title>\n",
       "<polygon fill=\"none\" points=\"190.5,-0.5 190.5,-46.5 496.5,-46.5 496.5,-0.5 190.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"245.5\" y=\"-19.8\">DotProduct: Dot</text>\n",
       "<polyline fill=\"none\" points=\"300.5,-0.5 300.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"328.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"300.5,-23.5 356.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"328.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"356.5,-0.5 356.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"426.5\" y=\"-31.3\">[(None, 5), (None, 5)]</text>\n",
       "<polyline fill=\"none\" points=\"356.5,-23.5 496.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"426.5\" y=\"-8.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 276432320&#45;&gt;279935912 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>276432320-&gt;279935912</title>\n",
       "<path d=\"M232.308,-83.3664C250.945,-73.4998 273.067,-61.7881 292.652,-51.4194\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"294.542,-54.379 301.743,-46.6068 291.267,-48.1925 294.542,-54.379\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 279642856&#45;&gt;279935912 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>279642856-&gt;279935912</title>\n",
       "<path d=\"M455.419,-83.3664C436.575,-73.4551 414.192,-61.682 394.413,-51.2787\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"396.01,-48.1643 385.53,-46.6068 392.751,-54.3596 396.01,-48.1643\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model,  show_shapes=True, show_layer_names=True, rankdir='HB').create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Item (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "User (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Movie-Embedding (Embedding)     (None, 1, 5)         8415        Item[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "User-Embedding (Embedding)      (None, 1, 5)         4720        User[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "FlattenMovies (Flatten)         (None, 5)            0           Movie-Embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FlattenUsers (Flatten)          (None, 5)            0           User-Embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "DotProduct (Dot)                (None, 1)            0           FlattenMovies[0][0]              \n",
      "                                                                 FlattenUsers[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 13,135\n",
      "Trainable params: 13,135\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit([x_train.user_id, x_train.item_id], x_train.rating, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Train Error')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(history.history['loss']).plot(logy=True)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Train Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = np.round(model.predict([x_test.user_id, x_test.item_id]),0)\n",
    "y_true = x_test.rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7122"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_true, y_hat)\n",
    "# n_latent_factors = 10  0.77525\n",
    "# n_latent_factors = 5   0.7122\n",
    "# n_latent_factors = 3   0.6915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1683.000000</td>\n",
       "      <td>1683.000000</td>\n",
       "      <td>1683.000000</td>\n",
       "      <td>1683.000000</td>\n",
       "      <td>1683.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.631815</td>\n",
       "      <td>-0.655838</td>\n",
       "      <td>0.738319</td>\n",
       "      <td>0.756361</td>\n",
       "      <td>-0.728284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.632339</td>\n",
       "      <td>0.454278</td>\n",
       "      <td>0.454777</td>\n",
       "      <td>0.469221</td>\n",
       "      <td>0.491661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.117716</td>\n",
       "      <td>-2.312297</td>\n",
       "      <td>-0.733359</td>\n",
       "      <td>-1.603890</td>\n",
       "      <td>-2.499438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.102589</td>\n",
       "      <td>-0.953371</td>\n",
       "      <td>0.445321</td>\n",
       "      <td>0.452624</td>\n",
       "      <td>-1.075903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.654682</td>\n",
       "      <td>-0.624554</td>\n",
       "      <td>0.738452</td>\n",
       "      <td>0.771737</td>\n",
       "      <td>-0.740372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.169846</td>\n",
       "      <td>-0.359019</td>\n",
       "      <td>1.031004</td>\n",
       "      <td>1.060018</td>\n",
       "      <td>-0.412569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.291163</td>\n",
       "      <td>1.013850</td>\n",
       "      <td>2.589378</td>\n",
       "      <td>2.812141</td>\n",
       "      <td>1.520030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1            2            3            4\n",
       "count  1683.000000  1683.000000  1683.000000  1683.000000  1683.000000\n",
       "mean     -0.631815    -0.655838     0.738319     0.756361    -0.728284\n",
       "std       0.632339     0.454278     0.454777     0.469221     0.491661\n",
       "min      -3.117716    -2.312297    -0.733359    -1.603890    -2.499438\n",
       "25%      -1.102589    -0.953371     0.445321     0.452624    -1.075903\n",
       "50%      -0.654682    -0.624554     0.738452     0.771737    -0.740372\n",
       "75%      -0.169846    -0.359019     1.031004     1.060018    -0.412569\n",
       "max       1.291163     1.013850     2.589378     2.812141     1.520030"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_embedding_learnt = model.get_layer(name='Movie-Embedding').get_weights()[0]\n",
    "pd.DataFrame(movie_embedding_learnt).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>944.000000</td>\n",
       "      <td>944.000000</td>\n",
       "      <td>944.000000</td>\n",
       "      <td>944.000000</td>\n",
       "      <td>944.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.794663</td>\n",
       "      <td>-0.901399</td>\n",
       "      <td>0.865097</td>\n",
       "      <td>0.889151</td>\n",
       "      <td>-0.893582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.648439</td>\n",
       "      <td>0.471091</td>\n",
       "      <td>0.519031</td>\n",
       "      <td>0.537172</td>\n",
       "      <td>0.521031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.108999</td>\n",
       "      <td>-2.980661</td>\n",
       "      <td>-0.779874</td>\n",
       "      <td>-0.916762</td>\n",
       "      <td>-2.716016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.238986</td>\n",
       "      <td>-1.218671</td>\n",
       "      <td>0.521040</td>\n",
       "      <td>0.565044</td>\n",
       "      <td>-1.233803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.840762</td>\n",
       "      <td>-0.912994</td>\n",
       "      <td>0.863694</td>\n",
       "      <td>0.878111</td>\n",
       "      <td>-0.895066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.449797</td>\n",
       "      <td>-0.616277</td>\n",
       "      <td>1.199968</td>\n",
       "      <td>1.208972</td>\n",
       "      <td>-0.582314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.035370</td>\n",
       "      <td>1.443757</td>\n",
       "      <td>2.706756</td>\n",
       "      <td>3.064734</td>\n",
       "      <td>0.785970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0           1           2           3           4\n",
       "count  944.000000  944.000000  944.000000  944.000000  944.000000\n",
       "mean    -0.794663   -0.901399    0.865097    0.889151   -0.893582\n",
       "std      0.648439    0.471091    0.519031    0.537172    0.521031\n",
       "min     -3.108999   -2.980661   -0.779874   -0.916762   -2.716016\n",
       "25%     -1.238986   -1.218671    0.521040    0.565044   -1.233803\n",
       "50%     -0.840762   -0.912994    0.863694    0.878111   -0.895066\n",
       "75%     -0.449797   -0.616277    1.199968    1.208972   -0.582314\n",
       "max      3.035370    1.443757    2.706756    3.064734    0.785970"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embedding_learnt = model.get_layer(name='User-Embedding').get_weights()[0]\n",
    "pd.DataFrame(user_embedding_learnt).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.constraints import non_neg\n",
    "movie_input = keras.layers.Input(shape=[1],name='Item')\n",
    "movie_embedding = keras.layers.Embedding(n_movies + 1, n_latent_factors, name='NonNegMovie-Embedding', embeddings_constraint=non_neg())(movie_input)\n",
    "movie_vec = keras.layers.Flatten(name='FlattenMovies')(movie_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = keras.layers.Input(shape=[1],name='User')\n",
    "user_vec = keras.layers.Flatten(name='FlattenUsers')(keras.layers.Embedding(n_users + 1, n_latent_factors,name='NonNegUser-Embedding',embeddings_constraint=non_neg())(user_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = keras.layers.merge.dot([movie_vec, user_vec], axes=-1,name='DotProduct')\n",
    "model = keras.Model([user_input, movie_input], prod)\n",
    "model.compile('adam', 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_nonneg = model.fit([x_train.user_id,x_train.item_id], x_train.rating, epochs=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1683.000000</td>\n",
       "      <td>1683.000000</td>\n",
       "      <td>1683.000000</td>\n",
       "      <td>1683.000000</td>\n",
       "      <td>1683.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.674588</td>\n",
       "      <td>0.673573</td>\n",
       "      <td>0.673093</td>\n",
       "      <td>0.675275</td>\n",
       "      <td>0.674736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.212079</td>\n",
       "      <td>0.213447</td>\n",
       "      <td>0.211516</td>\n",
       "      <td>0.213305</td>\n",
       "      <td>0.212626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.546561</td>\n",
       "      <td>0.542761</td>\n",
       "      <td>0.546005</td>\n",
       "      <td>0.544801</td>\n",
       "      <td>0.549431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.712057</td>\n",
       "      <td>0.710165</td>\n",
       "      <td>0.712138</td>\n",
       "      <td>0.711634</td>\n",
       "      <td>0.714001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.833296</td>\n",
       "      <td>0.832640</td>\n",
       "      <td>0.830650</td>\n",
       "      <td>0.833183</td>\n",
       "      <td>0.834146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.112228</td>\n",
       "      <td>1.070678</td>\n",
       "      <td>1.072184</td>\n",
       "      <td>1.087662</td>\n",
       "      <td>1.092998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0            1            2            3            4\n",
       "count  1683.000000  1683.000000  1683.000000  1683.000000  1683.000000\n",
       "mean      0.674588     0.673573     0.673093     0.675275     0.674736\n",
       "std       0.212079     0.213447     0.211516     0.213305     0.212626\n",
       "min      -0.000000    -0.000000    -0.000000    -0.000000    -0.000000\n",
       "25%       0.546561     0.542761     0.546005     0.544801     0.549431\n",
       "50%       0.712057     0.710165     0.712138     0.711634     0.714001\n",
       "75%       0.833296     0.832640     0.830650     0.833183     0.834146\n",
       "max       1.112228     1.070678     1.072184     1.087662     1.092998"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_embedding_learnt = model.get_layer(name='NonNegMovie-Embedding').get_weights()[0]\n",
    "pd.DataFrame(movie_embedding_learnt).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use that to build recomendation system\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_latent_factors_user = 10\n",
    "n_latent_factors_movie = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_input = keras.layers.Input(shape=[1],name='Item')\n",
    "movie_embedding = keras.layers.Embedding(n_movies + 1, n_latent_factors_movie, name='Movie-Embedding')(movie_input)\n",
    "movie_vec = keras.layers.Flatten(name='FlattenMovies')(movie_embedding)\n",
    "movie_vec = keras.layers.Dropout(0.2)(movie_vec)\n",
    "\n",
    "user_input = keras.layers.Input(shape=[1],name='User')\n",
    "user_vec = keras.layers.Flatten(name='FlattenUsers')(keras.layers.Embedding(n_users + 1, n_latent_factors_user,name='User-Embedding')(user_input))\n",
    "user_vec = keras.layers.Dropout(0.2)(user_vec)\n",
    "\n",
    "concat = keras.layers.concatenate([movie_vec, user_vec], axis=-1,name='Concat')\n",
    "concat_dropout = keras.layers.Dropout(0.2)(concat)\n",
    "dense = keras.layers.Dense(200,name='FullyConnected')(concat)\n",
    "dropout_1 = keras.layers.Dropout(0.2,name='Dropout')(dense)\n",
    "dense_2 = keras.layers.Dense(100,name='FullyConnected-1')(concat)\n",
    "dropout_2 = keras.layers.Dropout(0.2,name='Dropout')(dense_2)\n",
    "dense_3 = keras.layers.Dense(50,name='FullyConnected-2')(dense_2)\n",
    "dropout_3 = keras.layers.Dropout(0.2,name='Dropout')(dense_3)\n",
    "dense_4 = keras.layers.Dense(20,name='FullyConnected-3', activation='relu')(dense_3)\n",
    "\n",
    "result = keras.layers.Dense(1, activation='relu',name='Activation')(dense_4)\n",
    "adam = Adam(lr=0.005)\n",
    "model = keras.Model([user_input, movie_input], result)\n",
    "model.compile(optimizer=adam,loss= 'mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"719pt\" viewBox=\"0.00 0.00 693.50 719.00\" width=\"694pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 715)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-715 689.5,-715 689.5,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 849889152 -->\n",
       "<g class=\"node\" id=\"node1\"><title>849889152</title>\n",
       "<polygon fill=\"none\" points=\"51.5,-664.5 51.5,-710.5 286.5,-710.5 286.5,-664.5 51.5,-664.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"106\" y=\"-683.8\">Item: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"160.5,-664.5 160.5,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.5\" y=\"-695.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"160.5,-687.5 216.5,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.5\" y=\"-672.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"216.5,-664.5 216.5,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"251.5\" y=\"-695.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"216.5,-687.5 286.5,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"251.5\" y=\"-672.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 849628240 -->\n",
       "<g class=\"node\" id=\"node3\"><title>849628240</title>\n",
       "<polygon fill=\"none\" points=\"0,-581.5 0,-627.5 338,-627.5 338,-581.5 0,-581.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"95.5\" y=\"-600.8\">Movie-Embedding: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"191,-581.5 191,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"219\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"191,-604.5 247,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"219\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"247,-581.5 247,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292.5\" y=\"-612.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"247,-604.5 338,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292.5\" y=\"-589.3\">(None, 1, 10)</text>\n",
       "</g>\n",
       "<!-- 849889152&#45;&gt;849628240 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>849889152-&gt;849628240</title>\n",
       "<path d=\"M169,-664.366C169,-656.152 169,-646.658 169,-637.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"172.5,-637.607 169,-627.607 165.5,-637.607 172.5,-637.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 849832368 -->\n",
       "<g class=\"node\" id=\"node2\"><title>849832368</title>\n",
       "<polygon fill=\"none\" points=\"403,-664.5 403,-710.5 639,-710.5 639,-664.5 403,-664.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"458\" y=\"-683.8\">User: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"513,-664.5 513,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"541\" y=\"-695.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"513,-687.5 569,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"541\" y=\"-672.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"569,-664.5 569,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"604\" y=\"-695.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"569,-687.5 639,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"604\" y=\"-672.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 849628520 -->\n",
       "<g class=\"node\" id=\"node4\"><title>849628520</title>\n",
       "<polygon fill=\"none\" points=\"356.5,-581.5 356.5,-627.5 685.5,-627.5 685.5,-581.5 356.5,-581.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"447.5\" y=\"-600.8\">User-Embedding: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"538.5,-581.5 538.5,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"566.5\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"538.5,-604.5 594.5,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"566.5\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"594.5,-581.5 594.5,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"640\" y=\"-612.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"594.5,-604.5 685.5,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"640\" y=\"-589.3\">(None, 1, 10)</text>\n",
       "</g>\n",
       "<!-- 849832368&#45;&gt;849628520 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>849832368-&gt;849628520</title>\n",
       "<path d=\"M521,-664.366C521,-656.152 521,-646.658 521,-637.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"524.5,-637.607 521,-627.607 517.5,-637.607 524.5,-637.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 849833712 -->\n",
       "<g class=\"node\" id=\"node5\"><title>849833712</title>\n",
       "<polygon fill=\"none\" points=\"50.5,-498.5 50.5,-544.5 337.5,-544.5 337.5,-498.5 50.5,-498.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.5\" y=\"-517.8\">FlattenMovies: Flatten</text>\n",
       "<polyline fill=\"none\" points=\"190.5,-498.5 190.5,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218.5\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"190.5,-521.5 246.5,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218.5\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"246.5,-498.5 246.5,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292\" y=\"-529.3\">(None, 1, 10)</text>\n",
       "<polyline fill=\"none\" points=\"246.5,-521.5 337.5,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292\" y=\"-506.3\">(None, 10)</text>\n",
       "</g>\n",
       "<!-- 849628240&#45;&gt;849833712 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>849628240-&gt;849833712</title>\n",
       "<path d=\"M175.831,-581.366C178.394,-573.062 181.361,-563.451 184.144,-554.434\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"187.572,-555.194 187.177,-544.607 180.883,-553.13 187.572,-555.194\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 849628856 -->\n",
       "<g class=\"node\" id=\"node6\"><title>849628856</title>\n",
       "<polygon fill=\"none\" points=\"369,-498.5 369,-544.5 647,-544.5 647,-498.5 369,-498.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"434.5\" y=\"-517.8\">FlattenUsers: Flatten</text>\n",
       "<polyline fill=\"none\" points=\"500,-498.5 500,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"528\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"500,-521.5 556,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"528\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"556,-498.5 556,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"601.5\" y=\"-529.3\">(None, 1, 10)</text>\n",
       "<polyline fill=\"none\" points=\"556,-521.5 647,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"601.5\" y=\"-506.3\">(None, 10)</text>\n",
       "</g>\n",
       "<!-- 849628520&#45;&gt;849628856 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>849628520-&gt;849628856</title>\n",
       "<path d=\"M517.448,-581.366C516.129,-573.152 514.606,-563.658 513.172,-554.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"516.589,-553.926 511.548,-544.607 509.677,-555.035 516.589,-553.926\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 849628184 -->\n",
       "<g class=\"node\" id=\"node7\"><title>849628184</title>\n",
       "<polygon fill=\"none\" points=\"72,-415.5 72,-461.5 342,-461.5 342,-415.5 72,-415.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"140.5\" y=\"-434.8\">dropout_14: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"209,-415.5 209,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"237\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"209,-438.5 265,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"237\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"265,-415.5 265,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"303.5\" y=\"-446.3\">(None, 10)</text>\n",
       "<polyline fill=\"none\" points=\"265,-438.5 342,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"303.5\" y=\"-423.3\">(None, 10)</text>\n",
       "</g>\n",
       "<!-- 849833712&#45;&gt;849628184 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>849833712-&gt;849628184</title>\n",
       "<path d=\"M197.552,-498.366C198.871,-490.152 200.394,-480.658 201.828,-471.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"205.323,-472.035 203.452,-461.607 198.411,-470.926 205.323,-472.035\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 849628408 -->\n",
       "<g class=\"node\" id=\"node8\"><title>849628408</title>\n",
       "<polygon fill=\"none\" points=\"366,-415.5 366,-461.5 636,-461.5 636,-415.5 366,-415.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"434.5\" y=\"-434.8\">dropout_15: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"503,-415.5 503,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"531\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"503,-438.5 559,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"531\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"559,-415.5 559,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"597.5\" y=\"-446.3\">(None, 10)</text>\n",
       "<polyline fill=\"none\" points=\"559,-438.5 636,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"597.5\" y=\"-423.3\">(None, 10)</text>\n",
       "</g>\n",
       "<!-- 849628856&#45;&gt;849628408 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>849628856-&gt;849628408</title>\n",
       "<path d=\"M506.087,-498.366C505.377,-490.152 504.557,-480.658 503.785,-471.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"507.259,-471.268 502.91,-461.607 500.285,-471.871 507.259,-471.268\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 849628464 -->\n",
       "<g class=\"node\" id=\"node9\"><title>849628464</title>\n",
       "<polygon fill=\"none\" points=\"183,-332.5 183,-378.5 525,-378.5 525,-332.5 183,-332.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249.5\" y=\"-351.8\">Concat: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"316,-332.5 316,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"344\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"316,-355.5 372,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"344\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"372,-332.5 372,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"448.5\" y=\"-363.3\">[(None, 10), (None, 10)]</text>\n",
       "<polyline fill=\"none\" points=\"372,-355.5 525,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"448.5\" y=\"-340.3\">(None, 20)</text>\n",
       "</g>\n",
       "<!-- 849628184&#45;&gt;849628464 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>849628184-&gt;849628464</title>\n",
       "<path d=\"M247.168,-415.366C264.993,-405.544 286.137,-393.894 304.891,-383.56\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"306.811,-386.498 313.88,-378.607 303.433,-380.368 306.811,-386.498\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 849628408&#45;&gt;849628464 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>849628408-&gt;849628464</title>\n",
       "<path d=\"M460.832,-415.366C443.007,-405.544 421.863,-393.894 403.109,-383.56\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"404.567,-380.368 394.12,-378.607 401.189,-386.498 404.567,-380.368\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 849462776 -->\n",
       "<g class=\"node\" id=\"node10\"><title>849462776</title>\n",
       "<polygon fill=\"none\" points=\"205.5,-249.5 205.5,-295.5 502.5,-295.5 502.5,-249.5 205.5,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"284.5\" y=\"-268.8\">FullyConnected-1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"363.5,-249.5 363.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"391.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"363.5,-272.5 419.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"391.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"419.5,-249.5 419.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"461\" y=\"-280.3\">(None, 20)</text>\n",
       "<polyline fill=\"none\" points=\"419.5,-272.5 502.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"461\" y=\"-257.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 849628464&#45;&gt;849462776 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>849628464-&gt;849462776</title>\n",
       "<path d=\"M354,-332.366C354,-324.152 354,-314.658 354,-305.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"357.5,-305.607 354,-295.607 350.5,-305.607 357.5,-305.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 297328880 -->\n",
       "<g class=\"node\" id=\"node11\"><title>297328880</title>\n",
       "<polygon fill=\"none\" points=\"205.5,-166.5 205.5,-212.5 502.5,-212.5 502.5,-166.5 205.5,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"284.5\" y=\"-185.8\">FullyConnected-2: Dense</text>\n",
       "<polyline fill=\"none\" points=\"363.5,-166.5 363.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"391.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"363.5,-189.5 419.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"391.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"419.5,-166.5 419.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"461\" y=\"-197.3\">(None, 100)</text>\n",
       "<polyline fill=\"none\" points=\"419.5,-189.5 502.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"461\" y=\"-174.3\">(None, 50)</text>\n",
       "</g>\n",
       "<!-- 849462776&#45;&gt;297328880 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>849462776-&gt;297328880</title>\n",
       "<path d=\"M354,-249.366C354,-241.152 354,-231.658 354,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"357.5,-222.607 354,-212.607 350.5,-222.607 357.5,-222.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 849831360 -->\n",
       "<g class=\"node\" id=\"node12\"><title>849831360</title>\n",
       "<polygon fill=\"none\" points=\"208.5,-83.5 208.5,-129.5 499.5,-129.5 499.5,-83.5 208.5,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"287.5\" y=\"-102.8\">FullyConnected-3: Dense</text>\n",
       "<polyline fill=\"none\" points=\"366.5,-83.5 366.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"394.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"366.5,-106.5 422.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"394.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"422.5,-83.5 422.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"461\" y=\"-114.3\">(None, 50)</text>\n",
       "<polyline fill=\"none\" points=\"422.5,-106.5 499.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"461\" y=\"-91.3\">(None, 20)</text>\n",
       "</g>\n",
       "<!-- 297328880&#45;&gt;849831360 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>297328880-&gt;849831360</title>\n",
       "<path d=\"M354,-166.366C354,-158.152 354,-148.658 354,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"357.5,-139.607 354,-129.607 350.5,-139.607 357.5,-139.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 849830688 -->\n",
       "<g class=\"node\" id=\"node13\"><title>849830688</title>\n",
       "<polygon fill=\"none\" points=\"230,-0.5 230,-46.5 478,-46.5 478,-0.5 230,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"287.5\" y=\"-19.8\">Activation: Dense</text>\n",
       "<polyline fill=\"none\" points=\"345,-0.5 345,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"373\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"345,-23.5 401,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"373\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"401,-0.5 401,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"439.5\" y=\"-31.3\">(None, 20)</text>\n",
       "<polyline fill=\"none\" points=\"401,-23.5 478,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"439.5\" y=\"-8.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 849831360&#45;&gt;849830688 -->\n",
       "<g class=\"edge\" id=\"edge12\"><title>849831360-&gt;849830688</title>\n",
       "<path d=\"M354,-83.3664C354,-75.1516 354,-65.6579 354,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"357.5,-56.6068 354,-46.6068 350.5,-56.6069 357.5,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model,  show_shapes=True, show_layer_names=True, rankdir='HB').create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Item (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "User (InputLayer)               (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Movie-Embedding (Embedding)     (None, 1, 10)        16830       Item[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "User-Embedding (Embedding)      (None, 1, 10)        9440        User[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "FlattenMovies (Flatten)         (None, 10)           0           Movie-Embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "FlattenUsers (Flatten)          (None, 10)           0           User-Embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 10)           0           FlattenMovies[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 10)           0           FlattenUsers[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "Concat (Concatenate)            (None, 20)           0           dropout_14[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "FullyConnected-1 (Dense)        (None, 100)          2100        Concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "FullyConnected-2 (Dense)        (None, 50)           5050        FullyConnected-1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "FullyConnected-3 (Dense)        (None, 20)           1020        FullyConnected-2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Activation (Dense)              (None, 1)            21          FullyConnected-3[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 34,461\n",
      "Trainable params: 34,461\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit([x_train.user_id, x_train.item_id], x_train.rating, epochs=250, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69375\n",
      "0.7059811423778534\n"
     ]
    }
   ],
   "source": [
    "y_hat_2 = np.round(model.predict([x_test.user_id, x_test.item_id]),0)\n",
    "print(mean_absolute_error(y_true, y_hat_2))\n",
    "print(mean_absolute_error(y_true, model.predict([x_test.user_id, x_test.item_id])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_latent_factors_user = 5\n",
    "# n_latent_factors_movie = 8\n",
    "# 0.6913\n",
    "# 0.7127672422289848\n",
    "\n",
    "# n_latent_factors_user = 10\n",
    "# n_latent_factors_movie = 10\n",
    "# 0.69375\n",
    "# 0.7059811423778534\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keras rnn  #https://github.com/tertiarycourses/KerasTraining/blob/master/exercises/module5_RNN/module5_2_keras_rnn_imdb.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 14s 1us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   15   256     4 ...    19   178    32]\n",
      " [  125    68     2 ...    16   145    95]\n",
      " [  645   662     8 ...     7   129   113]\n",
      " ...\n",
      " [  529   443 17793 ...     4  3586     2]\n",
      " [  286  1814    23 ...    12     9    23]\n",
      " [   97    90    35 ...   204   131     9]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sequence.pad_sequences(X_train,maxlen=80)\n",
    "X_test = sequence.pad_sequences(X_test,maxlen=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(20000,128))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 192s 8ms/step - loss: 0.4241 - acc: 0.7995\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 179s 7ms/step - loss: 0.2369 - acc: 0.9045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3a5d4860>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 45s 2ms/step\n",
      "Loss =  0.38798090552330017\n",
      "Accuracy =  0.83948\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(X_test,y_test)\n",
    "print('Loss = ',loss)\n",
    "print('Accuracy = ',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keras cifar CNN   https://github.com/leriomaggio/deep-learning-keras-tensorflow/blob/master/4.%20Convolutional%20Neural%20Networks/4.3%20CIFAR10%20CNN.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import generic_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 59,  62,  63],\n",
       "         [ 43,  46,  45],\n",
       "         [ 50,  48,  43],\n",
       "         ...,\n",
       "         [158, 132, 108],\n",
       "         [152, 125, 102],\n",
       "         [148, 124, 103]],\n",
       "\n",
       "        [[ 16,  20,  20],\n",
       "         [  0,   0,   0],\n",
       "         [ 18,   8,   0],\n",
       "         ...,\n",
       "         [123,  88,  55],\n",
       "         [119,  83,  50],\n",
       "         [122,  87,  57]],\n",
       "\n",
       "        [[ 25,  24,  21],\n",
       "         [ 16,   7,   0],\n",
       "         [ 49,  27,   8],\n",
       "         ...,\n",
       "         [118,  84,  50],\n",
       "         [120,  84,  50],\n",
       "         [109,  73,  42]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[208, 170,  96],\n",
       "         [201, 153,  34],\n",
       "         [198, 161,  26],\n",
       "         ...,\n",
       "         [160, 133,  70],\n",
       "         [ 56,  31,   7],\n",
       "         [ 53,  34,  20]],\n",
       "\n",
       "        [[180, 139,  96],\n",
       "         [173, 123,  42],\n",
       "         [186, 144,  30],\n",
       "         ...,\n",
       "         [184, 148,  94],\n",
       "         [ 97,  62,  34],\n",
       "         [ 83,  53,  34]],\n",
       "\n",
       "        [[177, 144, 116],\n",
       "         [168, 129,  94],\n",
       "         [179, 142,  87],\n",
       "         ...,\n",
       "         [216, 184, 140],\n",
       "         [151, 118,  84],\n",
       "         [123,  92,  72]]],\n",
       "\n",
       "\n",
       "       [[[154, 177, 187],\n",
       "         [126, 137, 136],\n",
       "         [105, 104,  95],\n",
       "         ...,\n",
       "         [ 91,  95,  71],\n",
       "         [ 87,  90,  71],\n",
       "         [ 79,  81,  70]],\n",
       "\n",
       "        [[140, 160, 169],\n",
       "         [145, 153, 154],\n",
       "         [125, 125, 118],\n",
       "         ...,\n",
       "         [ 96,  99,  78],\n",
       "         [ 77,  80,  62],\n",
       "         [ 71,  73,  61]],\n",
       "\n",
       "        [[140, 155, 164],\n",
       "         [139, 146, 149],\n",
       "         [115, 115, 112],\n",
       "         ...,\n",
       "         [ 79,  82,  64],\n",
       "         [ 68,  70,  55],\n",
       "         [ 67,  69,  55]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[175, 167, 166],\n",
       "         [156, 154, 160],\n",
       "         [154, 160, 170],\n",
       "         ...,\n",
       "         [ 42,  34,  36],\n",
       "         [ 61,  53,  57],\n",
       "         [ 93,  83,  91]],\n",
       "\n",
       "        [[165, 154, 128],\n",
       "         [156, 152, 130],\n",
       "         [159, 161, 142],\n",
       "         ...,\n",
       "         [103,  93,  96],\n",
       "         [123, 114, 120],\n",
       "         [131, 121, 131]],\n",
       "\n",
       "        [[163, 148, 120],\n",
       "         [158, 148, 122],\n",
       "         [163, 156, 133],\n",
       "         ...,\n",
       "         [143, 133, 139],\n",
       "         [143, 134, 142],\n",
       "         [143, 133, 144]]],\n",
       "\n",
       "\n",
       "       [[[255, 255, 255],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         ...,\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         ...,\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[113, 120, 112],\n",
       "         [111, 118, 111],\n",
       "         [105, 112, 106],\n",
       "         ...,\n",
       "         [ 72,  81,  80],\n",
       "         [ 72,  80,  79],\n",
       "         [ 72,  80,  79]],\n",
       "\n",
       "        [[111, 118, 110],\n",
       "         [104, 111, 104],\n",
       "         [ 99, 106,  98],\n",
       "         ...,\n",
       "         [ 68,  75,  73],\n",
       "         [ 70,  76,  75],\n",
       "         [ 78,  84,  82]],\n",
       "\n",
       "        [[106, 113, 105],\n",
       "         [ 99, 106,  98],\n",
       "         [ 95, 102,  94],\n",
       "         ...,\n",
       "         [ 78,  85,  83],\n",
       "         [ 79,  85,  83],\n",
       "         [ 80,  86,  84]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 35, 178, 235],\n",
       "         [ 40, 176, 239],\n",
       "         [ 42, 176, 241],\n",
       "         ...,\n",
       "         [ 99, 177, 219],\n",
       "         [ 79, 147, 197],\n",
       "         [ 89, 148, 189]],\n",
       "\n",
       "        [[ 57, 182, 234],\n",
       "         [ 44, 184, 250],\n",
       "         [ 50, 183, 240],\n",
       "         ...,\n",
       "         [156, 182, 200],\n",
       "         [141, 177, 206],\n",
       "         [116, 149, 175]],\n",
       "\n",
       "        [[ 98, 197, 237],\n",
       "         [ 64, 189, 252],\n",
       "         [ 69, 192, 245],\n",
       "         ...,\n",
       "         [188, 195, 206],\n",
       "         [119, 135, 147],\n",
       "         [ 61,  79,  90]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 73,  79,  77],\n",
       "         [ 53,  63,  68],\n",
       "         [ 54,  68,  80],\n",
       "         ...,\n",
       "         [ 17,  40,  64],\n",
       "         [ 21,  36,  51],\n",
       "         [ 33,  48,  49]],\n",
       "\n",
       "        [[ 61,  68,  75],\n",
       "         [ 55,  70,  86],\n",
       "         [ 57,  79, 103],\n",
       "         ...,\n",
       "         [ 24,  48,  72],\n",
       "         [ 17,  35,  53],\n",
       "         [  7,  23,  32]],\n",
       "\n",
       "        [[ 44,  56,  73],\n",
       "         [ 46,  66,  88],\n",
       "         [ 49,  77, 105],\n",
       "         ...,\n",
       "         [ 27,  52,  77],\n",
       "         [ 21,  43,  66],\n",
       "         [ 12,  31,  50]]],\n",
       "\n",
       "\n",
       "       [[[189, 211, 240],\n",
       "         [186, 208, 236],\n",
       "         [185, 207, 235],\n",
       "         ...,\n",
       "         [175, 195, 224],\n",
       "         [172, 194, 222],\n",
       "         [169, 194, 220]],\n",
       "\n",
       "        [[194, 210, 239],\n",
       "         [191, 207, 236],\n",
       "         [190, 206, 235],\n",
       "         ...,\n",
       "         [173, 192, 220],\n",
       "         [171, 191, 218],\n",
       "         [167, 190, 216]],\n",
       "\n",
       "        [[208, 219, 244],\n",
       "         [205, 216, 240],\n",
       "         [204, 215, 239],\n",
       "         ...,\n",
       "         [175, 191, 217],\n",
       "         [172, 190, 216],\n",
       "         [169, 191, 215]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[207, 199, 181],\n",
       "         [203, 195, 175],\n",
       "         [203, 196, 173],\n",
       "         ...,\n",
       "         [135, 132, 127],\n",
       "         [162, 158, 150],\n",
       "         [168, 163, 151]],\n",
       "\n",
       "        [[198, 190, 170],\n",
       "         [189, 181, 159],\n",
       "         [180, 172, 147],\n",
       "         ...,\n",
       "         [178, 171, 160],\n",
       "         [175, 169, 156],\n",
       "         [175, 169, 154]],\n",
       "\n",
       "        [[198, 189, 173],\n",
       "         [189, 181, 162],\n",
       "         [178, 170, 149],\n",
       "         ...,\n",
       "         [195, 184, 169],\n",
       "         [196, 189, 171],\n",
       "         [195, 190, 171]]],\n",
       "\n",
       "\n",
       "       [[[229, 229, 239],\n",
       "         [236, 237, 247],\n",
       "         [234, 236, 247],\n",
       "         ...,\n",
       "         [217, 219, 233],\n",
       "         [221, 223, 234],\n",
       "         [222, 223, 233]],\n",
       "\n",
       "        [[222, 221, 229],\n",
       "         [239, 239, 249],\n",
       "         [233, 234, 246],\n",
       "         ...,\n",
       "         [223, 223, 236],\n",
       "         [227, 228, 238],\n",
       "         [210, 211, 220]],\n",
       "\n",
       "        [[213, 206, 211],\n",
       "         [234, 232, 239],\n",
       "         [231, 233, 244],\n",
       "         ...,\n",
       "         [220, 220, 232],\n",
       "         [220, 219, 232],\n",
       "         [202, 203, 215]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[150, 143, 135],\n",
       "         [140, 135, 127],\n",
       "         [132, 127, 120],\n",
       "         ...,\n",
       "         [224, 222, 218],\n",
       "         [230, 228, 225],\n",
       "         [241, 241, 238]],\n",
       "\n",
       "        [[137, 132, 126],\n",
       "         [130, 127, 120],\n",
       "         [125, 121, 115],\n",
       "         ...,\n",
       "         [181, 180, 178],\n",
       "         [202, 201, 198],\n",
       "         [212, 211, 207]],\n",
       "\n",
       "        [[122, 119, 114],\n",
       "         [118, 116, 110],\n",
       "         [120, 116, 111],\n",
       "         ...,\n",
       "         [179, 177, 173],\n",
       "         [164, 164, 162],\n",
       "         [163, 163, 161]]]], dtype=uint8)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "y_test = np_utils.to_categorical(y_test, n_classes)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.23137255, 0.24313726, 0.24705882],\n",
       "         [0.16862746, 0.18039216, 0.1764706 ],\n",
       "         [0.19607843, 0.1882353 , 0.16862746],\n",
       "         ...,\n",
       "         [0.61960787, 0.5176471 , 0.42352942],\n",
       "         [0.59607846, 0.49019608, 0.4       ],\n",
       "         [0.5803922 , 0.4862745 , 0.40392157]],\n",
       "\n",
       "        [[0.0627451 , 0.07843138, 0.07843138],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.07058824, 0.03137255, 0.        ],\n",
       "         ...,\n",
       "         [0.48235294, 0.34509805, 0.21568628],\n",
       "         [0.46666667, 0.3254902 , 0.19607843],\n",
       "         [0.47843137, 0.34117648, 0.22352941]],\n",
       "\n",
       "        [[0.09803922, 0.09411765, 0.08235294],\n",
       "         [0.0627451 , 0.02745098, 0.        ],\n",
       "         [0.19215687, 0.10588235, 0.03137255],\n",
       "         ...,\n",
       "         [0.4627451 , 0.32941177, 0.19607843],\n",
       "         [0.47058824, 0.32941177, 0.19607843],\n",
       "         [0.42745098, 0.28627452, 0.16470589]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8156863 , 0.6666667 , 0.3764706 ],\n",
       "         [0.7882353 , 0.6       , 0.13333334],\n",
       "         [0.7764706 , 0.6313726 , 0.10196079],\n",
       "         ...,\n",
       "         [0.627451  , 0.52156866, 0.27450982],\n",
       "         [0.21960784, 0.12156863, 0.02745098],\n",
       "         [0.20784314, 0.13333334, 0.07843138]],\n",
       "\n",
       "        [[0.7058824 , 0.54509807, 0.3764706 ],\n",
       "         [0.6784314 , 0.48235294, 0.16470589],\n",
       "         [0.7294118 , 0.5647059 , 0.11764706],\n",
       "         ...,\n",
       "         [0.72156864, 0.5803922 , 0.36862746],\n",
       "         [0.38039216, 0.24313726, 0.13333334],\n",
       "         [0.3254902 , 0.20784314, 0.13333334]],\n",
       "\n",
       "        [[0.69411767, 0.5647059 , 0.45490196],\n",
       "         [0.65882355, 0.5058824 , 0.36862746],\n",
       "         [0.7019608 , 0.5568628 , 0.34117648],\n",
       "         ...,\n",
       "         [0.84705883, 0.72156864, 0.54901963],\n",
       "         [0.5921569 , 0.4627451 , 0.32941177],\n",
       "         [0.48235294, 0.36078432, 0.28235295]]],\n",
       "\n",
       "\n",
       "       [[[0.6039216 , 0.69411767, 0.73333335],\n",
       "         [0.49411765, 0.5372549 , 0.53333336],\n",
       "         [0.4117647 , 0.40784314, 0.37254903],\n",
       "         ...,\n",
       "         [0.35686275, 0.37254903, 0.2784314 ],\n",
       "         [0.34117648, 0.3529412 , 0.2784314 ],\n",
       "         [0.30980393, 0.31764707, 0.27450982]],\n",
       "\n",
       "        [[0.54901963, 0.627451  , 0.6627451 ],\n",
       "         [0.5686275 , 0.6       , 0.6039216 ],\n",
       "         [0.49019608, 0.49019608, 0.4627451 ],\n",
       "         ...,\n",
       "         [0.3764706 , 0.3882353 , 0.30588236],\n",
       "         [0.3019608 , 0.3137255 , 0.24313726],\n",
       "         [0.2784314 , 0.28627452, 0.23921569]],\n",
       "\n",
       "        [[0.54901963, 0.60784316, 0.6431373 ],\n",
       "         [0.54509807, 0.57254905, 0.58431375],\n",
       "         [0.4509804 , 0.4509804 , 0.4392157 ],\n",
       "         ...,\n",
       "         [0.30980393, 0.32156864, 0.2509804 ],\n",
       "         [0.26666668, 0.27450982, 0.21568628],\n",
       "         [0.2627451 , 0.27058825, 0.21568628]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.6862745 , 0.654902  , 0.6509804 ],\n",
       "         [0.6117647 , 0.6039216 , 0.627451  ],\n",
       "         [0.6039216 , 0.627451  , 0.6666667 ],\n",
       "         ...,\n",
       "         [0.16470589, 0.13333334, 0.14117648],\n",
       "         [0.23921569, 0.20784314, 0.22352941],\n",
       "         [0.3647059 , 0.3254902 , 0.35686275]],\n",
       "\n",
       "        [[0.64705884, 0.6039216 , 0.5019608 ],\n",
       "         [0.6117647 , 0.59607846, 0.50980395],\n",
       "         [0.62352943, 0.6313726 , 0.5568628 ],\n",
       "         ...,\n",
       "         [0.40392157, 0.3647059 , 0.3764706 ],\n",
       "         [0.48235294, 0.44705883, 0.47058824],\n",
       "         [0.5137255 , 0.4745098 , 0.5137255 ]],\n",
       "\n",
       "        [[0.6392157 , 0.5803922 , 0.47058824],\n",
       "         [0.61960787, 0.5803922 , 0.47843137],\n",
       "         [0.6392157 , 0.6117647 , 0.52156866],\n",
       "         ...,\n",
       "         [0.56078434, 0.52156866, 0.54509807],\n",
       "         [0.56078434, 0.5254902 , 0.5568628 ],\n",
       "         [0.56078434, 0.52156866, 0.5647059 ]]],\n",
       "\n",
       "\n",
       "       [[[1.        , 1.        , 1.        ],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         ...,\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686],\n",
       "         [0.99215686, 0.99215686, 0.99215686]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         ...,\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843],\n",
       "         [0.99607843, 0.99607843, 0.99607843]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.44313726, 0.47058824, 0.4392157 ],\n",
       "         [0.43529412, 0.4627451 , 0.43529412],\n",
       "         [0.4117647 , 0.4392157 , 0.41568628],\n",
       "         ...,\n",
       "         [0.28235295, 0.31764707, 0.3137255 ],\n",
       "         [0.28235295, 0.3137255 , 0.30980393],\n",
       "         [0.28235295, 0.3137255 , 0.30980393]],\n",
       "\n",
       "        [[0.43529412, 0.4627451 , 0.43137255],\n",
       "         [0.40784314, 0.43529412, 0.40784314],\n",
       "         [0.3882353 , 0.41568628, 0.38431373],\n",
       "         ...,\n",
       "         [0.26666668, 0.29411766, 0.28627452],\n",
       "         [0.27450982, 0.29803923, 0.29411766],\n",
       "         [0.30588236, 0.32941177, 0.32156864]],\n",
       "\n",
       "        [[0.41568628, 0.44313726, 0.4117647 ],\n",
       "         [0.3882353 , 0.41568628, 0.38431373],\n",
       "         [0.37254903, 0.4       , 0.36862746],\n",
       "         ...,\n",
       "         [0.30588236, 0.33333334, 0.3254902 ],\n",
       "         [0.30980393, 0.33333334, 0.3254902 ],\n",
       "         [0.3137255 , 0.3372549 , 0.32941177]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.13725491, 0.69803923, 0.92156863],\n",
       "         [0.15686275, 0.6901961 , 0.9372549 ],\n",
       "         [0.16470589, 0.6901961 , 0.94509804],\n",
       "         ...,\n",
       "         [0.3882353 , 0.69411767, 0.85882354],\n",
       "         [0.30980393, 0.5764706 , 0.77254903],\n",
       "         [0.34901962, 0.5803922 , 0.7411765 ]],\n",
       "\n",
       "        [[0.22352941, 0.7137255 , 0.91764706],\n",
       "         [0.17254902, 0.72156864, 0.98039216],\n",
       "         [0.19607843, 0.7176471 , 0.9411765 ],\n",
       "         ...,\n",
       "         [0.6117647 , 0.7137255 , 0.78431374],\n",
       "         [0.5529412 , 0.69411767, 0.80784315],\n",
       "         [0.45490196, 0.58431375, 0.6862745 ]],\n",
       "\n",
       "        [[0.38431373, 0.77254903, 0.92941177],\n",
       "         [0.2509804 , 0.7411765 , 0.9882353 ],\n",
       "         [0.27058825, 0.7529412 , 0.9607843 ],\n",
       "         ...,\n",
       "         [0.7372549 , 0.7647059 , 0.80784315],\n",
       "         [0.46666667, 0.5294118 , 0.5764706 ],\n",
       "         [0.23921569, 0.30980393, 0.3529412 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.28627452, 0.30980393, 0.3019608 ],\n",
       "         [0.20784314, 0.24705882, 0.26666668],\n",
       "         [0.21176471, 0.26666668, 0.3137255 ],\n",
       "         ...,\n",
       "         [0.06666667, 0.15686275, 0.2509804 ],\n",
       "         [0.08235294, 0.14117648, 0.2       ],\n",
       "         [0.12941177, 0.1882353 , 0.19215687]],\n",
       "\n",
       "        [[0.23921569, 0.26666668, 0.29411766],\n",
       "         [0.21568628, 0.27450982, 0.3372549 ],\n",
       "         [0.22352941, 0.30980393, 0.40392157],\n",
       "         ...,\n",
       "         [0.09411765, 0.1882353 , 0.28235295],\n",
       "         [0.06666667, 0.13725491, 0.20784314],\n",
       "         [0.02745098, 0.09019608, 0.1254902 ]],\n",
       "\n",
       "        [[0.17254902, 0.21960784, 0.28627452],\n",
       "         [0.18039216, 0.25882354, 0.34509805],\n",
       "         [0.19215687, 0.3019608 , 0.4117647 ],\n",
       "         ...,\n",
       "         [0.10588235, 0.20392157, 0.3019608 ],\n",
       "         [0.08235294, 0.16862746, 0.25882354],\n",
       "         [0.04705882, 0.12156863, 0.19607843]]],\n",
       "\n",
       "\n",
       "       [[[0.7411765 , 0.827451  , 0.9411765 ],\n",
       "         [0.7294118 , 0.8156863 , 0.9254902 ],\n",
       "         [0.7254902 , 0.8117647 , 0.92156863],\n",
       "         ...,\n",
       "         [0.6862745 , 0.7647059 , 0.8784314 ],\n",
       "         [0.6745098 , 0.7607843 , 0.87058824],\n",
       "         [0.6627451 , 0.7607843 , 0.8627451 ]],\n",
       "\n",
       "        [[0.7607843 , 0.8235294 , 0.9372549 ],\n",
       "         [0.7490196 , 0.8117647 , 0.9254902 ],\n",
       "         [0.74509805, 0.80784315, 0.92156863],\n",
       "         ...,\n",
       "         [0.6784314 , 0.7529412 , 0.8627451 ],\n",
       "         [0.67058825, 0.7490196 , 0.85490197],\n",
       "         [0.654902  , 0.74509805, 0.84705883]],\n",
       "\n",
       "        [[0.8156863 , 0.85882354, 0.95686275],\n",
       "         [0.8039216 , 0.84705883, 0.9411765 ],\n",
       "         [0.8       , 0.84313726, 0.9372549 ],\n",
       "         ...,\n",
       "         [0.6862745 , 0.7490196 , 0.8509804 ],\n",
       "         [0.6745098 , 0.74509805, 0.84705883],\n",
       "         [0.6627451 , 0.7490196 , 0.84313726]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8117647 , 0.78039217, 0.70980394],\n",
       "         [0.79607844, 0.7647059 , 0.6862745 ],\n",
       "         [0.79607844, 0.76862746, 0.6784314 ],\n",
       "         ...,\n",
       "         [0.5294118 , 0.5176471 , 0.49803922],\n",
       "         [0.63529414, 0.61960787, 0.5882353 ],\n",
       "         [0.65882355, 0.6392157 , 0.5921569 ]],\n",
       "\n",
       "        [[0.7764706 , 0.74509805, 0.6666667 ],\n",
       "         [0.7411765 , 0.70980394, 0.62352943],\n",
       "         [0.7058824 , 0.6745098 , 0.5764706 ],\n",
       "         ...,\n",
       "         [0.69803923, 0.67058825, 0.627451  ],\n",
       "         [0.6862745 , 0.6627451 , 0.6117647 ],\n",
       "         [0.6862745 , 0.6627451 , 0.6039216 ]],\n",
       "\n",
       "        [[0.7764706 , 0.7411765 , 0.6784314 ],\n",
       "         [0.7411765 , 0.70980394, 0.63529414],\n",
       "         [0.69803923, 0.6666667 , 0.58431375],\n",
       "         ...,\n",
       "         [0.7647059 , 0.72156864, 0.6627451 ],\n",
       "         [0.76862746, 0.7411765 , 0.67058825],\n",
       "         [0.7647059 , 0.74509805, 0.67058825]]],\n",
       "\n",
       "\n",
       "       [[[0.8980392 , 0.8980392 , 0.9372549 ],\n",
       "         [0.9254902 , 0.92941177, 0.96862745],\n",
       "         [0.91764706, 0.9254902 , 0.96862745],\n",
       "         ...,\n",
       "         [0.8509804 , 0.85882354, 0.9137255 ],\n",
       "         [0.8666667 , 0.8745098 , 0.91764706],\n",
       "         [0.87058824, 0.8745098 , 0.9137255 ]],\n",
       "\n",
       "        [[0.87058824, 0.8666667 , 0.8980392 ],\n",
       "         [0.9372549 , 0.9372549 , 0.9764706 ],\n",
       "         [0.9137255 , 0.91764706, 0.9647059 ],\n",
       "         ...,\n",
       "         [0.8745098 , 0.8745098 , 0.9254902 ],\n",
       "         [0.8901961 , 0.89411765, 0.93333334],\n",
       "         [0.8235294 , 0.827451  , 0.8627451 ]],\n",
       "\n",
       "        [[0.8352941 , 0.80784315, 0.827451  ],\n",
       "         [0.91764706, 0.9098039 , 0.9372549 ],\n",
       "         [0.90588236, 0.9137255 , 0.95686275],\n",
       "         ...,\n",
       "         [0.8627451 , 0.8627451 , 0.9098039 ],\n",
       "         [0.8627451 , 0.85882354, 0.9098039 ],\n",
       "         [0.7921569 , 0.79607844, 0.84313726]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5882353 , 0.56078434, 0.5294118 ],\n",
       "         [0.54901963, 0.5294118 , 0.49803922],\n",
       "         [0.5176471 , 0.49803922, 0.47058824],\n",
       "         ...,\n",
       "         [0.8784314 , 0.87058824, 0.85490197],\n",
       "         [0.9019608 , 0.89411765, 0.88235295],\n",
       "         [0.94509804, 0.94509804, 0.93333334]],\n",
       "\n",
       "        [[0.5372549 , 0.5176471 , 0.49411765],\n",
       "         [0.50980395, 0.49803922, 0.47058824],\n",
       "         [0.49019608, 0.4745098 , 0.4509804 ],\n",
       "         ...,\n",
       "         [0.70980394, 0.7058824 , 0.69803923],\n",
       "         [0.7921569 , 0.7882353 , 0.7764706 ],\n",
       "         [0.83137256, 0.827451  , 0.8117647 ]],\n",
       "\n",
       "        [[0.47843137, 0.46666667, 0.44705883],\n",
       "         [0.4627451 , 0.45490196, 0.43137255],\n",
       "         [0.47058824, 0.45490196, 0.43529412],\n",
       "         ...,\n",
       "         [0.7019608 , 0.69411767, 0.6784314 ],\n",
       "         [0.6431373 , 0.6431373 , 0.63529414],\n",
       "         [0.6392157 , 0.6392157 , 0.6313726 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images = ImageDataGenerator(\n",
    "    featurewise_center=True,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=True,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we push 500 photos to photo generator\n",
    "gen = generated_images.flow(x_train, y_train, batch_size=500, shuffle=True)\n",
    "x_batch, y_batch = next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 32, 32, 3)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Training...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected embedding_1_input to have 2 dimensions, but got array with shape (500, 32, 32, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-124-b1dadd3554bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgenerated_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1207\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1209\u001b[1;33m             class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1211\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 749\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    750\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    125\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    128\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected embedding_1_input to have 2 dimensions, but got array with shape (500, 32, 32, 3)"
     ]
    }
   ],
   "source": [
    "n_epochs = 2\n",
    "for e in range(n_epochs):\n",
    "    print('Epoch', e)\n",
    "    print('Training...')\n",
    "    progbar = generic_utils.Progbar(x_train.shape[0])\n",
    "    \n",
    "    for x_batch, y_batch in generated_images.flow(x_train, y_train, batch_size=500, shuffle=True):\n",
    "        loss = model.train_on_batch(x_batch, y_batch)\n",
    "        progbar.add(x_batch.shape[0], values=[('train loss', loss[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16 = VGG16(include_top=True, weights='imagenet')\n",
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_FOLDER = 'imgs/imagenet'  #in the repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PIL'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-132-2d3721cf6465>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mPIL\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'PIL'"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "img_path = os.path.join(IMAGENET_FOLDER, 'strawberry_1157.jpeg')\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "print('Input image shape:', x.shape)\n",
    "\n",
    "preds = vgg16.predict(x)\n",
    "print('Predicted:', decode_predictions(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
