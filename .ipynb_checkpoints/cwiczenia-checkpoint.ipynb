{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 1 \n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "Write a program which will find all such numbers which are divisible by 7 but are not a multiple of 5,\n",
    "between 2000 and 3200 (both included).\n",
    "The numbers obtained should be printed in a comma-separated sequence on a single line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002,2009,2016,2023,2037,2044,2051,2058,2072,2079,2086,2093,2107,2114,2121,2128,2142,2149,2156,2163,2177,2184,2191,2198,2212,2219,2226,2233,2247,2254,2261,2268,2282,2289,2296,2303,2317,2324,2331,2338,2352,2359,2366,2373,2387,2394,2401,2408,2422,2429,2436,2443,2457,2464,2471,2478,2492,2499,2506,2513,2527,2534,2541,2548,2562,2569,2576,2583,2597,2604,2611,2618,2632,2639,2646,2653,2667,2674,2681,2688,2702,2709,2716,2723,2737,2744,2751,2758,2772,2779,2786,2793,2807,2814,2821,2828,2842,2849,2856,2863,2877,2884,2891,2898,2912,2919,2926,2933,2947,2954,2961,2968,2982,2989,2996,3003,3017,3024,3031,3038,3052,3059,3066,3073,3087,3094,3101,3108,3122,3129,3136,3143,3157,3164,3171,3178,3192,3199\n",
      "Wall time: 110 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# beter use python list then np arrey to append\n",
    "import numpy as np\n",
    "numbers = []\n",
    "for i in range(2000,3201):\n",
    "    if np.mod(i,7) == 0:\n",
    "        if np.mod(i,5) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            numbers.append(str(i))\n",
    "print(','.join(numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 2 \n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "Write a program which can compute the factorial of a given numbers.\n",
    "The results should be printed in a comma-separated sequence on a single line.\n",
    "Suppose the following input is supplied to the program:\n",
    "8\n",
    "Then, the output should be:\n",
    "40320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "\n",
    "factorials = []\n",
    "def factorial_finder(input_number):\n",
    "    for factorial in range(0,input_number):\n",
    "        if np.mod(input_number, factorial) ==0:\n",
    "            factorials.append(str(factorial))\n",
    "    print(','.join(factorials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,1,2,4,5,10,20,25,50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tensorflow\\Miniconda3\\envs\\gpu\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in remainder\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "factorial_finder(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 3 \n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "With a given integral number n, write a program to generate a dictionary that contains (i, i*i) such that is an integral number between 1 and n (both included). and then the program should print the dictionary.\n",
    "Suppose the following input is supplied to the program:\n",
    "8\n",
    "Then, the output should be:\n",
    "{1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "\n",
    "numbers = dict()\n",
    "def number_dictionary(input_number):\n",
    "    for number in range(1,input_number+1):\n",
    "        numbers[number] = np.power(number, 2)\n",
    "    print(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64}\n"
     ]
    }
   ],
   "source": [
    "number_dictionary(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 6\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "Write a program that calculates and prints the value according to the given formula:\n",
    "\n",
    "Q = Square root of [(2 * C * D)/H]\n",
    "Following are the fixed values of C and H:\n",
    "C is 50. H is 30.\n",
    "D is the variable whose values should be input to your program in a comma-separated sequence.\n",
    "Example\n",
    "Let us assume the following comma separated input sequence is given to the program:\n",
    "\n",
    "100,150,180\n",
    "The output of the program should be:\n",
    "18,22,24\n",
    "\n",
    "Hints:\n",
    "If the output received is in decimal form, it should be rounded off to its nearest value (for example, if the output received is 26.0, it should be printed as 26)\n",
    "In case of input data being supplied to the question, it should be assumed to be a console input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "def cw6_fun(D):\n",
    "    # Q = Square root of [(2 * C * D)/H]\n",
    "    # C is 50. H is 30\n",
    "    numbers = []\n",
    "    D = D.split(\",\")\n",
    "    C = 50.\n",
    "    H = 30.\n",
    "    for d in D:\n",
    "        d = int(d)\n",
    "        q1 = np.multiply(2*C,d)\n",
    "        q2 = np.divide(q1,H)\n",
    "        Q = int(np.sqrt(q2))\n",
    "        numbers.append(str(Q))\n",
    "    print(','.join(numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18,22,24\n",
      "Wall time: 1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cw6_fun(\"100,150,180\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 7\n",
    "\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "Write a program which takes 2 digits, X,Y as input and generates a 2-dimensional array. The element value in the i-th row and j-th column of the array should be i*j.\n",
    "Note: i=0,1.., X-1; j=0,1,¡­Y-1.\n",
    "Example\n",
    "Suppose the following inputs are given to the program:\n",
    "3,5\n",
    "Then, the output of the program should be:\n",
    "[[0, 0, 0, 0, 0], [0, 1, 2, 3, 4], [0, 2, 4, 6, 8]] \n",
    "\n",
    "Hints:\n",
    "Note: In case of input data being supplied to the question, it should be assumed to be a console input in a comma-separated form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "def cw7(in_number):\n",
    "    # Q = Square root of [(2 * C * D)/H]\n",
    "    # C is 50. H is 30\n",
    "    table = []\n",
    "    in_number = in_number.split(\",\")\n",
    "    # number of rows\n",
    "    in_number[0] = int(in_number[0])\n",
    "    # number of columns\n",
    "    in_number[1] = int(in_number[1])\n",
    "    for num_row in range(0,in_number[0]):\n",
    "        tab_row = []\n",
    "        for num_col in range(0,in_number[1]):\n",
    "            tab_col = num_row * num_col\n",
    "            tab_row.append(tab_col)\n",
    "        table.append(tab_row)\n",
    "    print(table)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 0], [0, 1, 2, 3, 4], [0, 2, 4, 6, 8]]\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cw7(\"3,5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 8\n",
    "\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "Write a program that accepts a comma separated sequence of words as input and prints the words in a comma-separated sequence after sorting them alphabetically.\n",
    "Suppose the following input is supplied to the program:\n",
    "without,hello,bag,world\n",
    "Then, the output should be:\n",
    "bag,hello,without,world\n",
    "\n",
    "Hints:\n",
    "In case of input data being supplied to the question, it should be assumed to be a console input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "def cw8(words):\n",
    "    words=words.split(\",\")\n",
    "    words = sorted(words)\n",
    "    print(','.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dupa,huj,kurwa,pizda\n"
     ]
    }
   ],
   "source": [
    "cw8(\"dupa,kurwa,pizda,huj\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 9\n",
    "\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question\n",
    "Write a program that accepts sequence of lines as input and prints the lines after making all characters in the sentence capitalized.\n",
    "Suppose the following input is supplied to the program:\n",
    "Hello world\n",
    "Practice makes perfect\n",
    "Then, the output should be:\n",
    "HELLO WORLD\n",
    "PRACTICE MAKES PERFECT\n",
    "\n",
    "Hints:\n",
    "In case of input data being supplied to the question, it should be assumed to be a console input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "def cw9(words):\n",
    "    words_upper = []\n",
    "    words=words.split(\" \")\n",
    "    for word in words:\n",
    "        words_upper.append(word.upper())\n",
    "    print(' '.join(words_upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO WORLD PRACTICE MAKES PERFECT\n"
     ]
    }
   ],
   "source": [
    "cw9(\"Hello world Practice makes perfect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 10\n",
    "\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "Write a program that accepts a sequence of whitespace separated words as input and prints the words after removing all duplicate words and sorting them alphanumerically.\n",
    "Suppose the following input is supplied to the program:\n",
    "hello world and practice makes perfect and hello world again\n",
    "Then, the output should be:\n",
    "again and hello makes perfect practice world\n",
    "\n",
    "Hints:\n",
    "In case of input data being supplied to the question, it should be assumed to be a console input.\n",
    "We use set container to remove duplicated data automatically and then use sorted() to sort the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def cw10(words):\n",
    "    words=words.split(\" \")\n",
    "    uniq_words = Counter(words) \n",
    "    uniq_words = sorted(uniq_words)\n",
    "    print(' '.join(uniq_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "again and hello makes perfect practice world\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cw10(\"hello world and practice makes perfect and hello world again\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 11\n",
    "\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "Write a program which accepts a sequence of comma separated 4 digit binary numbers as its input and then check whether they are divisible by 5 or not. The numbers that are divisible by 5 are to be printed in a comma separated sequence.\n",
    "Example:\n",
    "0100,0011,1010,1001\n",
    "Then the output should be:\n",
    "1010\n",
    "Notes: Assume the data is input by console.\n",
    "\n",
    "Hints:\n",
    "In case of input data being supplied to the question, it should be assumed to be a console input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "def cw11(numbers):\n",
    "    numbers = numbers.split(\",\")\n",
    "    int_numbers = []\n",
    "    for number in numbers:\n",
    "        number = int(number, 2)\n",
    "        if number % 5 == 0:\n",
    "            int_numbers.append(str(number))\n",
    "    print(','.join(int_numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "cw11('0100,0011,1010,1001')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 12\n",
    "\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "Write a program, which will find all such numbers between 1000 and 3000 (both included) such that each digit of the number is an even number.\n",
    "The numbers obtained should be printed in a comma-separated sequence on a single line.\n",
    "\n",
    "Hints:\n",
    "In case of input data being supplied to the question, it should be assumed to be a console input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def cw12(numbers):\n",
    "    numbers = numbers.split(\",\")\n",
    "    if len(numbers) !=2:\n",
    "        print(\"huj dawaj 2 liczby stara kurwo\")\n",
    "        return\n",
    "    numbers[0] = int(numbers[0])\n",
    "    numbers[1] = int(numbers[1])\n",
    "    even_numbers = []\n",
    "    for number in range(numbers[0], numbers[1]+1):\n",
    "        if number % 2 == 0:\n",
    "            even_numbers.append(str(number))\n",
    "    print(','.join(even_numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30,32,34,36,38,40,42,44,46,48,50,52,54,56,58,60\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cw12(\"30,60\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 13\n",
    "\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "Write a program that accepts a sentence and calculate the number of letters and digits.\n",
    "Suppose the following input is supplied to the program:\n",
    "hello world! 123\n",
    "Then, the output should be:\n",
    "LETTERS 10\n",
    "DIGITS 3\n",
    "\n",
    "Hints:\n",
    "In case of input data being supplied to the question, it should be assumed to be a console input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def cw13(thing):\n",
    "    letters = 0\n",
    "    digits = 0\n",
    "    for mark in thing:\n",
    "        if not mark  is \" \":\n",
    "            if mark.isdigit():\n",
    "                digits += 1\n",
    "            else:\n",
    "                letters += 1\n",
    "    print(\"LETTERS\",letters, \"DIGITS\",digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LETTERS 7 DIGITS 4\n"
     ]
    }
   ],
   "source": [
    "cw13(\"dupa huj 1234\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 14\n",
    "\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "Write a program that accepts a sentence and calculate the number of upper case letters and lower case letters.\n",
    "Suppose the following input is supplied to the program:\n",
    "Hello world!\n",
    "Then, the output should be:\n",
    "UPPER CASE 1\n",
    "LOWER CASE 9\n",
    "\n",
    "Hints:\n",
    "In case of input data being supplied to the question, it should be assumed to be a console input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def cw14(words):\n",
    "    lower_case = 0\n",
    "    upper_case = 0\n",
    "    for letter in words:\n",
    "        if not letter is \" \":\n",
    "            if letter.islower():\n",
    "                lower_case += 1\n",
    "            else:\n",
    "                upper_case += 1\n",
    "    print(\"UPPER CASE \",upper_case,\"LOWER CASE\",lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPPER CASE  4 LOWER CASE 7\n"
     ]
    }
   ],
   "source": [
    "cw14(\"dupa huj DUPA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 15\n",
    "\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Question:\n",
    "Write a program that computes the value of a+aa+aaa+aaaa with a given digit as the value of a.\n",
    "Suppose the following input is supplied to the program:\n",
    "9\n",
    "Then, the output should be:\n",
    "11106\n",
    "\n",
    "Hints:\n",
    "In case of input data being supplied to the question, it should be assumed to be a console input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 16\n",
    "\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "Use a list comprehension to square each odd number in a list. The list is input by a sequence of comma-separated numbers.\n",
    "Suppose the following input is supplied to the program:\n",
    "1,2,3,4,5,6,7,8,9\n",
    "Then, the output should be:\n",
    "1,3,5,7,9\n",
    "\n",
    "Hints:\n",
    "In case of input data being supplied to the question, it should be assumed to be a console input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw16(numbers):\n",
    "    numbers = numbers.split(\",\")\n",
    "    odd =[]\n",
    "    for number in numbers:\n",
    "        number = int(number)\n",
    "        if number % 2 == 1:\n",
    "            odd.append(str(number))\n",
    "    print(','.join(odd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,3,5,7,9\n"
     ]
    }
   ],
   "source": [
    "cw16(\"1,2,3,4,5,6,7,8,9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 18\n",
    "\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "A website requires the users to input username and password to register. Write a program to check the validity of password input by users.\n",
    "Following are the criteria for checking the password:\n",
    "1. At least 1 letter between [a-z]\n",
    "2. At least 1 number between [0-9]\n",
    "1. At least 1 letter between [A-Z]\n",
    "3. At least 1 character from [$#@]\n",
    "4. Minimum length of transaction password: 6\n",
    "5. Maximum length of transaction password: 12\n",
    "Your program should accept a sequence of comma separated passwords and will check them according to the above criteria. Passwords that match the criteria are to be printed, each separated by a comma.\n",
    "Example\n",
    "If the following passwords are given as input to the program:\n",
    "ABd1234@1,a F1#,2w3E*,2We3345\n",
    "Then, the output of the program should be:\n",
    "ABd1234@1\n",
    "\n",
    "Hints:\n",
    "In case of input data being supplied to the question, it should be assumed to be a console input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw18(passwords):\n",
    "    passwords = passwords.split(\",\")\n",
    "    good_passwords = []\n",
    "    for password in passwords:\n",
    "        # At least 1 letter between [a-z]\n",
    "        low_case_latter = False\n",
    "        for letter in password:\n",
    "            if letter.islower():\n",
    "                low_case_latter = True\n",
    "        # At least 1 number between [0-9]\n",
    "        number = False\n",
    "        for letter in password:\n",
    "            if letter.isdigit():\n",
    "                number = True\n",
    "        # At least 1 letter between [A-Z]\n",
    "        uper_case_latter = False\n",
    "        for letter in password:\n",
    "            if letter.isupper():\n",
    "                uper_case_latter = True\n",
    "        # At least 1 character from [$#@]\n",
    "        special_latter = False\n",
    "        for letter in password:\n",
    "            if letter is '$' or letter is '#' or letter is '@':\n",
    "                special_latter = True\n",
    "        # Minimum length of transaction password: 6\n",
    "        min_len_word = False\n",
    "        if len(password) > 6:\n",
    "            min_len_word = True\n",
    "        # Maximum length of transaction password: 12\n",
    "        max_len_word = False\n",
    "        if len(password) < 12:\n",
    "            max_len_word = True\n",
    "        # we check all condition\n",
    "        if low_case_latter and number and uper_case_latter and special_latter and min_len_word and max_len_word:\n",
    "            good_passwords.append(password)\n",
    "    print(good_passwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ABd1234@1']\n"
     ]
    }
   ],
   "source": [
    "cw18(\"ABd1234@1,a F1#,2w3E*,2We3345\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 19\n",
    "\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Question:\n",
    "You are required to write a program to sort the (name, age, height) tuples by ascending order where name is string, age and height are numbers. The tuples are input by console. The sort criteria is:\n",
    "1: Sort based on name;\n",
    "2: Then sort based on age;\n",
    "3: Then sort by score.\n",
    "The priority is that name > age > score.\n",
    "If the following tuples are given as input to the program:\n",
    "Tom,19,80\n",
    "John,20,90\n",
    "Jony,17,91\n",
    "Jony,17,93\n",
    "Json,21,85\n",
    "Then, the output of the program should be:\n",
    "[('John', '20', '90'), ('Jony', '17', '91'), ('Jony', '17', '93'), ('Json', '21', '85'), ('Tom', '19', '80')]\n",
    "\n",
    "Hints:\n",
    "In case of input data being supplied to the question, it should be assumed to be a console input.\n",
    "We use itemgetter to enable multiple sort keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "peoples = []\n",
    "def cw19(people):\n",
    "    people = people.split(\",\")\n",
    "    peoples.append(people)\n",
    "    peoples_sorted =[]\n",
    "    peoples_sorted = sorted(peoples, key=itemgetter(0,1,2))\n",
    "    print(peoples_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Tom', '19', '80']]\n",
      "[['John', '20', '90'], ['Tom', '19', '80']]\n",
      "[['John', '20', '90'], ['Jony', '17', '91'], ['Tom', '19', '80']]\n",
      "[['John', '20', '90'], ['Jony', '17', '91'], ['Jony', '17', '93'], ['Tom', '19', '80']]\n",
      "[['John', '20', '90'], ['Jony', '17', '91'], ['Jony', '17', '93'], ['Json', '21', '85'], ['Tom', '19', '80']]\n"
     ]
    }
   ],
   "source": [
    "cw19(\"Tom,19,80\")\n",
    "cw19(\"John,20,90\")\n",
    "cw19(\"Jony,17,91\")\n",
    "cw19(\"Jony,17,93\")\n",
    "cw19(\"Json,21,85\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  cw 20\n",
    "\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "Define a class with a generator which can iterate the numbers, which are divisible by 7, between a given range 0 and n.\n",
    "\n",
    "Hints:\n",
    "Consider use yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw20(number):\n",
    "    my_list = range(0,number)\n",
    "    for num in my_list:\n",
    "        if num % 7 == 0:\n",
    "            yield num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object cw20 at 0x000000000549D728>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw20(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  cw 21\n",
    "\n",
    "from https://github.com/zhiwehu/Python-programming-exercises/blob/master/100%2B%20Python%20challenging%20programming%20exercises.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question\n",
    "A robot moves in a plane starting from the original point (0,0). The robot can move toward UP, DOWN, LEFT and RIGHT with a given steps. The trace of robot movement is shown as the following:\n",
    "UP 5\n",
    "DOWN 3\n",
    "LEFT 3\n",
    "RIGHT 2\n",
    "¡­\n",
    "The numbers after the direction are steps. Please write a program to compute the distance from current position after a sequence of movement and original point. If the distance is a float, then just print the nearest integer.\n",
    "Example:\n",
    "If the following tuples are given as input to the program:\n",
    "UP 5\n",
    "DOWN 3\n",
    "LEFT 3\n",
    "RIGHT 2\n",
    "Then, the output of the program should be:\n",
    "2\n",
    "\n",
    "Hints:\n",
    "In case of input data being supplied to the question, it should be assumed to be a console input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "position_memory = []\n",
    "def cw21(move):\n",
    "    # we make move\n",
    "    pos = [0,0]\n",
    "    move = move.split(\" \")\n",
    "    # we dicide about move\n",
    "    if move[0] == 'UP':\n",
    "        pos[0] += int(move[1])\n",
    "    if move[0] == 'DOWN':\n",
    "        pos[0] -= int(move[1])\n",
    "    if move[0] == 'RIGHT':\n",
    "        pos[1] += int(move[1])\n",
    "    if move[0] == 'LEFT':\n",
    "        pos[1] -= int(move[1])\n",
    "    # we append move to memory\n",
    "    position_memory.append(pos)\n",
    "    # we make stored moves\n",
    "    position = [0,0]\n",
    "    for positions in position_memory:\n",
    "        position[0] += positions[0]\n",
    "        position[1] += positions[1]\n",
    "    print(\"position: \",position)\n",
    "    # now we calculate how far we go, info:\n",
    "    # http://matematyka.pisz.pl/strona/1248.html\n",
    "    # 2d : d = sqer([(x2-x1)^2]+[(y2-y1)^2])\n",
    "    start_pos = [0,0]\n",
    "    d = math.sqrt(((position[0]-start_pos[0])**2)+((position[1]-start_pos[1])**2))\n",
    "    print(\"How far we go: \",d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position:  [0, -10]\n",
      "How far we go:  10.0\n"
     ]
    }
   ],
   "source": [
    "cw21(\"LEFT 10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "Write a program to compute the frequency of the words from the input. The output should output after sorting the key alphanumerically. \n",
    "Suppose the following input is supplied to the program:\n",
    "New to Python or choosing between Python 2 and Python 3? Read Python 2 or Python 3.\n",
    "Then, the output should be:\n",
    "\n",
    "2:2\n",
    "3.:1\n",
    "3?:1\n",
    "New:1\n",
    "Python:5\n",
    "Read:1\n",
    "and:1\n",
    "between:1\n",
    "choosing:1\n",
    "or:2\n",
    "to:1\n",
    "\n",
    "Hints\n",
    "In case of input data being supplied to the question, it should be assumed to be a console input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw22(words):\n",
    "    words = words.split(\" \")\n",
    "    output = {}\n",
    "    for word in words:\n",
    "        output[word] = output.get(word,0)+1\n",
    "    words = output.keys()\n",
    "    words= sorted(words)\n",
    "    for word in words:\n",
    "        print(\"%s:%d\" % (word,output[word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2:2\n",
      "3:1\n",
      "3?:1\n",
      "New:1\n",
      "Python:5\n",
      "Read:1\n",
      "and:1\n",
      "between:1\n",
      "choosing:1\n",
      "or:2\n",
      "to:1\n"
     ]
    }
   ],
   "source": [
    "cw22(\"New to Python or choosing between Python 2 and Python 3? Read Python 2 or Python 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 16\n",
    "\n",
    "\n",
    "from https://www.practicepython.org/exercise/2014/05/28/16-password-generator.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a password generator in Python. Be creative with how you generate passwords - strong passwords have a mix of lowercase letters, uppercase letters, numbers, and symbols. The passwords should be random, generating a new password every time the user asks for a new password. Include your run-time code in a main method.\n",
    "\n",
    "Extra:\n",
    "\n",
    "    Ask the user how strong they want their password to be. For weak passwords, pick a word or two from a list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def password_generator(number_of_digits, how_strong_password):\n",
    "    import random\n",
    "    import string\n",
    "    password = []\n",
    "    if how_strong_password == \"weak\":\n",
    "        number_of_digits = int(number_of_digits)\n",
    "        password = random.choices(string.ascii_lowercase, k=number_of_digits)\n",
    "        password = ''.join(password)\n",
    "        return password\n",
    "        print(password)\n",
    "    if how_strong_password == \"mid\":\n",
    "        number_of_digits = int(number_of_digits)\n",
    "        password = random.choices(string.digits + string.ascii_lowercase, k=number_of_digits)\n",
    "        password = ''.join(password)\n",
    "        return password\n",
    "        print(password)\n",
    "    if how_strong_password == \"strong\":\n",
    "        number_of_digits = int(number_of_digits)\n",
    "        password = random.choices(string.ascii_uppercase + string.digits + string.ascii_lowercase, k=number_of_digits)\n",
    "        password = ''.join(password)\n",
    "        return password\n",
    "        print(password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Az55fWaVJ7GdzproJNOZZkhfb'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "password_generator(25,\"strong\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 17\n",
    "\n",
    "from https://www.practicepython.org/exercise/2014/05/28/16-password-generator.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the BeautifulSoup and requests Python packages to print out a list of all the article titles on the New York Times homepage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title_new_york(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    req_for_title = requests.get(url)\n",
    "    req_for_title_html = req_for_title.text\n",
    "    soup = BeautifulSoup(req_for_title_html, \"html5lib\")\n",
    "    output_titles = []\n",
    "    titles = soup.findAll('h2', attrs={'class' : 'story-heading'})\n",
    "    for title in titles:\n",
    "        title = title.text.strip() \n",
    "        output_titles.append(title)\n",
    "    print(output_titles)\n",
    "    return output_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_title_new_york(\"https://www.nytimes.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 18\n",
    "\n",
    "from https://www.practicepython.org/exercise/2014/05/28/16-password-generator.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a program that will play the “cows and bulls” game with the user. The game works like this:\n",
    "\n",
    "Randomly generate a 4-digit number. Ask the user to guess a 4-digit number. For every digit that the user guessed correctly in the correct place, they have a “cow”. For every digit the user guessed correctly in the wrong place is a “bull.” Every time the user makes a guess, tell them how many “cows” and “bulls” they have. Once the user guesses the correct number, the game is over. Keep track of the number of guesses the user makes throughout teh game and tell the user at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cw18():\n",
    "    def __init__(self):\n",
    "        import random\n",
    "        import string\n",
    "        self.password = random.choices(string.digits, k=4)\n",
    "        self.attempts = 0\n",
    "    def check_num(self, user_number):\n",
    "        self.attempts += 1\n",
    "        user_number = str(user_number)\n",
    "        user_number = list(user_number)\n",
    "        if len(user_number) != 4:\n",
    "            return \"del liczbe z 4 cyframi\"\n",
    "        num_cows = 0\n",
    "        num_bulls = 0\n",
    "        if self.password == user_number:\n",
    "            print(\"win w: \", self.attempts)\n",
    "            return \n",
    "        # we itarate over user_number\n",
    "        for digit_user_number in user_number:\n",
    "            # we itarate over password\n",
    "            for digit_password in self.password:\n",
    "                if digit_user_number == digit_password:\n",
    "                    num_cows += 1  \n",
    "        num_bulls = 4 - num_cows\n",
    "        print(\"attempts: \",self.attempts)\n",
    "        print(\"password: \",self.password)          \n",
    "        print(\"num_cows: \",num_cows)\n",
    "        print(\"num_bulls: \",num_bulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cw18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempts:  1\n",
      "password:  ['3', '1', '3', '7']\n",
      "num_cows:  3\n",
      "num_bulls:  1\n"
     ]
    }
   ],
   "source": [
    "x.check_num(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 19\n",
    "https://www.practicepython.org/exercise/2014/07/14/19-decode-a-web-page-two.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the requests and BeautifulSoup Python libraries, print to the screen the full text of the article on this website: http://www.vanityfair.com/society/2014/06/monica-lewinsky-humiliation-culture.\n",
    "\n",
    "The article is long, so it is split up between 4 pages. Your task is to print out the text to the screen so that you can read the full article without having to click any buttons.\n",
    "\n",
    "(Hint: The post here describes in detail how to use the BeautifulSoup and requests libraries through the solution of the exercise posted here.)\n",
    "\n",
    "This will just print the full text of the article to the screen. It will not make it easy to read, so next exercise we will learn how to write this text to a .txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw19(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    req_for_title = requests.get(url)\n",
    "    req_for_title_html = req_for_title.text\n",
    "    soup = BeautifulSoup(req_for_title_html, \"html5lib\")\n",
    "    texts = soup.findAll('p')\n",
    "    output_text = []\n",
    "    for text in texts:\n",
    "        text = text.text.strip()\n",
    "        output_text.append(text)\n",
    "    print(output_text)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cw19(\"https://www.vanityfair.com/style/society/2014/06/monica-lewinsky-humiliation-culture\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 20\n",
    "https://www.practicepython.org/exercise/2014/11/11/20-element-search.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that takes an ordered list of numbers (a list where the elements are in order from smallest to largest) and another number. The function decides whether or not the given number is inside the list and returns (then prints) an appropriate boolean.\n",
    "\n",
    "Extras:\n",
    "\n",
    "    Use binary search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw20(num_list, num):\n",
    "    bol_value = num_list[0] < num and num_list[len(num_list)-1] > num\n",
    "    print(\"inside: \", bol_value)\n",
    "# ndont work\n",
    "def binary_search(num_list, num):\n",
    "    len_list = len(num_list)\n",
    "    left_side = 0\n",
    "    right_side = len_list - 1\n",
    "    while left_side <= right_side:\n",
    "        m = (left_side+right_side)/2\n",
    "        if num_list[m] < num:\n",
    "            left_side = m + 1\n",
    "        elif num_list[m] > num:\n",
    "            left_side = m - 1\n",
    "        else:\n",
    "            return m\n",
    "    return unsuccessful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside:  False\n"
     ]
    }
   ],
   "source": [
    "cw20([1, 3, 5, 30, 42, 43, 500],0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 21\n",
    "\n",
    "https://www.practicepython.org/exercise/2014/11/30/21-write-to-a-file.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the code from the How To Decode A Website exercise (if you didn’t do it or just want to play with some different code, use the code from the solution), and instead of printing the results to a screen, write the results to a txt file. In your code, just make up a name for the file you are saving to.\n",
    "\n",
    "Extras:\n",
    "\n",
    "    Ask the user to specify the name of the output file that will be saved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw21(file_name):\n",
    "    text = cw19(\"https://www.vanityfair.com/style/society/2014/06/monica-lewinsky-humiliation-culture\")\n",
    "    text = str(' '.join(text))\n",
    "    print(text)\n",
    "    with open(file_name, 'w', encoding='utf-8') as open_file:\n",
    "        open_file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['‘How does it feel to be America’s premier blow-job queen?”', 'It was early 2001. I was sitting on the stage of New York’s Cooper Union in the middle of taping a Q&A for an HBO documentary. I was the subject. And I was thunderstruck.', 'Hundreds of people in the audience, mostly students, were staring at me, many with their mouths agape, wondering if I would dare to answer this question.', 'The main reason I had agreed to participate in the program was not to rehash or revise the story line of Interngate but to try to shift the focus to meaningful issues. Many troubling political and judicial questions had been brought to light by the investigation and impeachment of President Bill Clinton. But the most egregious had been generally ignored. People seemed indifferent to the deeper matters at hand, such as the erosion of private life in the public sphere, the balance of power and gender inequality in politics and media, and the erosion of legal protections to ensure that neither a parent nor a child should ever have to testify against each other.', 'How naïve I was.', 'There were gasps and sputters from the audience. Numerous blurred, faceless people called out, “Don’t answer it!”', '“It’s hurtful and it’s insulting,” I said, attempting to gather my wits. “And as insulting as it is to me, it’s even more insulting to my family. I don’t actually know why this whole story became about oral sex. I don’t. It was a mutual relationship.… The fact that it did is maybe a result of a male-dominated society.”', 'The audience laughed. Maybe they were surprised to hear these words coming from me.', 'I looked straight at the smirking guy who had asked the question. “You might be better poised to answer that.” After a pause, I added, “That’s probably cost me another year of therapy.”', 'You could argue that in agreeing to participate in an HBO documentary called Monica in Black and White I had signed up to be shamed and publicly humiliated yet again. You might even think I would have been inured to humiliation. This encounter at Cooper Union, after all, paled in comparison with the 445-page Starr Report, which was the culmination of independent counsel Kenneth Starr’s four-year investigation of the Clinton White House. It included chapter and verse about my intimate sexual activities, along with transcripts of audiotapes that chronicled many of my private conversations. But the “B.J. Queen” question—which was included in the show when it aired on HBO in 2002—sat with me for a long time after the audience left and the taping wrapped.', 'True, this wasn’t the first time I’d been stigmatized for my affair with Bill Clinton. But never had I been so directly confronted, one-on-one, with such a crass characterization. One of the unintended consequences of my agreeing to put myself out there and to try to tell the truth had been that shame would once again be hung around my neck like a scarlet-A albatross. Believe me, once it’s on, it is a bitch to take off.', 'Had that awkward moment at Cooper Union aired only a few years later, with the advent of social media, the humiliation would have been even more devastating. That clip would have gone viral on Twitter, YouTube, Facebook, TMZ, Gawker. It would have become a meme of its own on Tumblr. The viralness itself would have merited mention on the Daily Beast and Huffington Post. As it was, it was viral enough, and, thanks to the all-encompassing nature of the Web, you can, 12 years later, watch it all day long on YouTube if you want to (but I really hope you have better things to do with your time).', 'I know I’m not alone when it comes to public humiliation. No one, it seems, can escape the unforgiving gaze of the Internet, where gossip, half-truths, and lies take root and fester. We have created, to borrow a term from historian Nicolaus Mills, a “culture of humiliation” that not only encourages and revels in Schadenfreude but also rewards those who humiliate others, from the ranks of the paparazzi to the gossip bloggers, the late-night comedians, and the Web “entrepreneurs” who profit from clandestine videos.', 'Yes, we’re all connected now. We can tweet a revolution in the streets or chronicle achievements large and small. But we’re also caught in a feedback loop of defame and shame, one in which we have become both perps and victims. We may not have become a crueler society—although it sure feels as if we have—but the Internet has seismically shifted the tone of our interactions. The ease, the speed, and the distance that our electronic devices afford us can also make us colder, more glib, and less concerned about the consequences of our pranks and prejudice. Having lived humiliation in the most intimate possible way, I marvel at how willingly we have all signed on to this new way of being.', 'In my own case, each easy click of that YouTube link reinforces the archetype, despite my efforts to parry it away: Me, America’s B.J. Queen. That Intern. That Vixen. Or, in the inescapable phrase of our 42nd president, “That Woman.”', 'It may surprise you to learn that I’m actually a person.', 'In 1998, when news of my affair with Bill Clinton broke, I was arguably the most humiliated person in the world. Thanks to the Drudge Report, I was also possibly the first person whose global humiliation was driven by the Internet.', 'For several years I tried my hand in the fashion-accessory business and became involved in various media projects, including the HBO documentary. Then I lay low for the most part. (The last major interview I granted was 10 years ago.) After all, not lying low had exposed me to criticism for trying to “capitalize” on my “notoriety.” Apparently, others talking about me is O.K.; me speaking out for myself is not. I turned down offers that would have earned me more than $10 million, because they didn’t feel like the right thing to do. Over time, the media circus quieted down, but it never quite moved on, even as I attempted to move on.', 'Meanwhile, I watched my friends’ lives move forward. Marriages. Kids. Degrees. (Second marriages. More kids. More degrees.) I decided to turn over a new leaf and attend grad school.', 'I moved to England to study, to challenge myself, to escape scrutiny, and to reimagine my identity. My professors and fellow students at the London School of Economics were wonderful—welcoming and respectful. I had more anonymity in London, perhaps due to the fact that I spent most of my waking hours in class or buried in the library. In 2006, I graduated with a master’s in social psychology. My master’s thesis examined social bias in the courtroom and was titled “In Search of the Impartial Juror: An Exploration of Pretrial Publicity and the Third Person Effect.” I liked to joke that I was trading the blue dress for blue stockings, and the degree provided new scaffolding to hang my life experiences on. It would also prove, so I hoped, to be a gateway to a more normal life.', 'I moved between London, Los Angeles, New York, and Portland, Oregon, interviewing for a variety of jobs that fell under the umbrella of “creative communication” and “branding,” with an emphasis on charity campaigns. Yet, because of what potential employers so tactfully referred to as my “history,” I was never “quite right” for the position. In some cases, I was right for all the wrong reasons, as in “Of course, your job would require you to attend our events.” And, of course, these would be events at which press would be in attendance.', 'In one promising job interview that took place during the run-up to the 2008 primary season, the conversation took an interesting turn. “So here’s the thing, Monica,” the interviewer said. “You’re clearly a bright young woman and affable, but for us—and probably any other organization that relies on grants and other government funding—it’s risky. We would first need a Letter of Indemnification from the Clintons. After all, there is a 25 percent chance that Mrs. Clinton will be the next president.” I gave a fake smile and said, “I understand.”', 'Another job interview, this one typical: walked into the stark, terminally cool reception area of a hip-yet-prestigious advertising agency in Los Angeles, my hometown. As always, I put on my best “I’m friendly, not a diva” smile. “Hi. Monica Lewinsky here to see So-and-So.”', 'The twentysomething receptionist pushed her black-rimmed hipster frames up her nose. “Monica who?”', 'Before I could answer, another twentysomething, in skinny jeans, plaid shirt, and bow tie, rushed over and interrupted: “ Ms. Lewinsky.” Like a maître d’, he continued, “Pleasure to have you here. I’ll let So-and-So know you’ve arrived. Soy latte? Green tea? Filtered water?”', 'I found myself sitting at a small round table, face-to-face with So-and-So, the agency’s head of strategy and planning. We talked. She kept wincing. This was not going well. I tried to keep myself from getting flustered. Now she was not only wincing but also clearing her throat. Was that perspiration on her brow? It hit me: she was nervous, in full-tic mode.', 'I’ve had to become adept at handling any number of reactions in social situations and job interviews. I get it: it must be disconcerting to sit across from “That Woman.” Needless to say, I didn’t get the position.', 'I eventually came to realize that traditional employment might not be an option for me. I’ve managed to get by (barely, at times) with my own projects, usually with start-ups that I have participated in, or with loans from friends and family.', 'In another job interview I was asked, “If you were a brand, which brand would you be?” Let me tell you, when you’re Monica Lewinsky, that is one loaded question.', 'In September of 2010, the culmination of these experiences began to snap into a broader context for me. A phone conversation with my mother shifted the lens through which I viewed my world. We were discussing the tragic death of Tyler Clementi. Tyler, you will recall, was an 18-year-old Rutgers freshman who was secretly streamed via Webcam kissing another man. Days later, after being derided and humiliated on social media, he committed suicide by jumping off the George Washington Bridge.', 'My mom wept. Sobbing, she kept repeating over and over, “How his parents must feel … his poor parents.”', 'It was an unbearably tragic event, and while hearing of it brought me to tears, too, I couldn’t quite grasp why my mom was so distraught. And then it dawned on me: she was reliving 1998, when she wouldn’t let me out of her sight. She was replaying those weeks when she stayed by my bed, night after night, because I, too, was suicidal. The shame, the scorn, and the fear that had been thrown at her daughter left her afraid that I would take my own life—a fear that I would be literally humiliated to death. (I have never actually attempted suicide, but I had strong suicidal temptations several times during the investigations and during one or two periods after.)', 'I would never be so presumptuous as to equate my own story with Tyler Clementi’s. After all, my public humiliation had been the result of my involvement with a world-renowned public figure—that is, a consequence of my own poor choices. But in that moment, when I felt the depths of my mother’s anguish, I wished I could have had a chance to have spoken to Tyler about how my love life, my sex life, my most private moments, my most sensitive secrets, had been broadcast around the globe. I wished I had been able to say to him that I knew a little of how it might have felt for him to be exposed before the world. And, as hard as it is to imagine surviving it, it is possible.', 'In the wake of Tyler’s tragedy, my own suffering took on a different meaning. Perhaps by sharing my story, I reasoned, I might be able to help others in their darkest moments of humiliation. The question became: How do I find and give a purpose to my past? It was my Prufrockian moment: “Do I dare / Disturb the universe?” Or, in my case, the Clinton universe.', 'Despite a decade of self-imposed silence, I have been periodically resuscitated as part of the national conversation, almost always in connection with the Clintons. For instance, in January and February of this year, Rand Paul, the Kentucky senator and a possible 2016 Republican presidential aspirant, managed to drag me into the pre-election muck. He fought back against the Democrats’ charges of a G.O.P. “war on women” by arguing that Bill Clinton had committed workplace “violence” and acted in a “predatory” manner against “a 20-year-old girl who was there from college.”', 'Sure, my boss took advantage of me, but I will always remain firm on this point: it was a consensual relationship. Any “abuse” came in the aftermath, when I was made a scapegoat in order to protect his powerful position.', 'So, trying to disappear has not kept me out of the fray. I am, for better or for worse, presumed to be a known quantity. Every day I am recognized. Every day. Sometimes a person will walk past me again and again, as if I wouldn’t notice. (Thankfully, 99.9 percent of the time when strangers do say something to me they are supportive and respectful.) Every day someone mentions me in a tweet or a blog post, and not altogether kindly. Every day, it seems, my name shows up in an op-ed column or a press clip or two—mentioned in passing in articles on subjects as disparate as millennials, Scandal, and French president François Hollande’s love life. Miley Cyrus references me in her twerking stage act, Eminem raps about me, and Beyoncé’s latest hit gives me a shout-out. Thanks, Beyoncé, but if we’re verbing, I think you meant “Bill Clinton’d all on my gown,” not “Monica Lewinsky’d.”', 'With every man I date (yes, I date!), I go through some degree of 1998 whiplash. I need to be extremely circumspect about what it means to be “public” with someone. In the early years post-impeachment, I once left a front-row seat along the third-base line at a Yankees game when I learned that my date—a guy whose company I thoroughly enjoyed—was actually in another relationship. It was only a green-card marriage, but I freaked that we could be photographed together and someone might call the gossip rags. I’ve become adept at figuring out when men are interested in me for the wrong reason. Thankfully, those have been few and far between. But every man that has been special to me over the past 16 years has helped me find another piece of myself—the self that was shattered in 1998. And so, no matter the heartbreak, tears, or disenchantment, I’ll always be grateful to them.', 'In February of this year, around the same time Senator Paul put me back into the unwanted spotlight, I became the “narcissistic loony toon,” the latest twist on Me as Archetype.', 'A snapshot of a scenario I’ve grown all too accustomed to, even as I attempt to move on with my life: A shrill ring interrupts the rhythms of my day. The call—from the doorman of the apartment building where I’m staying in New York—leads me to an exasperated “What? Again?” They’ve reappeared: the paparazzi, like swallows, have returned to the sidewalk outside, pacing and circling and pacing some more.', 'I hit the computer. Time for a little self-Google. (Oh, dear reader, please do not judge.) My heart sinks. There’s an explosion on Google News. I know what this means. Whatever day I’ve planned has been jettisoned. To leave the house—and risk a photo—only ensures that the story will stay alive.', 'The cameras have returned because of the headlines: a conservative Web site has gone poking around the University of Arkansas archive of one of Hillary Clinton’s closest friends and admirers, Diane Blair, and has unearthed a cache of memos from the 1990s. In some of them, Blair, who died in 2000, quotes the former First Lady about her husband’s relationship with me. Though Hillary, according to Blair’s notes, claimed to find her husband’s “lapse” inexcusable, she praised him for trying to “manage someone who was clearly a ‘narcissistic loony toon.’ ”', 'My first thought, as I was getting up to speed: If that’s the worst thing she said, I should be so lucky. Mrs. Clinton, I read, had supposedly confided to Blair that, in part, she blamed herself for her husband’s affair (by being emotionally neglectful) and seemed to forgive him. Although she regarded Bill as having engaged in “gross inappropriate behavior,” the affair was, nonetheless, “consensual (was not a power relationship).”', 'I field the usual calls from friends who lend moral support whenever these volcanic media stories erupt. They diffuse the tension with good-natured teasing: “So, are we changing your monogram to NLT?” I try to ignore the former First Lady’s long-buried comments. Given my experiences with Linda Tripp, I know better than anyone what it’s like to have a conversation with a girlfriend exposed and scrutinized, taken out of context. But, even so, it begins to gnaw at me. I realize that Hillary Clinton was—unlike me when Tripp was prying loose my innermost secrets and insecurities and recording them surreptitiously—fully aware of this documentation: she’s the one who, according to the memos, asked Blair to keep a record or diary of their discussions for archival purposes.', 'Yes, I get it. Hillary Clinton wanted it on record that she was lashing out at her husband’s mistress. She may have faulted her husband for being inappropriate, but I find her impulse to blame the Woman—not only me, but herself—troubling. And all too familiar: with every marital indiscretion that finds its way into the public sphere—many of which involve male politicians—it always seems like the woman conveniently takes the fall. Sure, the Anthony Weiners and Eliot Spitzers do what they need to do to look humiliated on cable news. They bow out of public life for a while, but they inevitably return, having put it all behind them. The women in these imbroglios return to lives that are not so easily repaired.', 'But there is another layer here that is making me bristle: Narcissist? Loony?', 'You might remember that just five days before the world had ever heard my name the F.B.I.—after my friend Linda Tripp approached Special Prosecutor Kenneth Starr’s office with information about my affair with the president—entrapped me in a terrifying “sting” in the Pentagon City mall. At age 24, cornered in a hotel room on January 16, 1998, with mainly male interrogators taking orders from Starr, I was discouraged from contacting my attorney and threatened with 27 years in jail for filing an affidavit denying the affair with Clinton, among other alleged crimes. I was offered immunity from that threat if I agreed to place monitored calls and wear a wire in conversations with two of the president’s confidants and possibly the president himself. I refused. Confiding in Linda Tripp turned into an unintended betrayal. But this? The mother of all betrayals. That, I couldn’t do. Courageous or foolish, maybe, but narcissistic and loony?', 'These 16-year-old descriptions of me triggered memories of past anguish, particularly in the area of women lobbing derision at one another. So where, you might be wondering, were the feminists back then?', 'It’s a question that troubles me to this day.', 'I sorely wished for some sign of understanding from the feminist camp. Some good, old-fashioned, girl-on-girl support was much in need. None came. Given the issues at play—gender politics, sex in the workplace—you’d think they would have spoken up. They didn’t. I understood their dilemma: Bill Clinton had been a president “friendly” to women’s causes.', 'It also didn’t help that my case was not one of conventional “sexual harassment”; that charge against Bill Clinton had been made by Paula Jones, who brought a colossal lawsuit against him. My name surfaced only because, thanks to newly won advances by feminists, investigations of such cases were now allowed to cast a wider net. The Jones case became a stick that the right wing used to strike back at the Clinton-supporting feminists: Why wouldn’t they enthusiastically support an investigation into a case of sexual harassment? What if the president had been a Republican? Charges of hypocrisy flew.', 'A handful of representatives of the modern feminist movement did chime in, obliquely. Yet, instead of any meaningful engagement, we got this: January 30, 1998. Day Nine of the scandal. Cocktails at Le Bernardin, in Manhattan. In attendance: writers Erica Jong, Nancy Friday, Katie Roiphe, and Elizabeth Benedict; Saturday Night Live writer Patricia Marx; Marisa Bowe, the editor of Word, an online magazine; fashion designer Nicole Miller; former dominatrix Susan Shellogg; and their host, Le Bernardin co-owner Maguy Le Coze. The New York Observer brought this coven together to trade Interngate insights, to be recorded by Francine Prose. (Sadly, the gal who would really make this coven complete is missing: Maureen Dowd, or Moremean Dowdy, as I used to refer to her. Today, I’d meet her for a drink.)', 'Oh, to have been at that cocktail party:', 'Marisa Bowe: His whole life is about having to be in control and really intelligent all the time. And his wife is really intelligent and in control all the time. And the idea of just having stupid sex with some not-brilliant woman in the Oval Office, I can see the appeal in that.', 'Imaginary Me: I’m not saying I’m brilliant, but how do you know I’m not? My first job out of college was at the White House.', 'Susan Shellogg: And do you think it’s tremendously selfish? Selfish and demanding, having oral sex and not reciprocating? I mean … she didn’t say, “Well, you know he satisfied me.”', 'Me: And where exactly “didn’t” I say this? In which public statement that I didn’t make? In which testimony that’s not been released?', 'Katie Roiphe: I think what people are outraged about is the way that [Monica Lewinsky] looks, which is interesting. Because we like to think of our presidents as sort of godlike, and so if J.F.K. has an affair with Marilyn Monroe, it’s all in the realm of the demigods…. I mean, the thing I kept hearing over and over again was Monica Lewinsky’s not that pretty.', 'Me: Well, thanks. The first picture that surfaced was a passport photo. Would you like to have a passport photo splattered across publications around the world as the picture that defines you?', 'What you are also saying here is that the primary quality that would qualify a woman to have an intimate relationship with a powerful man is physical attractiveness. If that’s not setting the movement back, I don’t know what is.', 'Erica Jong: My dental hygienist pointed out that she had third-stage gum disease.', 'Shellogg: What do you think will happen to [her]? I mean, she’ll just fade out quietly or write a book? Or people will forget about her six months from now?', 'Nancy Friday: She can rent out her mouth.', 'Me: (Speechless.)', 'Jong: But, you know, men do like to get close to the mouth that has been close to power. Think of the fantasy in the man’s mind as she’s going down on him and he’s thinking, “Oh my God.”', 'Elizabeth Benedict: Do for me what you did to the President. Do that.', 'Me: (Still speechless.)', 'Jong: I think it’s a tribute to how far we’ve come that we’re not trashing Monica Lewinsky.', 'The catty confab appeared under the headline SUPERGALS LOVE THAT NAUGHTY PREZ. (Writing in Vanity Fair, Marjorie Williams called it “the most embarrassing thing I had read in a long time.”) To me, it illustrates a perplexing aspect of the culture of humiliation, one that Phyllis Chesler recognized in her book Woman’s Inhumanity to Woman: that women themselves are not immune to certain kinds of misogyny. We see it today in how the “mean girls” at school lurk on the modern playground of the Web (or around a pundit’s roundtable on TV or at a French restaurant), ever eager to pile on.', 'I still have deep respect for feminism and am thankful for the great strides the movement has made in advancing women’s rights over the past few decades. But, given my experience of being passed around like gender-politics cocktail food, I don’t identify myself as a Feminist, capital F. The movement’s leaders failed in articulating a position that was not essentially anti-woman during the witch hunt of 1998. In the case of the New York Supergals, it should not have been that hard for them to swoon over the president without attacking and shaming me. Instead, they joined the humiliation derby.', 'I , myself, deeply regret what happened between me and President Clinton. Let me say it again: I. Myself. Deeply. Regret. What. Happened. At the time—at least from my point of view—it was an authentic connection, with emotional intimacy, frequent visits, plans made, phone calls and gifts exchanged. In my early 20s, I was too young to understand the real-life consequences, and too young to see that I would be sacrificed for political expediency. I look back now, shake my head in disbelief, and wonder: what was I—what were we—thinking? I would give anything to go back and rewind the tape.', 'Like many other Americans, I’ve been thinking about Hillary Clinton. What might happen, I’ve wondered, if she does run in 2016? And what if she wins—and then wins a second term?', 'But when I think about these matters, there’s a dimension at play for me other than just the fact that we might finally have a woman in the White House. We all remember the second-wave feminist rallying cry The personal is political. Many people (myself included) proclaimed that my relationship with Bill Clinton was a personal matter, not one to be used in a high-stakes political war. When I hear of Hillary’s prospective candidacy, I cannot help but fear the next wave of paparazzi, the next wave of “Where is she now?” stories, the next reference to me in Fox News’s coverage of the primaries. I’ve begun to find it debilitating to plot out the cycle of my life based, to some degree, on the political calendar. For me, it’s a scenario in which the personal and the political are impossible to separate.', 'In 2008, when Hillary was running for president, I remained virtually reclusive, despite being inundated with press requests. I put off announcing several media projects in 2012 until after the election. (They were subsequently canceled—and, no, I wasn’t offered $12 million for a salacious tell-all book, contrary to press reports.) And recently I’ve found myself gun-shy yet again, fearful of “becoming an issue” should she decide to ramp up her campaign. But should I put my life on hold for another 8 to 10 years?', 'Being a conscientious Democrat—and aware that I could be used as a tool for the left or the right—I have remained silent for 10 years. So silent, in fact, that the buzz in some circles has been that the Clintons must have paid me off; why else would I have refrained from speaking out? I can assure you that nothing could be further from the truth.', 'So why speak now? Because it is time.', 'I turned 40 last year, and it is time to stop tiptoeing around my past—and other people’s futures. I am determined to have a different ending to my story. I’ve decided, finally, to stick my head above the parapet so that I can take back my narrative and give a purpose to my past. (What this will cost me, I will soon find out.) Despite what some headlines will falsely report about this piece, this is not about Me versus the Clintons. Their lives have moved on; they occupy important and powerful places on the global stage. I wish them no ill. And I fully understand that what has happened to me and the issue of my future do not matter to either of them.', 'It also goes back to the personal and the political. I have lived many of the questions that have become central to our national discourse since 1998. How far should we allow the government into our bedrooms? How do we reconcile the right to privacy with the need to expose sexual indiscretion? How do we guard against an overzealous government demanding our private data and information? And, most important to me personally, how do we cope with the shame game as it’s played in the Internet Age? (My current goal is to get involved with efforts on behalf of victims of online humiliation and harassment and to start speaking on this topic in public forums.)', 'So far, That Woman has never been able to escape the shadow of that first depiction. I was the Unstable Stalker (a phrase disseminated by the Clinton White House), the Dimwit Floozy, the Poor Innocent who didn’t know any better. The Clinton administration, the special prosecutor’s minions, the political operatives on both sides of the aisle, and the media were able to brand me. And that brand stuck, in part because it was imbued with power. I became a social representation, a social canvas on which anybody could project their confusion about women, sex, infidelity, politics, and body issues.', 'Unlike the other parties involved, I was so young that I had no established identity to which I could return. I didn’t “let this define” me—I simply hadn’t had the life experience to establish my own identity in 1998. If you haven’t figured out who you are, it’s hard not to accept the horrible image of you created by others. (Thus, my compassion for young people who find themselves shamed on the Web.) Despite much self-searching and therapy and exploring of different paths, I remained “stuck” for far too many years.', 'No longer. It’s time to burn the beret and bury the blue dress. And move forward.', 'Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement.', 'Condé Nast', '© 2018 Condé Nast. All rights reserved.', 'Use of and/or registration on any portion of this site constitutes acceptance of our User Agreement (updated 5/28/18) and Privacy Policy and Cookie Statement (updated 5/28/18).', 'Your CA Privacy Rights.', 'The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.', 'Ad Choices']\n",
      "‘How does it feel to be America’s premier blow-job queen?” It was early 2001. I was sitting on the stage of New York’s Cooper Union in the middle of taping a Q&A for an HBO documentary. I was the subject. And I was thunderstruck. Hundreds of people in the audience, mostly students, were staring at me, many with their mouths agape, wondering if I would dare to answer this question. The main reason I had agreed to participate in the program was not to rehash or revise the story line of Interngate but to try to shift the focus to meaningful issues. Many troubling political and judicial questions had been brought to light by the investigation and impeachment of President Bill Clinton. But the most egregious had been generally ignored. People seemed indifferent to the deeper matters at hand, such as the erosion of private life in the public sphere, the balance of power and gender inequality in politics and media, and the erosion of legal protections to ensure that neither a parent nor a child should ever have to testify against each other. How naïve I was. There were gasps and sputters from the audience. Numerous blurred, faceless people called out, “Don’t answer it!” “It’s hurtful and it’s insulting,” I said, attempting to gather my wits. “And as insulting as it is to me, it’s even more insulting to my family. I don’t actually know why this whole story became about oral sex. I don’t. It was a mutual relationship.… The fact that it did is maybe a result of a male-dominated society.” The audience laughed. Maybe they were surprised to hear these words coming from me. I looked straight at the smirking guy who had asked the question. “You might be better poised to answer that.” After a pause, I added, “That’s probably cost me another year of therapy.” You could argue that in agreeing to participate in an HBO documentary called Monica in Black and White I had signed up to be shamed and publicly humiliated yet again. You might even think I would have been inured to humiliation. This encounter at Cooper Union, after all, paled in comparison with the 445-page Starr Report, which was the culmination of independent counsel Kenneth Starr’s four-year investigation of the Clinton White House. It included chapter and verse about my intimate sexual activities, along with transcripts of audiotapes that chronicled many of my private conversations. But the “B.J. Queen” question—which was included in the show when it aired on HBO in 2002—sat with me for a long time after the audience left and the taping wrapped. True, this wasn’t the first time I’d been stigmatized for my affair with Bill Clinton. But never had I been so directly confronted, one-on-one, with such a crass characterization. One of the unintended consequences of my agreeing to put myself out there and to try to tell the truth had been that shame would once again be hung around my neck like a scarlet-A albatross. Believe me, once it’s on, it is a bitch to take off. Had that awkward moment at Cooper Union aired only a few years later, with the advent of social media, the humiliation would have been even more devastating. That clip would have gone viral on Twitter, YouTube, Facebook, TMZ, Gawker. It would have become a meme of its own on Tumblr. The viralness itself would have merited mention on the Daily Beast and Huffington Post. As it was, it was viral enough, and, thanks to the all-encompassing nature of the Web, you can, 12 years later, watch it all day long on YouTube if you want to (but I really hope you have better things to do with your time). I know I’m not alone when it comes to public humiliation. No one, it seems, can escape the unforgiving gaze of the Internet, where gossip, half-truths, and lies take root and fester. We have created, to borrow a term from historian Nicolaus Mills, a “culture of humiliation” that not only encourages and revels in Schadenfreude but also rewards those who humiliate others, from the ranks of the paparazzi to the gossip bloggers, the late-night comedians, and the Web “entrepreneurs” who profit from clandestine videos. Yes, we’re all connected now. We can tweet a revolution in the streets or chronicle achievements large and small. But we’re also caught in a feedback loop of defame and shame, one in which we have become both perps and victims. We may not have become a crueler society—although it sure feels as if we have—but the Internet has seismically shifted the tone of our interactions. The ease, the speed, and the distance that our electronic devices afford us can also make us colder, more glib, and less concerned about the consequences of our pranks and prejudice. Having lived humiliation in the most intimate possible way, I marvel at how willingly we have all signed on to this new way of being. In my own case, each easy click of that YouTube link reinforces the archetype, despite my efforts to parry it away: Me, America’s B.J. Queen. That Intern. That Vixen. Or, in the inescapable phrase of our 42nd president, “That Woman.” It may surprise you to learn that I’m actually a person. In 1998, when news of my affair with Bill Clinton broke, I was arguably the most humiliated person in the world. Thanks to the Drudge Report, I was also possibly the first person whose global humiliation was driven by the Internet. For several years I tried my hand in the fashion-accessory business and became involved in various media projects, including the HBO documentary. Then I lay low for the most part. (The last major interview I granted was 10 years ago.) After all, not lying low had exposed me to criticism for trying to “capitalize” on my “notoriety.” Apparently, others talking about me is O.K.; me speaking out for myself is not. I turned down offers that would have earned me more than $10 million, because they didn’t feel like the right thing to do. Over time, the media circus quieted down, but it never quite moved on, even as I attempted to move on. Meanwhile, I watched my friends’ lives move forward. Marriages. Kids. Degrees. (Second marriages. More kids. More degrees.) I decided to turn over a new leaf and attend grad school. I moved to England to study, to challenge myself, to escape scrutiny, and to reimagine my identity. My professors and fellow students at the London School of Economics were wonderful—welcoming and respectful. I had more anonymity in London, perhaps due to the fact that I spent most of my waking hours in class or buried in the library. In 2006, I graduated with a master’s in social psychology. My master’s thesis examined social bias in the courtroom and was titled “In Search of the Impartial Juror: An Exploration of Pretrial Publicity and the Third Person Effect.” I liked to joke that I was trading the blue dress for blue stockings, and the degree provided new scaffolding to hang my life experiences on. It would also prove, so I hoped, to be a gateway to a more normal life. I moved between London, Los Angeles, New York, and Portland, Oregon, interviewing for a variety of jobs that fell under the umbrella of “creative communication” and “branding,” with an emphasis on charity campaigns. Yet, because of what potential employers so tactfully referred to as my “history,” I was never “quite right” for the position. In some cases, I was right for all the wrong reasons, as in “Of course, your job would require you to attend our events.” And, of course, these would be events at which press would be in attendance. In one promising job interview that took place during the run-up to the 2008 primary season, the conversation took an interesting turn. “So here’s the thing, Monica,” the interviewer said. “You’re clearly a bright young woman and affable, but for us—and probably any other organization that relies on grants and other government funding—it’s risky. We would first need a Letter of Indemnification from the Clintons. After all, there is a 25 percent chance that Mrs. Clinton will be the next president.” I gave a fake smile and said, “I understand.” Another job interview, this one typical: walked into the stark, terminally cool reception area of a hip-yet-prestigious advertising agency in Los Angeles, my hometown. As always, I put on my best “I’m friendly, not a diva” smile. “Hi. Monica Lewinsky here to see So-and-So.” The twentysomething receptionist pushed her black-rimmed hipster frames up her nose. “Monica who?” Before I could answer, another twentysomething, in skinny jeans, plaid shirt, and bow tie, rushed over and interrupted: “ Ms. Lewinsky.” Like a maître d’, he continued, “Pleasure to have you here. I’ll let So-and-So know you’ve arrived. Soy latte? Green tea? Filtered water?” I found myself sitting at a small round table, face-to-face with So-and-So, the agency’s head of strategy and planning. We talked. She kept wincing. This was not going well. I tried to keep myself from getting flustered. Now she was not only wincing but also clearing her throat. Was that perspiration on her brow? It hit me: she was nervous, in full-tic mode. I’ve had to become adept at handling any number of reactions in social situations and job interviews. I get it: it must be disconcerting to sit across from “That Woman.” Needless to say, I didn’t get the position. I eventually came to realize that traditional employment might not be an option for me. I’ve managed to get by (barely, at times) with my own projects, usually with start-ups that I have participated in, or with loans from friends and family. In another job interview I was asked, “If you were a brand, which brand would you be?” Let me tell you, when you’re Monica Lewinsky, that is one loaded question. In September of 2010, the culmination of these experiences began to snap into a broader context for me. A phone conversation with my mother shifted the lens through which I viewed my world. We were discussing the tragic death of Tyler Clementi. Tyler, you will recall, was an 18-year-old Rutgers freshman who was secretly streamed via Webcam kissing another man. Days later, after being derided and humiliated on social media, he committed suicide by jumping off the George Washington Bridge. My mom wept. Sobbing, she kept repeating over and over, “How his parents must feel … his poor parents.” It was an unbearably tragic event, and while hearing of it brought me to tears, too, I couldn’t quite grasp why my mom was so distraught. And then it dawned on me: she was reliving 1998, when she wouldn’t let me out of her sight. She was replaying those weeks when she stayed by my bed, night after night, because I, too, was suicidal. The shame, the scorn, and the fear that had been thrown at her daughter left her afraid that I would take my own life—a fear that I would be literally humiliated to death. (I have never actually attempted suicide, but I had strong suicidal temptations several times during the investigations and during one or two periods after.) I would never be so presumptuous as to equate my own story with Tyler Clementi’s. After all, my public humiliation had been the result of my involvement with a world-renowned public figure—that is, a consequence of my own poor choices. But in that moment, when I felt the depths of my mother’s anguish, I wished I could have had a chance to have spoken to Tyler about how my love life, my sex life, my most private moments, my most sensitive secrets, had been broadcast around the globe. I wished I had been able to say to him that I knew a little of how it might have felt for him to be exposed before the world. And, as hard as it is to imagine surviving it, it is possible. In the wake of Tyler’s tragedy, my own suffering took on a different meaning. Perhaps by sharing my story, I reasoned, I might be able to help others in their darkest moments of humiliation. The question became: How do I find and give a purpose to my past? It was my Prufrockian moment: “Do I dare / Disturb the universe?” Or, in my case, the Clinton universe. Despite a decade of self-imposed silence, I have been periodically resuscitated as part of the national conversation, almost always in connection with the Clintons. For instance, in January and February of this year, Rand Paul, the Kentucky senator and a possible 2016 Republican presidential aspirant, managed to drag me into the pre-election muck. He fought back against the Democrats’ charges of a G.O.P. “war on women” by arguing that Bill Clinton had committed workplace “violence” and acted in a “predatory” manner against “a 20-year-old girl who was there from college.” Sure, my boss took advantage of me, but I will always remain firm on this point: it was a consensual relationship. Any “abuse” came in the aftermath, when I was made a scapegoat in order to protect his powerful position. So, trying to disappear has not kept me out of the fray. I am, for better or for worse, presumed to be a known quantity. Every day I am recognized. Every day. Sometimes a person will walk past me again and again, as if I wouldn’t notice. (Thankfully, 99.9 percent of the time when strangers do say something to me they are supportive and respectful.) Every day someone mentions me in a tweet or a blog post, and not altogether kindly. Every day, it seems, my name shows up in an op-ed column or a press clip or two—mentioned in passing in articles on subjects as disparate as millennials, Scandal, and French president François Hollande’s love life. Miley Cyrus references me in her twerking stage act, Eminem raps about me, and Beyoncé’s latest hit gives me a shout-out. Thanks, Beyoncé, but if we’re verbing, I think you meant “Bill Clinton’d all on my gown,” not “Monica Lewinsky’d.” With every man I date (yes, I date!), I go through some degree of 1998 whiplash. I need to be extremely circumspect about what it means to be “public” with someone. In the early years post-impeachment, I once left a front-row seat along the third-base line at a Yankees game when I learned that my date—a guy whose company I thoroughly enjoyed—was actually in another relationship. It was only a green-card marriage, but I freaked that we could be photographed together and someone might call the gossip rags. I’ve become adept at figuring out when men are interested in me for the wrong reason. Thankfully, those have been few and far between. But every man that has been special to me over the past 16 years has helped me find another piece of myself—the self that was shattered in 1998. And so, no matter the heartbreak, tears, or disenchantment, I’ll always be grateful to them. In February of this year, around the same time Senator Paul put me back into the unwanted spotlight, I became the “narcissistic loony toon,” the latest twist on Me as Archetype. A snapshot of a scenario I’ve grown all too accustomed to, even as I attempt to move on with my life: A shrill ring interrupts the rhythms of my day. The call—from the doorman of the apartment building where I’m staying in New York—leads me to an exasperated “What? Again?” They’ve reappeared: the paparazzi, like swallows, have returned to the sidewalk outside, pacing and circling and pacing some more. I hit the computer. Time for a little self-Google. (Oh, dear reader, please do not judge.) My heart sinks. There’s an explosion on Google News. I know what this means. Whatever day I’ve planned has been jettisoned. To leave the house—and risk a photo—only ensures that the story will stay alive. The cameras have returned because of the headlines: a conservative Web site has gone poking around the University of Arkansas archive of one of Hillary Clinton’s closest friends and admirers, Diane Blair, and has unearthed a cache of memos from the 1990s. In some of them, Blair, who died in 2000, quotes the former First Lady about her husband’s relationship with me. Though Hillary, according to Blair’s notes, claimed to find her husband’s “lapse” inexcusable, she praised him for trying to “manage someone who was clearly a ‘narcissistic loony toon.’ ” My first thought, as I was getting up to speed: If that’s the worst thing she said, I should be so lucky. Mrs. Clinton, I read, had supposedly confided to Blair that, in part, she blamed herself for her husband’s affair (by being emotionally neglectful) and seemed to forgive him. Although she regarded Bill as having engaged in “gross inappropriate behavior,” the affair was, nonetheless, “consensual (was not a power relationship).” I field the usual calls from friends who lend moral support whenever these volcanic media stories erupt. They diffuse the tension with good-natured teasing: “So, are we changing your monogram to NLT?” I try to ignore the former First Lady’s long-buried comments. Given my experiences with Linda Tripp, I know better than anyone what it’s like to have a conversation with a girlfriend exposed and scrutinized, taken out of context. But, even so, it begins to gnaw at me. I realize that Hillary Clinton was—unlike me when Tripp was prying loose my innermost secrets and insecurities and recording them surreptitiously—fully aware of this documentation: she’s the one who, according to the memos, asked Blair to keep a record or diary of their discussions for archival purposes. Yes, I get it. Hillary Clinton wanted it on record that she was lashing out at her husband’s mistress. She may have faulted her husband for being inappropriate, but I find her impulse to blame the Woman—not only me, but herself—troubling. And all too familiar: with every marital indiscretion that finds its way into the public sphere—many of which involve male politicians—it always seems like the woman conveniently takes the fall. Sure, the Anthony Weiners and Eliot Spitzers do what they need to do to look humiliated on cable news. They bow out of public life for a while, but they inevitably return, having put it all behind them. The women in these imbroglios return to lives that are not so easily repaired. But there is another layer here that is making me bristle: Narcissist? Loony? You might remember that just five days before the world had ever heard my name the F.B.I.—after my friend Linda Tripp approached Special Prosecutor Kenneth Starr’s office with information about my affair with the president—entrapped me in a terrifying “sting” in the Pentagon City mall. At age 24, cornered in a hotel room on January 16, 1998, with mainly male interrogators taking orders from Starr, I was discouraged from contacting my attorney and threatened with 27 years in jail for filing an affidavit denying the affair with Clinton, among other alleged crimes. I was offered immunity from that threat if I agreed to place monitored calls and wear a wire in conversations with two of the president’s confidants and possibly the president himself. I refused. Confiding in Linda Tripp turned into an unintended betrayal. But this? The mother of all betrayals. That, I couldn’t do. Courageous or foolish, maybe, but narcissistic and loony? These 16-year-old descriptions of me triggered memories of past anguish, particularly in the area of women lobbing derision at one another. So where, you might be wondering, were the feminists back then? It’s a question that troubles me to this day. I sorely wished for some sign of understanding from the feminist camp. Some good, old-fashioned, girl-on-girl support was much in need. None came. Given the issues at play—gender politics, sex in the workplace—you’d think they would have spoken up. They didn’t. I understood their dilemma: Bill Clinton had been a president “friendly” to women’s causes. It also didn’t help that my case was not one of conventional “sexual harassment”; that charge against Bill Clinton had been made by Paula Jones, who brought a colossal lawsuit against him. My name surfaced only because, thanks to newly won advances by feminists, investigations of such cases were now allowed to cast a wider net. The Jones case became a stick that the right wing used to strike back at the Clinton-supporting feminists: Why wouldn’t they enthusiastically support an investigation into a case of sexual harassment? What if the president had been a Republican? Charges of hypocrisy flew. A handful of representatives of the modern feminist movement did chime in, obliquely. Yet, instead of any meaningful engagement, we got this: January 30, 1998. Day Nine of the scandal. Cocktails at Le Bernardin, in Manhattan. In attendance: writers Erica Jong, Nancy Friday, Katie Roiphe, and Elizabeth Benedict; Saturday Night Live writer Patricia Marx; Marisa Bowe, the editor of Word, an online magazine; fashion designer Nicole Miller; former dominatrix Susan Shellogg; and their host, Le Bernardin co-owner Maguy Le Coze. The New York Observer brought this coven together to trade Interngate insights, to be recorded by Francine Prose. (Sadly, the gal who would really make this coven complete is missing: Maureen Dowd, or Moremean Dowdy, as I used to refer to her. Today, I’d meet her for a drink.) Oh, to have been at that cocktail party: Marisa Bowe: His whole life is about having to be in control and really intelligent all the time. And his wife is really intelligent and in control all the time. And the idea of just having stupid sex with some not-brilliant woman in the Oval Office, I can see the appeal in that. Imaginary Me: I’m not saying I’m brilliant, but how do you know I’m not? My first job out of college was at the White House. Susan Shellogg: And do you think it’s tremendously selfish? Selfish and demanding, having oral sex and not reciprocating? I mean … she didn’t say, “Well, you know he satisfied me.” Me: And where exactly “didn’t” I say this? In which public statement that I didn’t make? In which testimony that’s not been released? Katie Roiphe: I think what people are outraged about is the way that [Monica Lewinsky] looks, which is interesting. Because we like to think of our presidents as sort of godlike, and so if J.F.K. has an affair with Marilyn Monroe, it’s all in the realm of the demigods…. I mean, the thing I kept hearing over and over again was Monica Lewinsky’s not that pretty. Me: Well, thanks. The first picture that surfaced was a passport photo. Would you like to have a passport photo splattered across publications around the world as the picture that defines you? What you are also saying here is that the primary quality that would qualify a woman to have an intimate relationship with a powerful man is physical attractiveness. If that’s not setting the movement back, I don’t know what is. Erica Jong: My dental hygienist pointed out that she had third-stage gum disease. Shellogg: What do you think will happen to [her]? I mean, she’ll just fade out quietly or write a book? Or people will forget about her six months from now? Nancy Friday: She can rent out her mouth. Me: (Speechless.) Jong: But, you know, men do like to get close to the mouth that has been close to power. Think of the fantasy in the man’s mind as she’s going down on him and he’s thinking, “Oh my God.” Elizabeth Benedict: Do for me what you did to the President. Do that. Me: (Still speechless.) Jong: I think it’s a tribute to how far we’ve come that we’re not trashing Monica Lewinsky. The catty confab appeared under the headline SUPERGALS LOVE THAT NAUGHTY PREZ. (Writing in Vanity Fair, Marjorie Williams called it “the most embarrassing thing I had read in a long time.”) To me, it illustrates a perplexing aspect of the culture of humiliation, one that Phyllis Chesler recognized in her book Woman’s Inhumanity to Woman: that women themselves are not immune to certain kinds of misogyny. We see it today in how the “mean girls” at school lurk on the modern playground of the Web (or around a pundit’s roundtable on TV or at a French restaurant), ever eager to pile on. I still have deep respect for feminism and am thankful for the great strides the movement has made in advancing women’s rights over the past few decades. But, given my experience of being passed around like gender-politics cocktail food, I don’t identify myself as a Feminist, capital F. The movement’s leaders failed in articulating a position that was not essentially anti-woman during the witch hunt of 1998. In the case of the New York Supergals, it should not have been that hard for them to swoon over the president without attacking and shaming me. Instead, they joined the humiliation derby. I , myself, deeply regret what happened between me and President Clinton. Let me say it again: I. Myself. Deeply. Regret. What. Happened. At the time—at least from my point of view—it was an authentic connection, with emotional intimacy, frequent visits, plans made, phone calls and gifts exchanged. In my early 20s, I was too young to understand the real-life consequences, and too young to see that I would be sacrificed for political expediency. I look back now, shake my head in disbelief, and wonder: what was I—what were we—thinking? I would give anything to go back and rewind the tape. Like many other Americans, I’ve been thinking about Hillary Clinton. What might happen, I’ve wondered, if she does run in 2016? And what if she wins—and then wins a second term? But when I think about these matters, there’s a dimension at play for me other than just the fact that we might finally have a woman in the White House. We all remember the second-wave feminist rallying cry The personal is political. Many people (myself included) proclaimed that my relationship with Bill Clinton was a personal matter, not one to be used in a high-stakes political war. When I hear of Hillary’s prospective candidacy, I cannot help but fear the next wave of paparazzi, the next wave of “Where is she now?” stories, the next reference to me in Fox News’s coverage of the primaries. I’ve begun to find it debilitating to plot out the cycle of my life based, to some degree, on the political calendar. For me, it’s a scenario in which the personal and the political are impossible to separate. In 2008, when Hillary was running for president, I remained virtually reclusive, despite being inundated with press requests. I put off announcing several media projects in 2012 until after the election. (They were subsequently canceled—and, no, I wasn’t offered $12 million for a salacious tell-all book, contrary to press reports.) And recently I’ve found myself gun-shy yet again, fearful of “becoming an issue” should she decide to ramp up her campaign. But should I put my life on hold for another 8 to 10 years? Being a conscientious Democrat—and aware that I could be used as a tool for the left or the right—I have remained silent for 10 years. So silent, in fact, that the buzz in some circles has been that the Clintons must have paid me off; why else would I have refrained from speaking out? I can assure you that nothing could be further from the truth. So why speak now? Because it is time. I turned 40 last year, and it is time to stop tiptoeing around my past—and other people’s futures. I am determined to have a different ending to my story. I’ve decided, finally, to stick my head above the parapet so that I can take back my narrative and give a purpose to my past. (What this will cost me, I will soon find out.) Despite what some headlines will falsely report about this piece, this is not about Me versus the Clintons. Their lives have moved on; they occupy important and powerful places on the global stage. I wish them no ill. And I fully understand that what has happened to me and the issue of my future do not matter to either of them. It also goes back to the personal and the political. I have lived many of the questions that have become central to our national discourse since 1998. How far should we allow the government into our bedrooms? How do we reconcile the right to privacy with the need to expose sexual indiscretion? How do we guard against an overzealous government demanding our private data and information? And, most important to me personally, how do we cope with the shame game as it’s played in the Internet Age? (My current goal is to get involved with efforts on behalf of victims of online humiliation and harassment and to start speaking on this topic in public forums.) So far, That Woman has never been able to escape the shadow of that first depiction. I was the Unstable Stalker (a phrase disseminated by the Clinton White House), the Dimwit Floozy, the Poor Innocent who didn’t know any better. The Clinton administration, the special prosecutor’s minions, the political operatives on both sides of the aisle, and the media were able to brand me. And that brand stuck, in part because it was imbued with power. I became a social representation, a social canvas on which anybody could project their confusion about women, sex, infidelity, politics, and body issues. Unlike the other parties involved, I was so young that I had no established identity to which I could return. I didn’t “let this define” me—I simply hadn’t had the life experience to establish my own identity in 1998. If you haven’t figured out who you are, it’s hard not to accept the horrible image of you created by others. (Thus, my compassion for young people who find themselves shamed on the Web.) Despite much self-searching and therapy and exploring of different paths, I remained “stuck” for far too many years. No longer. It’s time to burn the beret and bury the blue dress. And move forward. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement. Condé Nast © 2018 Condé Nast. All rights reserved. Use of and/or registration on any portion of this site constitutes acceptance of our User Agreement (updated 5/28/18) and Privacy Policy and Cookie Statement (updated 5/28/18). Your CA Privacy Rights. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast. Ad Choices\n"
     ]
    }
   ],
   "source": [
    "cw21(\"dupa.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 22\n",
    "\n",
    "https://www.practicepython.org/exercise/2014/12/06/22-read-from-file.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a .txt file that has a list of a bunch of names, count how many of each name there are in the file, and print out the results to the screen. I have a .txt file for you, if you want to use it!\n",
    "\n",
    "Extra:\n",
    "\n",
    "    Instead of using the .txt file from above (or instead of, if you want the challenge), take this .txt file, and count how many of each “category” of each image there are. This text file is actually a list of files corresponding to the SUN database scene recognition database, and lists the file directory hierarchy for the images. Once you take a look at the first line or two of the file, it will be clear which part represents the scene category. To do this, you’re going to have to remember a bit about string parsing in Python 3. I talked a little bit about it in this post.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cw22():\n",
    "    def __init__(self):\n",
    "        self.file_name = \"\"\n",
    "    def save_file(self, file_name, text):\n",
    "        text = str(' '.join(text))\n",
    "        with open(file_name, 'w', encoding='utf-8') as open_file:\n",
    "            open_file.write(text)\n",
    "    def count_names(self, file_name):\n",
    "        from collections import Counter\n",
    "        with open(file_name, 'r+', encoding='utf-8') as open_file:\n",
    "            all_text = open_file.read()\n",
    "        names = all_text.split(\" \")\n",
    "        print(Counter(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Lea': 1, 'Luke': 1, 'Darth': 1, 'kornel': 1, 'korneliusz': 1})\n"
     ]
    }
   ],
   "source": [
    "names=[\"Lea\", 'Luke', 'Darth', 'kornel', 'korneliusz']\n",
    "x = cw22()\n",
    "x.save_file(\"dupa.txt\", names)\n",
    "x.count_names(\"dupa.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 23\n",
    "https://www.practicepython.org/exercise/2014/12/14/23-file-overlap.html|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given two .txt files that have lists of numbers in them, find the numbers that are overlapping. One .txt file has a list of all prime numbers under 1000, and the other .txt file has a list of happy numbers up to 1000.\n",
    "\n",
    "(If you forgot, prime numbers are numbers that can’t be divided by any other number. And yes, happy numbers are a real thing in mathematics - you can look it up on Wikipedia. The explanation is easier with an example, which I will describe below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cw22():\n",
    "    def prime_gen(self, n):\n",
    "        s=[True]*int(n/2)\n",
    "        for i in range(int((n/2-1)/2) >> 1):\n",
    "            for j in range((i*(i+3)<<1)+3,int(n/2),(i<<1)+3): s[j]=False\n",
    "        return [2] + [((i<<1)+3) for i in range(int(n/2)) if (s[i])]\n",
    "    \n",
    "    def happy_gen(self):\n",
    "        return[1, 7, 10, 13, 19, 23, 28, 31, 32, 44, 49, 68, 70, 79,\n",
    "                82, 86, 91, 94, 97, 100, 103, 109, 129, 130, 133, 139,\n",
    "                167, 176, 188, 190, 192, 193, 203, 208, 219, 226, 230,\n",
    "                236, 239, 262, 263, 280, 291, 293, 301, 302, 310, 313,\n",
    "                319, 320, 326, 329, 331, 338, 356, 362, 365, 367, 368,\n",
    "                376, 379, 383, 386, 391, 392, 397, 404, 409, 440, 446,\n",
    "                464, 469, 478, 487, 490, 496, 536, 556, 563, 565, 566,\n",
    "                608, 617, 622, 623, 632, 635, 637, 638, 644, 649, 653,\n",
    "                655, 656, 665, 671, 673, 680, 683, 694, 700, 709, 716,\n",
    "                736, 739, 748, 761, 763, 784, 790, 793, 802, 806, 818,\n",
    "                820, 833, 836, 847, 860, 863, 874, 881, 888, 899, 901,\n",
    "                904, 907, 910, 912, 913, 921, 923, 931, 932, 937, 940,\n",
    "                946, 964, 970, 973, 989, 998, 1000]\n",
    "    \n",
    "    def save_files(self):\n",
    "        text = x.prime_gen( 1000)\n",
    "        text = ','.join(str(e) for e in text)\n",
    "        with open(\"prim.txt\", 'w', encoding='utf-8') as open_file:\n",
    "            open_file.write(text)\n",
    "        text = cw22.happy_gen(self)\n",
    "        text = ','.join(str(e) for e in text)\n",
    "        with open(\"happy.txt\", 'w', encoding='utf-8') as open_file:\n",
    "            open_file.write(text)\n",
    "            \n",
    "    def overlapping_numbers(self):\n",
    "        overlapping =[]\n",
    "        with open(\"prim.txt\", 'r+', encoding='utf-8') as open_file:\n",
    "            all_num1 = open_file.read()\n",
    "        all_num1 = all_num1.split(\",\")\n",
    "        with open(\"happy.txt\", 'r+', encoding='utf-8') as open_file:\n",
    "            all_num2 = open_file.read()\n",
    "        all_num2 = all_num2.split(\",\")\n",
    "        for num1 in all_num1:\n",
    "            for num2 in all_num2:\n",
    "                if num1 == num2:\n",
    "                    overlapping.append(num1)\n",
    "        return overlapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cw22()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7',\n",
       " '13',\n",
       " '19',\n",
       " '23',\n",
       " '31',\n",
       " '79',\n",
       " '97',\n",
       " '103',\n",
       " '109',\n",
       " '139',\n",
       " '167',\n",
       " '193',\n",
       " '239',\n",
       " '263',\n",
       " '293',\n",
       " '313',\n",
       " '331',\n",
       " '367',\n",
       " '379',\n",
       " '383',\n",
       " '397',\n",
       " '409',\n",
       " '487',\n",
       " '563',\n",
       " '617',\n",
       " '653',\n",
       " '673',\n",
       " '683',\n",
       " '709',\n",
       " '739',\n",
       " '761',\n",
       " '863',\n",
       " '881',\n",
       " '907',\n",
       " '937']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.overlapping_numbers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 24\n",
    "https://www.practicepython.org/exercise/2014/12/27/24-draw-a-game-board.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "his exercise is Part 1 of 4 of the Tic Tac Toe exercise series. The other exercises are: Part 2, Part 3, and Part 4.\n",
    "\n",
    "Time for some fake graphics! Let’s say we want to draw game boards that look like this:\n",
    ":\n",
    "     --- --- --- \n",
    "    |   |   |   | \n",
    "     --- --- ---  \n",
    "    |   |   |   | \n",
    "     --- --- ---  \n",
    "    |   |   |   | \n",
    "     --- --- --- \n",
    "\n",
    "This one is 3x3 (like in tic tac toe). Obviously, they come in many other sizes (8x8 for chess, 19x19 for Go, and many more).\n",
    "\n",
    "Ask the user what size game board they want to draw, and draw it for them to the screen using Python’s print statement.\n",
    "\n",
    "Remember that in Python 3, printing to the screen is accomplished by\n",
    "\n",
    "  print(\"Thing to show on screen\")\n",
    "\n",
    "Hint: this requires some use of functions, as were discussed previously on this blog and elsewhere on the Internet, like this TutorialsPoint link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw24(number_x, number_y):\n",
    "    up_line = \" ---\"\n",
    "    mid_line = \"|   \"\n",
    "    for i in range(number_y):\n",
    "        graph = ''.join(up_line for i in range(number_x))\n",
    "        print(graph)\n",
    "        graph = ''.join(mid_line for i in range(number_x+1))\n",
    "        print(graph)\n",
    "        if i == number_y-1:\n",
    "            graph = ''.join(up_line for i in range(number_x))\n",
    "            print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- --- --- --- ---\n",
      "|   |   |   |   |   |   \n",
      " --- --- --- --- ---\n",
      "|   |   |   |   |   |   \n",
      " --- --- --- --- ---\n",
      "|   |   |   |   |   |   \n",
      " --- --- --- --- ---\n",
      "|   |   |   |   |   |   \n",
      " --- --- --- --- ---\n",
      "|   |   |   |   |   |   \n",
      " --- --- --- --- ---\n"
     ]
    }
   ],
   "source": [
    "cw24(5,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 25 \n",
    "https://www.practicepython.org/exercise/2015/11/01/25-guessing-game-two.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a previous exercise, we’ve written a program that “knows” a number and asks a user to guess it.\n",
    "\n",
    "This time, we’re going to do exactly the opposite. You, the user, will have in your head a number between 0 and 100. The program will guess a number, and you, the user, will say whether it is too high, too low, or your number.\n",
    "\n",
    "At the end of this exchange, your program should print out how many guesses it took to get your number.\n",
    "\n",
    "As the writer of this program, you will have to choose how your program will strategically guess. A naive strategy can be to simply start the guessing at 1, and keep going (2, 3, 4, etc.) until you hit the number. But that’s not an optimal guessing strategy. An alternate strategy might be to guess 50 (right in the middle of the range), and then increase / decrease by 1 as needed. After you’ve written the program, try to find the optimal strategy! (We’ll talk about what is the optimal one next week with the solution.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cw25():\n",
    "    def __init__(self):\n",
    "        import random\n",
    "        import string\n",
    "        self.attempts = 0\n",
    "        self.prediction = []\n",
    "        for number in range(0,101):\n",
    "            self.prediction.append(number)\n",
    "    def pred(self):\n",
    "        self.attempts += 1\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cw25()\n",
    "x.pred()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 26\n",
    "https://www.practicepython.org/exercise/2015/11/16/26-check-tic-tac-toe.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have guessed, we are trying to build up to a full tic-tac-toe board. However, this is significantly more than half an hour of coding, so we’re doing it in pieces.\n",
    "\n",
    "Today, we will simply focus on checking whether someone has WON a game of Tic Tac Toe, not worrying about how the moves were made.\n",
    "\n",
    "If a game of Tic Tac Toe is represented as a list of lists, like so:\n",
    "\n",
    "game = [[1, 2, 0],\n",
    "\t[2, 1, 0],\n",
    "\t[2, 1, 1]]\n",
    "\n",
    "where a 0 means an empty square, a 1 means that player 1 put their token in that space, and a 2 means that player 2 put their token in that space.\n",
    "\n",
    "Your task this week: given a 3 by 3 list of lists that represents a Tic Tac Toe game board, tell me whether anyone has won, and tell me which player won, if any. A Tic Tac Toe win is 3 in a row - either in a row, a column, or a diagonal. Don’t worry about the case where TWO people have won - assume that in every board there will only be one winner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw26(game_state):\n",
    "    # we check --- type win\n",
    "    for state in game_state:\n",
    "        if state[0] == state[1] and state[0] == state[2]:\n",
    "            return state[0]\n",
    "    # we check | type win\n",
    "    for col in range(0,3):\n",
    "        if game_state[0][col]==game_state[1][col] and game_state[0][col]==game_state[2][col]:\n",
    "            return game_state[0][col] \n",
    "    # we check X type win\n",
    "    if game_state[0][0]==game_state[1][1] and game_state[0][0]==game_state[2][2]:\n",
    "            return game_state[0][0]\n",
    "    if game_state[0][2]==game_state[1][1] and game_state[0][2]==game_state[2][0]:\n",
    "            return game_state[0][2]\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_state = [[1, 0, 2],\n",
    "            [2,1, 0],\n",
    "            [2, 1, 1]]\n",
    "cw26(game_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 27\n",
    "https://www.practicepython.org/exercise/2015/11/26/27-tic-tac-toe-draw.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cw27():\n",
    "    def __init__(self):\n",
    "        self.game_state = [[0, 0, 0],\n",
    "                        [0, 0, 0],\n",
    "                        [0, 0, 0]]\n",
    "        self.move_count = 0\n",
    "    def game_move(self, player_move):\n",
    "        self.move_count += 1\n",
    "        player_move = player_move.split(\",\")\n",
    "        player_move[0] = int(player_move[0])\n",
    "        player_move[1] = int(player_move[1])\n",
    "        print(player_move)\n",
    "        # we check if field is free\n",
    "        if self.game_state[player_move[0]][player_move[1]] != 0:\n",
    "            return \"not free position\"\n",
    "        if self.move_count % 2 ==1:\n",
    "            # player 1\n",
    "            self.game_state[player_move[0]][player_move[1]] = 1\n",
    "        if self.move_count % 2 ==0:\n",
    "            # player 2\n",
    "            self.game_state[player_move[0]][player_move[1]] = 2\n",
    "        print(self.game_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cw27()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n",
      "[[0, 0, 0], [0, 0, 1], [0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "x.game_move(\"1,2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 28\n",
    "https://www.practicepython.org/exercise/2016/03/27/28-max-of-three.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw28(var1, var2, var3):\n",
    "    # we save values for later\n",
    "    p_var1 = var1\n",
    "    p_var2 = var2\n",
    "    p_var3 = var3\n",
    "    # we make list form str\n",
    "    var1 = list(str(var1))\n",
    "    var2 = list(str(var2))\n",
    "    var3 = list(str(var3))\n",
    "    # we take len for str\n",
    "    var1 = len(var1)\n",
    "    var2 = len(var2)\n",
    "    var3 = len(var3)\n",
    "    # we return longest str\n",
    "    if var1 > var2:\n",
    "        return p_var1\n",
    "    else:\n",
    "        return p_var2\n",
    "    if var1 > var3:\n",
    "        return p_var1\n",
    "    else:\n",
    "        return p_var3\n",
    "    if var2 > var3:\n",
    "        return p_var2\n",
    "    else:\n",
    "        return p_var3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12aa54674'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw28(1235,\"12aa54674\",\"324325afeasgtwery26\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 29\n",
    "https://www.practicepython.org/exercise/2016/08/03/29-tic-tac-toe-game.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cw29_tic_tac_toe_game():\n",
    "    def __init__(self):\n",
    "        self.game_state = [[0, 0, 0],\n",
    "                        [0, 0, 0],\n",
    "                        [0, 0, 0]]\n",
    "        self.turn_count = 0\n",
    "        \n",
    "    def game(self):\n",
    "        print(\" game start we weit for muve \")\n",
    "        for game_turn in range(9):\n",
    "            player_move = input()\n",
    "            self.turn_count += 1\n",
    "            self.game_move(player_move)\n",
    "            self.scratch_board(self.game_state)\n",
    "            self.win_checker(self.game_state)\n",
    "            \n",
    "    def game_move(self, player_move):\n",
    "        player_move = player_move.split(\",\")\n",
    "        player_move[0] = int(player_move[0])\n",
    "        player_move[1] = int(player_move[1])\n",
    "        # we check if field is free\n",
    "        if self.game_state[player_move[0]][player_move[1]] != 0:\n",
    "            return \"not free position\"\n",
    "        if self.turn_count % 2 == 1:\n",
    "            # player 1\n",
    "            self.game_state[player_move[0]][player_move[1]] = 1\n",
    "        if self.turn_count % 2 == 0:\n",
    "            # player 2\n",
    "            self.game_state[player_move[0]][player_move[1]] = 2\n",
    "        #print(self.game_state)\n",
    "        \n",
    "    def scratch_board(self, game_state):\n",
    "        print(str(game_state[0][0]) + \" | \" + str(game_state[0][1]) + \" | \" + str(game_state[0][2]))\n",
    "        print(str(game_state[1][0]) + \" | \" + str(game_state[1][1]) + \" | \" + str(game_state[1][2]))\n",
    "        print(str(game_state[2][0]) + \" | \" + str(game_state[2][1]) + \" | \" + str(game_state[2][2]))\n",
    "        \n",
    "        \n",
    "    \n",
    "    def win_checker(self, game_state):\n",
    "        # we check --- type win\n",
    "        for state in self.game_state:\n",
    "            if state[0] == state[1] and state[0] == state[2]:\n",
    "                return state[0]\n",
    "        # we check | type win\n",
    "        for col in range(0,3):\n",
    "            if self.game_state[0][col]==self.game_state[1][col] and self.game_state[0][col]==self.game_state[2][col]:\n",
    "                return self.game_state[0][col] \n",
    "        # we check X type win\n",
    "        if self.game_state[0][0]==self.game_state[1][1] and self.game_state[0][0]==self.game_state[2][2]:\n",
    "                return self.game_state[0][0]\n",
    "        if self.game_state[0][2]==self.game_state[1][1] and self.game_state[0][2]==self.game_state[2][0]:\n",
    "                return self.game_state[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cw29_tic_tac_toe_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " game start we weit for muve \n",
      "sdag\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'sdag'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-39e94cff247d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-27-5aba10c8da6e>\u001b[0m in \u001b[0;36mgame\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mplayer_move\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mturn_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgame_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer_move\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscratch_board\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgame_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwin_checker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgame_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-5aba10c8da6e>\u001b[0m in \u001b[0;36mgame_move\u001b[1;34m(self, player_move)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgame_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayer_move\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mplayer_move\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplayer_move\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mplayer_move\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer_move\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mplayer_move\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplayer_move\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m# we check if field is free\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'sdag'"
     ]
    }
   ],
   "source": [
    "x.game()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cw 30\n",
    "https://www.practicepython.org/solution/2016/10/15/30-pick-word-solutions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw30():\n",
    "    import random\n",
    "    with open('sowpods.txt') as file:\n",
    "        words = list(file)\n",
    "    print(random.choice(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTSPORTING\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cw30()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Pandas Data Series [4 exercises with solution] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.w3resource.com/python-exercises/pandas/index.php"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cw1 Write a Python program to create and display a one-dimensional array-like object containing an array of data using Pandas module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw1(number):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    arrey = pd.Series(np.random.randn(number))\n",
    "    print(arrey)\n",
    "    return arrey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.324399\n",
      "1    1.598574\n",
      "2   -3.058923\n",
      "3   -0.657532\n",
      "4   -2.749224\n",
      "5    0.639393\n",
      "6   -2.024478\n",
      "7   -1.659101\n",
      "8    1.860229\n",
      "9    2.063544\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "x = cw1(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cw2 Write a Python program to convert a Panda module Series to Python list and it's type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw2(pn_module_series):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    pylist = pn_module_series.tolist()\n",
    "    print(pylist)\n",
    "    return pylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3243989623023908, 1.5985744855555228, -3.058922522582071, -0.6575321477101014, -2.749224085516973, 0.6393925635772136, -2.02447772534292, -1.6591009219436894, 1.8602291369577364, 2.063544371760775]\n"
     ]
    }
   ],
   "source": [
    "y = cw2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Write a Python program to add, subtract, multiple and divide two Pandas Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw3(pn_series1, pn_series2, operator):\n",
    "    # operator = \"add\",\"subtract\",\"multiply\",\"divide\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    if operator is \"add\":\n",
    "        pn_series1 = pn_series1.add(pn_series2)\n",
    "        print(pn_series1)\n",
    "    if operator is \"subtract\":\n",
    "        pn_series1 = pn_series1.subtract(pn_series2)\n",
    "        print(pn_series1)\n",
    "    if operator is \"multiply\":\n",
    "        pn_series1 = pn_series1.multiply(pn_series2)\n",
    "        print(pn_series1)\n",
    "    if operator is \"divide\":\n",
    "        pn_series1 = pn_series1.divide(pn_series2, fill_value=0)\n",
    "        print(pn_series1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2.000000\n",
      "1    1.333333\n",
      "2    1.200000\n",
      "3    1.142857\n",
      "4    1.111111\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# we do pandas series form list\n",
    "import pandas as pd\n",
    "pn_series1 = [2, 4, 6, 8, 10]\n",
    "pn_series1 = pd.Series(pn_series1)\n",
    "pn_series2 = [1, 3, 5, 7, 9]\n",
    "pn_series2 = pd.Series(pn_series2)\n",
    "x = cw3(pn_series1, pn_series2, \"divide\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Write a Python program to get the largest integer smaller or equal to the division of the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw4(series1, series2):\n",
    "    series3 = series1.divide(series2,fill_value=0)\n",
    "    series3 = series3.round()\n",
    "    return series3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we do pandas series form list\n",
    "import pandas as pd\n",
    "pn_series1 = [2, 4, 6, 8, 10]\n",
    "pn_series1 = pd.Series(pn_series1)\n",
    "pn_series2 = [1, 3, 5, 7, 9]\n",
    "pn_series2 = pd.Series(pn_series2)\n",
    "cw4(pn_series1, pn_series2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naprężenia w reaktorze zbiornikowym z mieszadłem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZADANIE\n",
    "Aglomeraty komórek o wielkości 120 μm hodowane są w reaktorze o objętości \n",
    "3,5 L wyposażonym w mieszadło Rushtonao średnicy 6 cm. Aglomeraty maja gęstość 1010 kg/m3 oraz   lepkość 1,3x10-3Pas.\n",
    "Oszacuj maksymalną dopuszczalna szybkość mieszania zapobiegającą niszczeniu komórek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw_bio_1(d, v, D):\n",
    "    # Skala Kołmogorowa mikrowirówmniejsza niż ½ -2/3 średnicy cząstki powoduje niszczenie komórek. \n",
    "    # Wielkość skali Kołmogorowa wynosi:\n",
    "    lambdaa = (2/3)*d\n",
    "    # Moc mieszadła powodująca tworzenie się takich wirów można policzyć z zależności:\n",
    "    lepkosc_dynamiczna = 1.3*(10**(-3))\n",
    "    gestosc = 1010\n",
    "    lepkosc_kinematyczna = lepkosc_dynamiczna/gestosc\n",
    "    dysypacja_mocy = (lepkosc_kinematyczna**3)/(lambdaa**4)\n",
    "    moc_mieszania = dysypacja_mocy*gestosc*(D**3)\n",
    "    print(moc_mieszania)\n",
    "    return moc_mieszania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1357457295853351e-20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1357457295853351e-20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw_bio_1(120,3.5,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Web Scraping [25 exercises with solution] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a Python program to test if a given page is found or not on the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw1(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    from urllib.request import urlopen\n",
    "    from urllib.error import HTTPError\n",
    "    from urllib.error import URLError\n",
    "    try:\n",
    "        html = urlopen(url)\n",
    "    except HTTPError as e:\n",
    "        print(\"HTTP error\")\n",
    "    except URLError as e:\n",
    "        print(\"Server not found!\")\n",
    "    else:\n",
    "        print(html.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw1(\"https://www.google.pl/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw2(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    req_for_robot = requests.get(url)\n",
    "    req_for_robot_html = req_for_robot.text\n",
    "    req_for_robot_html = BeautifulSoup(req_for_robot_html, \"html5lib\")\n",
    "    return req_for_robot_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "<html class=\"client-nojs\" dir=\"ltr\" lang=\"en\"><head>\n",
       "<meta charset=\"utf-8\"/>\n",
       "<title>Robots exclusion standard - Wikipedia</title>\n",
       "<script>document.documentElement.className = document.documentElement.className.replace( /(^|\\s)client-nojs(\\s|$)/, \"$1client-js$2\" );</script>\n",
       "<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"Robots_exclusion_standard\",\"wgTitle\":\"Robots exclusion standard\",\"wgCurRevisionId\":853666262,\"wgRevisionId\":853666262,\"wgArticleId\":101673,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"All articles with unsourced statements\",\"Articles with unsourced statements from November 2016\",\"World Wide Web\"],\"wgBreakFrames\":false,\"wgPageContentLanguage\":\"en\",\"wgPageContentModel\":\"wikitext\",\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\"\",\"\"],\"wgDefaultDateFormat\":\"dmy\",\"wgMonthNames\":[\"\",\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\"wgMonthNamesShort\":[\"\",\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"],\"wgRelevantPageName\":\"Robots_exclusion_standard\",\"wgRelevantArticleId\":101673,\"wgRequestId\":\"W3BcqgpAIC0AACRgJdIAAAAY\",\"wgIsProbablyEditable\":true,\"wgRelevantPageIsProbablyEditable\":true,\"wgRestrictionEdit\":[],\"wgRestrictionMove\":[],\"wgFlaggedRevsParams\":{\"tags\":{}},\"wgStableRevisionId\":null,\"wgCategoryTreePageCategoryOptions\":\"{\\\"mode\\\":0,\\\"hideprefix\\\":20,\\\"showcount\\\":true,\\\"namespaces\\\":false}\",\"wgWikiEditorEnabledModules\":[],\"wgBetaFeaturesFeatures\":[],\"wgMediaViewerOnClick\":true,\"wgMediaViewerEnabledByDefault\":true,\"wgPopupsShouldSendModuleToUser\":true,\"wgPopupsConflictsWithNavPopupGadget\":false,\"wgVisualEditor\":{\"pageLanguageCode\":\"en\",\"pageLanguageDir\":\"ltr\",\"pageVariantFallbacks\":\"en\",\"usePageImages\":true,\"usePageDescriptions\":true},\"wgMFExpandAllSectionsUserOption\":true,\"wgMFEnableFontChanger\":true,\"wgMFDisplayWikibaseDescriptions\":{\"search\":true,\"nearby\":true,\"watchlist\":true,\"tagline\":false},\"wgRelatedArticles\":null,\"wgRelatedArticlesUseCirrusSearch\":true,\"wgRelatedArticlesOnlyUseCirrusSearch\":false,\"wgULSCurrentAutonym\":\"English\",\"wgNoticeProject\":\"wikipedia\",\"wgCentralNoticeCookiesToDelete\":[],\"wgCentralNoticeCategoriesUsingLegacy\":[\"Fundraising\",\"fundraising\"],\"wgWikibaseItemId\":\"Q80776\",\"wgScoreNoteLanguages\":{\"arabic\":\"العربية\",\"catalan\":\"català\",\"deutsch\":\"Deutsch\",\"english\":\"English\",\"espanol\":\"español\",\"italiano\":\"italiano\",\"nederlands\":\"Nederlands\",\"norsk\":\"norsk\",\"portugues\":\"português\",\"suomi\":\"suomi\",\"svenska\":\"svenska\",\"vlaams\":\"West-Vlams\"},\"wgScoreDefaultNoteLanguage\":\"nederlands\",\"wgCentralAuthMobileDomain\":false,\"wgCodeMirrorEnabled\":true,\"wgVisualEditorToolbarScrollOffset\":0,\"wgVisualEditorUnsupportedEditParams\":[\"undo\",\"undoafter\",\"veswitched\"],\"wgEditSubmitButtonLabelPublish\":true});mw.loader.state({\"ext.gadget.charinsert-styles\":\"ready\",\"ext.globalCssJs.user.styles\":\"ready\",\"ext.globalCssJs.site.styles\":\"ready\",\"site.styles\":\"ready\",\"noscript\":\"ready\",\"user.styles\":\"ready\",\"ext.globalCssJs.user\":\"ready\",\"ext.globalCssJs.site\":\"ready\",\"user\":\"ready\",\"user.options\":\"ready\",\"user.tokens\":\"loading\",\"ext.cite.styles\":\"ready\",\"ext.pygments\":\"ready\",\"mediawiki.legacy.shared\":\"ready\",\"mediawiki.legacy.commonPrint\":\"ready\",\"mediawiki.toc.styles\":\"ready\",\"wikibase.client.init\":\"ready\",\"ext.visualEditor.desktopArticleTarget.noscript\":\"ready\",\"ext.uls.interlanguage\":\"ready\",\"ext.wikimediaBadges\":\"ready\",\"mediawiki.skinning.interface\":\"ready\",\"skins.vector.styles\":\"ready\"});mw.loader.implement(\"user.tokens@1dqfd7l\",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({\"editToken\":\"+\\\\\",\"patrolToken\":\"+\\\\\",\"watchToken\":\"+\\\\\",\"csrfToken\":\"+\\\\\"});\n",
       "});mw.loader.load([\"ext.cite.a11y\",\"site\",\"mediawiki.page.startup\",\"mediawiki.user\",\"mediawiki.page.ready\",\"mediawiki.toc\",\"mediawiki.searchSuggest\",\"ext.gadget.teahouse\",\"ext.gadget.ReferenceTooltips\",\"ext.gadget.watchlist-notice\",\"ext.gadget.DRN-wizard\",\"ext.gadget.charinsert\",\"ext.gadget.refToolbar\",\"ext.gadget.extra-toolbar-buttons\",\"ext.gadget.switcher\",\"ext.centralauth.centralautologin\",\"mmv.head\",\"mmv.bootstrap.autostart\",\"ext.popups\",\"ext.visualEditor.desktopArticleTarget.init\",\"ext.visualEditor.targetLoader\",\"ext.eventLogging.subscriber\",\"ext.wikimediaEvents\",\"ext.navigationTiming\",\"ext.uls.eventlogger\",\"ext.uls.init\",\"ext.uls.compactlinks\",\"ext.uls.interface\",\"ext.3d\",\"ext.centralNotice.geoIP\",\"ext.centralNotice.startUp\",\"skins.vector.js\"]);});</script>\n",
       "<link href=\"/w/load.php?debug=false&amp;lang=en&amp;modules=ext.cite.styles%7Cext.pygments%2CwikimediaBadges%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cmediawiki.legacy.commonPrint%2Cshared%7Cmediawiki.skinning.interface%7Cmediawiki.toc.styles%7Cskins.vector.styles%7Cwikibase.client.init&amp;only=styles&amp;skin=vector\" rel=\"stylesheet\"/>\n",
       "<script async=\"\" src=\"/w/load.php?debug=false&amp;lang=en&amp;modules=startup&amp;only=scripts&amp;skin=vector\"></script>\n",
       "<meta content=\"\" name=\"ResourceLoaderDynamicStyles\"/>\n",
       "<link href=\"/w/load.php?debug=false&amp;lang=en&amp;modules=ext.gadget.charinsert-styles&amp;only=styles&amp;skin=vector\" rel=\"stylesheet\"/>\n",
       "<link href=\"/w/load.php?debug=false&amp;lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector\" rel=\"stylesheet\"/>\n",
       "<meta content=\"MediaWiki 1.32.0-wmf.16\" name=\"generator\"/>\n",
       "<meta content=\"origin\" name=\"referrer\"/>\n",
       "<meta content=\"origin-when-crossorigin\" name=\"referrer\"/>\n",
       "<meta content=\"origin-when-cross-origin\" name=\"referrer\"/>\n",
       "<link href=\"android-app://org.wikipedia/http/en.m.wikipedia.org/wiki/Robots_exclusion_standard\" rel=\"alternate\"/>\n",
       "<link href=\"/w/index.php?title=Robots_exclusion_standard&amp;action=edit\" rel=\"alternate\" title=\"Edit this page\" type=\"application/x-wiki\"/>\n",
       "<link href=\"/w/index.php?title=Robots_exclusion_standard&amp;action=edit\" rel=\"edit\" title=\"Edit this page\"/>\n",
       "<link href=\"/static/apple-touch/wikipedia.png\" rel=\"apple-touch-icon\"/>\n",
       "<link href=\"/static/favicon/wikipedia.ico\" rel=\"shortcut icon\"/>\n",
       "<link href=\"/w/opensearch_desc.php\" rel=\"search\" title=\"Wikipedia (en)\" type=\"application/opensearchdescription+xml\"/>\n",
       "<link href=\"//en.wikipedia.org/w/api.php?action=rsd\" rel=\"EditURI\" type=\"application/rsd+xml\"/>\n",
       "<link href=\"//creativecommons.org/licenses/by-sa/3.0/\" rel=\"license\"/>\n",
       "<link href=\"https://en.wikipedia.org/wiki/Robots_exclusion_standard\" rel=\"canonical\"/>\n",
       "<link href=\"//login.wikimedia.org\" rel=\"dns-prefetch\"/>\n",
       "<link href=\"//meta.wikimedia.org\" rel=\"dns-prefetch\"/>\n",
       "<!--[if lt IE 9]><script src=\"/w/load.php?debug=false&amp;lang=en&amp;modules=html5shiv&amp;only=scripts&amp;skin=vector&amp;sync=1\"></script><![endif]-->\n",
       "</head>\n",
       "<body class=\"mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject page-Robots_exclusion_standard rootpage-Robots_exclusion_standard skin-vector action-view\">\t\t<div class=\"noprint\" id=\"mw-page-base\"></div>\n",
       "\t\t<div class=\"noprint\" id=\"mw-head-base\"></div>\n",
       "\t\t<div class=\"mw-body\" id=\"content\" role=\"main\">\n",
       "\t\t\t<a id=\"top\"></a>\n",
       "\t\t\t<div class=\"mw-body-content\" id=\"siteNotice\"><!-- CentralNotice --></div><div class=\"mw-indicators mw-body-content\">\n",
       "</div>\n",
       "<h1 class=\"firstHeading\" id=\"firstHeading\" lang=\"en\">Robots exclusion standard</h1>\t\t\t<div class=\"mw-body-content\" id=\"bodyContent\">\n",
       "\t\t\t\t<div class=\"noprint\" id=\"siteSub\">From Wikipedia, the free encyclopedia</div>\t\t\t\t<div id=\"contentSub\"></div>\n",
       "\t\t\t\t<div id=\"jump-to-nav\"></div>\t\t\t\t<a class=\"mw-jump-link\" href=\"#mw-head\">Jump to navigation</a>\n",
       "\t\t\t\t<a class=\"mw-jump-link\" href=\"#p-search\">Jump to search</a>\n",
       "\t\t\t\t<div class=\"mw-content-ltr\" dir=\"ltr\" id=\"mw-content-text\" lang=\"en\"><div class=\"mw-parser-output\"><div class=\"hatnote navigation-not-searchable\" role=\"note\"><span class=\"plainlinks selfreference noprint\">\"robots.txt\" redirects here. For Wikipedia's robots.txt files, see the <i><a class=\"external text\" href=\"https://www.mediawiki.org/robots.txt\">MediaWiki Robots.txt file</a></i>, <i><a class=\"external text\" href=\"https://en.wikipedia.org/robots.txt\">English Wikipedia Robots.txt file</a></i>, and <i><a href=\"/wiki/MediaWiki:Robots.txt\" title=\"MediaWiki:Robots.txt\">MediaWiki:Robots.txt</a>.</i></span></div>\n",
       "<p>The <b>robots exclusion standard</b>, also known as the <b>robots exclusion protocol</b> or simply <b>robots.txt</b>, is a standard used by <a href=\"/wiki/Website\" title=\"Website\">websites</a> to communicate with <a href=\"/wiki/Web_crawler\" title=\"Web crawler\">web crawlers</a> and other <a href=\"/wiki/Internet_bot\" title=\"Internet bot\">web robots</a>. The standard specifies how to inform the web robot about which areas of the website should not be processed or scanned. Robots are often used by <a href=\"/wiki/Web_search_engine\" title=\"Web search engine\">search engines</a> to categorize websites. Not all robots cooperate with the standard; <a href=\"/wiki/Email_address_harvesting\" title=\"Email address harvesting\">email harvesters</a>, <a class=\"mw-redirect\" href=\"/wiki/Spambots\" title=\"Spambots\">spambots</a>, <a href=\"/wiki/Malware\" title=\"Malware\">malware</a>, and robots that scan for security vulnerabilities may even start with the portions of the website where they have been told to stay out. The standard is different from but can be used in conjunction with, <a href=\"/wiki/Sitemaps\" title=\"Sitemaps\">Sitemaps</a>, a robot <i>inclusion</i> standard for websites.\n",
       "</p>\n",
       "<div class=\"toc\" id=\"toc\"><input class=\"toctogglecheckbox\" id=\"toctogglecheckbox\" role=\"button\" style=\"display:none\" type=\"checkbox\"/><div class=\"toctitle\" dir=\"ltr\" lang=\"en\"><h2>Contents</h2><span class=\"toctogglespan\"><label class=\"toctogglelabel\" for=\"toctogglecheckbox\"></label></span></div>\n",
       "<ul>\n",
       "<li class=\"toclevel-1 tocsection-1\"><a href=\"#History\"><span class=\"tocnumber\">1</span> <span class=\"toctext\">History</span></a></li>\n",
       "<li class=\"toclevel-1 tocsection-2\"><a href=\"#About_the_standard\"><span class=\"tocnumber\">2</span> <span class=\"toctext\">About the standard</span></a></li>\n",
       "<li class=\"toclevel-1 tocsection-3\"><a href=\"#Security\"><span class=\"tocnumber\">3</span> <span class=\"toctext\">Security</span></a></li>\n",
       "<li class=\"toclevel-1 tocsection-4\"><a href=\"#Alternatives\"><span class=\"tocnumber\">4</span> <span class=\"toctext\">Alternatives</span></a></li>\n",
       "<li class=\"toclevel-1 tocsection-5\"><a href=\"#Examples\"><span class=\"tocnumber\">5</span> <span class=\"toctext\">Examples</span></a></li>\n",
       "<li class=\"toclevel-1 tocsection-6\"><a href=\"#Nonstandard_extensions\"><span class=\"tocnumber\">6</span> <span class=\"toctext\">Nonstandard extensions</span></a>\n",
       "<ul>\n",
       "<li class=\"toclevel-2 tocsection-7\"><a href=\"#Crawl-delay_directive\"><span class=\"tocnumber\">6.1</span> <span class=\"toctext\">Crawl-delay directive</span></a></li>\n",
       "<li class=\"toclevel-2 tocsection-8\"><a href=\"#Allow_directive\"><span class=\"tocnumber\">6.2</span> <span class=\"toctext\">Allow directive</span></a></li>\n",
       "<li class=\"toclevel-2 tocsection-9\"><a href=\"#Sitemap\"><span class=\"tocnumber\">6.3</span> <span class=\"toctext\">Sitemap</span></a></li>\n",
       "<li class=\"toclevel-2 tocsection-10\"><a href=\"#Host\"><span class=\"tocnumber\">6.4</span> <span class=\"toctext\">Host</span></a></li>\n",
       "<li class=\"toclevel-2 tocsection-11\"><a href='#Universal_\"*\"_match'><span class=\"tocnumber\">6.5</span> <span class=\"toctext\">Universal \"*\" match</span></a></li>\n",
       "</ul>\n",
       "</li>\n",
       "<li class=\"toclevel-1 tocsection-12\"><a href=\"#Meta_tags_and_headers\"><span class=\"tocnumber\">7</span> <span class=\"toctext\">Meta tags and headers</span></a></li>\n",
       "<li class=\"toclevel-1 tocsection-13\"><a href=\"#See_also\"><span class=\"tocnumber\">8</span> <span class=\"toctext\">See also</span></a></li>\n",
       "<li class=\"toclevel-1 tocsection-14\"><a href=\"#References\"><span class=\"tocnumber\">9</span> <span class=\"toctext\">References</span></a></li>\n",
       "<li class=\"toclevel-1 tocsection-15\"><a href=\"#External_links\"><span class=\"tocnumber\">10</span> <span class=\"toctext\">External links</span></a></li>\n",
       "</ul>\n",
       "</div>\n",
       "\n",
       "<h2><span class=\"mw-headline\" id=\"History\">History</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Robots_exclusion_standard&amp;action=edit&amp;section=1\" title=\"Edit section: History\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n",
       "<p>The standard was proposed by <a href=\"/wiki/Martijn_Koster\" title=\"Martijn Koster\">Martijn Koster</a>,<sup class=\"reference\" id=\"cite_ref-1\"><a href=\"#cite_note-1\">[1]</a></sup><sup class=\"reference\" id=\"cite_ref-2\"><a href=\"#cite_note-2\">[2]</a></sup>\n",
       "when working for <a href=\"/wiki/Nexor\" title=\"Nexor\">Nexor</a><sup class=\"reference\" id=\"cite_ref-3\"><a href=\"#cite_note-3\">[3]</a></sup>\n",
       "in February 1994<sup class=\"reference\" id=\"cite_ref-4\"><a href=\"#cite_note-4\">[4]</a></sup>\n",
       "on the <i>www-talk</i> mailing list, the main communication channel for WWW-related activities at the time. <a href=\"/wiki/Charles_Stross\" title=\"Charles Stross\">Charles Stross</a> claims to have provoked Koster to suggest robots.txt, after he wrote a badly-behaved web crawler that inadvertently caused a <a class=\"mw-redirect\" href=\"/wiki/Denial_of_service\" title=\"Denial of service\">denial of service</a> attack on Koster's server.<sup class=\"reference\" id=\"cite_ref-5\"><a href=\"#cite_note-5\">[5]</a></sup>\n",
       "</p><p>It quickly became a <a href=\"/wiki/De_facto_standard\" title=\"De facto standard\">de facto standard</a> that present and future web crawlers were expected to follow; most complied, including those operated by search engines such as <a href=\"/wiki/WebCrawler\" title=\"WebCrawler\">WebCrawler</a>, <a href=\"/wiki/Lycos\" title=\"Lycos\">Lycos</a>, and <a href=\"/wiki/AltaVista\" title=\"AltaVista\">AltaVista</a>.<sup class=\"reference\" id=\"cite_ref-sear_Robo_6-0\"><a href=\"#cite_note-sear_Robo-6\">[6]</a></sup>\n",
       "</p>\n",
       "<h2><span class=\"mw-headline\" id=\"About_the_standard\">About the standard</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Robots_exclusion_standard&amp;action=edit&amp;section=2\" title=\"Edit section: About the standard\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n",
       "<p>When a site owner wishes to give instructions to web robots they place a text file called <style data-mw-deduplicate=\"TemplateStyles:r854393789\">.mw-parser-output .monospaced{font-family:monospace,monospace}</style><span class=\"monospaced\">robots.txt</span> in the root of the web site hierarchy (e.g. <link href=\"mw-data:TemplateStyles:r854393789\" rel=\"mw-deduplicated-inline-style\"/><span class=\"monospaced\">https://www.example.com/robots.txt</span>). This text file contains the instructions in a specific format (see examples below). Robots that <i>choose</i> to follow the instructions try to fetch this file and read the instructions before fetching any other file from the website. If this file doesn't exist, web robots assume that the web owner wishes to provide no specific instructions and crawl the entire site.\n",
       "</p><p>A robots.txt file on a website will function as a request that specified robots ignore specified files or directories when crawling a site. This might be, for example, out of a preference for privacy from search engine results, or the belief that the content of the selected directories might be misleading or irrelevant to the categorization of the site as a whole, or out of a desire that an application only operates on certain data. Links to pages listed in robots.txt can still appear in search results if they are linked to from a page that is crawled.<sup class=\"reference\" id=\"cite_ref-7\"><a href=\"#cite_note-7\">[7]</a></sup>\n",
       "</p><p>A robots.txt file covers one <a class=\"mw-redirect\" href=\"/wiki/Same_origin_policy\" title=\"Same origin policy\">origin</a>. For websites with multiple subdomains, each subdomain must have its own robots.txt file. If <link href=\"mw-data:TemplateStyles:r854393789\" rel=\"mw-deduplicated-inline-style\"/><span class=\"monospaced\">example.com</span> had a robots.txt file but <link href=\"mw-data:TemplateStyles:r854393789\" rel=\"mw-deduplicated-inline-style\"/><span class=\"monospaced\">a.example.com</span> did not, the rules that would apply for <link href=\"mw-data:TemplateStyles:r854393789\" rel=\"mw-deduplicated-inline-style\"/><span class=\"monospaced\">example.com</span> would not apply to <link href=\"mw-data:TemplateStyles:r854393789\" rel=\"mw-deduplicated-inline-style\"/><span class=\"monospaced\">a.example.com</span>. In addition, each protocol and port needs its own robots.txt file; <link href=\"mw-data:TemplateStyles:r854393789\" rel=\"mw-deduplicated-inline-style\"/><span class=\"monospaced\">http://example.com/robots.txt</span> does not apply to pages under <link href=\"mw-data:TemplateStyles:r854393789\" rel=\"mw-deduplicated-inline-style\"/><span class=\"monospaced\">http://example.com:8080/</span> or <link href=\"mw-data:TemplateStyles:r854393789\" rel=\"mw-deduplicated-inline-style\"/><span class=\"monospaced\">https://example.com/</span>.\n",
       "</p><p>Some major search <a href=\"/wiki/Facebook_Paper\" title=\"Facebook Paper\">engines</a> following this standard include Ask,<sup class=\"reference\" id=\"cite_ref-ask-webmasters_8-0\"><a href=\"#cite_note-ask-webmasters-8\">[8]</a></sup> AOL,<sup class=\"reference\" id=\"cite_ref-about-aol-search_9-0\"><a href=\"#cite_note-about-aol-search-9\">[9]</a></sup> Baidu,<sup class=\"reference\" id=\"cite_ref-baidu-spider_10-0\"><a href=\"#cite_note-baidu-spider-10\">[10]</a></sup> Bing,<sup class=\"reference\" id=\"cite_ref-bing-blog-robots_11-0\"><a href=\"#cite_note-bing-blog-robots-11\">[11]</a></sup> DuckDuckGo, <sup class=\"reference\" id=\"cite_ref-duckduckgo-bot_12-0\"><a href=\"#cite_note-duckduckgo-bot-12\">[12]</a></sup> Google,<sup class=\"reference\" id=\"cite_ref-google-webmasters-spec_13-0\"><a href=\"#cite_note-google-webmasters-spec-13\">[13]</a></sup> Yahoo!,<sup class=\"reference\" id=\"cite_ref-yahoo-search-is-bing_14-0\"><a href=\"#cite_note-yahoo-search-is-bing-14\">[14]</a></sup> and Yandex.<sup class=\"reference\" id=\"cite_ref-yandex-robots_15-0\"><a href=\"#cite_note-yandex-robots-15\">[15]</a></sup>\n",
       "</p><p>The volunteering group Archive Team explicitly ignores robots.txt for the most part, viewing it as an obsolete standard that hinders web archival efforts. According to project leader Jason Scott, \"unchecked, and left alone, the robots.txt file ensures no mirroring or reference for items that may have general use and meaning beyond the website's context.\"<sup class=\"reference\" id=\"cite_ref-16\"><a href=\"#cite_note-16\">[16]</a></sup> For some years, the <a href=\"/wiki/Internet_Archive\" title=\"Internet Archive\">Internet Archive</a> did not crawl sites with robots.txt, but in April 2017, it announced that it would no longer honour directives in the robots.txt files. “Over time we have observed that the robots.txt files that are geared toward search engine crawlers do not necessarily serve our archival purposes\".<sup class=\"reference\" id=\"cite_ref-Internet_Archive_17-0\"><a href=\"#cite_note-Internet_Archive-17\">[17]</a></sup> This was in response to entire domains being tagged with robots.txt when the content became obsolete.<sup class=\"reference\" id=\"cite_ref-Internet_Archive_17-1\"><a href=\"#cite_note-Internet_Archive-17\">[17]</a></sup>\n",
       "</p>\n",
       "<h2><span class=\"mw-headline\" id=\"Security\">Security</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Robots_exclusion_standard&amp;action=edit&amp;section=3\" title=\"Edit section: Security\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n",
       "<p>Despite the use of the terms \"allow\" and \"disallow\", the protocol is purely advisory<sup class=\"reference\" id=\"cite_ref-18\"><a href=\"#cite_note-18\">[18]</a></sup> and relies on the compliance of the <a class=\"mw-redirect\" href=\"/wiki/Web_robot\" title=\"Web robot\">web robot</a>. Malicious web robots are unlikely to honor robots.txt; some may even use the robots.txt as a guide to find disallowed links and go straight to them. While this is sometimes claimed to be a security risk,<sup class=\"reference\" id=\"cite_ref-19\"><a href=\"#cite_note-19\">[19]</a></sup> this sort of <a href=\"/wiki/Security_through_obscurity\" title=\"Security through obscurity\">security through obscurity</a> is discouraged by standards bodies. The <a href=\"/wiki/National_Institute_of_Standards_and_Technology\" title=\"National Institute of Standards and Technology\">National Institute of Standards and Technology</a> (NIST) in the United States specifically recommends against this practice: \"System security should not depend on the secrecy of the implementation or its components.\"<sup class=\"reference\" id=\"cite_ref-20\"><a href=\"#cite_note-20\">[20]</a></sup> In the context of robots.txt files, security through obscurity is not recommended as a security technique.<sup class=\"reference\" id=\"cite_ref-21\"><a href=\"#cite_note-21\">[21]</a></sup>\n",
       "</p>\n",
       "<h2><span class=\"mw-headline\" id=\"Alternatives\">Alternatives</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Robots_exclusion_standard&amp;action=edit&amp;section=4\" title=\"Edit section: Alternatives\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n",
       "<p>Many robots also pass a special <a class=\"mw-redirect\" href=\"/wiki/User-agent\" title=\"User-agent\">user-agent</a> to the web server when fetching content.<sup class=\"reference\" id=\"cite_ref-22\"><a href=\"#cite_note-22\">[22]</a></sup> A web administrator could also configure the server to automatically return failure (or <a href=\"/wiki/Cloaking\" title=\"Cloaking\">pass alternative content</a>) when it detects a connection using one of the robots.<sup class=\"reference\" id=\"cite_ref-23\"><a href=\"#cite_note-23\">[23]</a></sup><sup class=\"reference\" id=\"cite_ref-24\"><a href=\"#cite_note-24\">[24]</a></sup>\n",
       "</p><p>Some sites, notably <a href=\"/wiki/Google\" title=\"Google\">Google</a>, host a <code>humans.txt</code> file that displays site contributor information.<sup class=\"reference\" id=\"cite_ref-25\"><a href=\"#cite_note-25\">[25]</a></sup> Some sites such as <a href=\"/wiki/GitHub\" title=\"GitHub\">GitHub</a> redirect to an about page.<sup class=\"reference\" id=\"cite_ref-26\"><a href=\"#cite_note-26\">[26]</a></sup> Previously Google also had a joke file hosted at <code>/killer-robots.txt</code>.<sup class=\"reference\" id=\"cite_ref-27\"><a href=\"#cite_note-27\">[27]</a></sup>\n",
       "</p>\n",
       "<h2><span class=\"mw-headline\" id=\"Examples\">Examples</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Robots_exclusion_standard&amp;action=edit&amp;section=5\" title=\"Edit section: Examples\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n",
       "<p>This example tells <b>all robots</b> that they <b>can visit all files</b> because the wildcard <code>*</code> stands for all robots and the <code>Disallow</code> directive has no value, meaning no pages are disallowed.\n",
       "</p>\n",
       "<pre>User-agent: *\n",
       "Disallow:\n",
       "</pre>\n",
       "<p>The same result can be accomplished with an empty or missing robots.txt file.\n",
       "</p><p>This example tells <b>all robots</b> to stay out of a website:\n",
       "</p>\n",
       "<pre>User-agent: *\n",
       "Disallow: /\n",
       "</pre>\n",
       "<p>This example tells <b>all robots</b> not to enter three directories:\n",
       "</p>\n",
       "<pre>User-agent: *\n",
       "Disallow: /cgi-bin/\n",
       "Disallow: /tmp/\n",
       "Disallow: /junk/\n",
       "</pre>\n",
       "<p>This example tells <b>all robots</b> to stay away from one specific file:\n",
       "</p>\n",
       "<pre>User-agent: *\n",
       "Disallow: /directory/file.html\n",
       "</pre>\n",
       "<p>Note that all other files in the specified directory will be processed.\n",
       "</p><p>This example tells <b>a specific robot</b> to stay out of a website:\n",
       "</p>\n",
       "<pre>User-agent: BadBot # replace 'BadBot' with the actual user-agent of the bot\n",
       "Disallow: /\n",
       "</pre>\n",
       "<p>This example tells <b>two specific robots</b> not to enter one specific directory:\n",
       "</p>\n",
       "<pre>User-agent: BadBot # replace 'BadBot' with the actual user-agent of the bot\n",
       "User-agent: Googlebot\n",
       "Disallow: /private/\n",
       "</pre>\n",
       "<p>Example demonstrating how comments can be used:\n",
       "</p>\n",
       "<pre># Comments appear after the \"#\" symbol at the start of a line, or after a directive\n",
       "User-agent: * # match all bots\n",
       "Disallow: / # keep them out\n",
       "</pre>\n",
       "<p>It is also possible to list multiple <b>robots</b> with their own rules. The actual <b>robot</b> string is defined by the crawler. A few robot operators, such as <a href=\"/wiki/Google\" title=\"Google\">Google</a>, support several user-agent strings that allow the operator to deny access to a subset of their services by using specific user-agent strings.<sup class=\"reference\" id=\"cite_ref-google-webmasters-spec_13-1\"><a href=\"#cite_note-google-webmasters-spec-13\">[13]</a></sup>\n",
       "</p><p>Example demonstrating multiple user-agents:\n",
       "</p>\n",
       "<pre>User-agent: googlebot        # all Google services\n",
       "Disallow: /private/          # disallow this directory\n",
       "\n",
       "User-agent: googlebot-news   # only the news service\n",
       "Disallow: /                  # disallow everything\n",
       "\n",
       "User-agent: *                # any robot\n",
       "Disallow: /something/        # disallow this directory\n",
       "</pre>\n",
       "<p><a class=\"external free\" href=\"https://en.wikipedia.org/robots.txt\">https://en.wikipedia.org/robots.txt</a>\n",
       "</p>\n",
       "<h2><span class=\"mw-headline\" id=\"Nonstandard_extensions\">Nonstandard extensions</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Robots_exclusion_standard&amp;action=edit&amp;section=6\" title=\"Edit section: Nonstandard extensions\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n",
       "<h3><span class=\"mw-headline\" id=\"Crawl-delay_directive\">Crawl-delay directive</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Robots_exclusion_standard&amp;action=edit&amp;section=7\" title=\"Edit section: Crawl-delay directive\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n",
       "<p>The crawl-delay value is supported by some crawlers to throttle their visits to the host. Since this value is not part of the standard, its interpretation is dependent on the crawler reading it. Yandex interprets the value as the number of seconds to wait between subsequent visits.<sup class=\"reference\" id=\"cite_ref-yandex-robots_15-1\"><a href=\"#cite_note-yandex-robots-15\">[15]</a></sup> Bing defines crawl-delay as the size of a time window (from 1 to 30 seconds) during which BingBot will access a web site only once.<sup class=\"reference\" id=\"cite_ref-bing-crawl-delay_28-0\"><a href=\"#cite_note-bing-crawl-delay-28\">[28]</a></sup>\n",
       "</p>\n",
       "<pre>User-agent: *\n",
       "Crawl-delay: 10\n",
       "</pre>\n",
       "<h3><span class=\"mw-headline\" id=\"Allow_directive\">Allow directive</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Robots_exclusion_standard&amp;action=edit&amp;section=8\" title=\"Edit section: Allow directive\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n",
       "<p>Some major crawlers support an <code>Allow</code> directive, which can counteract a following <code>Disallow</code> directive.<sup class=\"reference\" id=\"cite_ref-29\"><a href=\"#cite_note-29\">[29]</a></sup><sup class=\"reference\" id=\"cite_ref-30\"><a href=\"#cite_note-30\">[30]</a></sup> This is useful when one tells robots to avoid an entire directory but still wants some HTML documents in that directory crawled and indexed. While by standard implementation the first matching robots.txt pattern always wins, Google's implementation differs in that Allow patterns with equal or more characters in the directive path win over a matching Disallow pattern.<sup class=\"reference\" id=\"cite_ref-31\"><a href=\"#cite_note-31\">[31]</a></sup> Bing uses either the <code>Allow</code> or <code>Disallow</code> directive, whichever is more specific, based on length, like Google.<sup class=\"reference\" id=\"cite_ref-bing-blog-robots_11-1\"><a href=\"#cite_note-bing-blog-robots-11\">[11]</a></sup>\n",
       "</p><p>In order to be compatible to all robots, if one wants to allow single files inside an otherwise disallowed directory, it is necessary to place the Allow directive(s) first, followed by the Disallow, for example:\n",
       "</p>\n",
       "<pre>Allow: /directory1/myfile.html\n",
       "Disallow: /directory1/\n",
       "</pre>\n",
       "<p>This example will Disallow anything in /directory1/ except /directory1/myfile.html, since the latter will match first. The order is only important to robots that follow the standard; in the case of the Google or Bing bots, the order is not important.\n",
       "</p>\n",
       "<h3><span class=\"mw-headline\" id=\"Sitemap\">Sitemap</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Robots_exclusion_standard&amp;action=edit&amp;section=9\" title=\"Edit section: Sitemap\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n",
       "<p>Some crawlers support a <code>Sitemap</code> directive, allowing multiple <a href=\"/wiki/Sitemaps\" title=\"Sitemaps\">Sitemaps</a> in the same robots.txt in the form:<sup class=\"reference\" id=\"cite_ref-32\"><a href=\"#cite_note-32\">[32]</a></sup>\n",
       "</p>\n",
       "<pre>Sitemap: http://www.gstatic.com/s2/sitemaps/profiles-sitemap.xml\n",
       "\n",
       "Sitemap: http://www.google.com/hostednews/sitemap_index.xml\n",
       "</pre>\n",
       "<h3><span class=\"mw-headline\" id=\"Host\">Host</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Robots_exclusion_standard&amp;action=edit&amp;section=10\" title=\"Edit section: Host\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n",
       "<p>Some crawlers (<a href=\"/wiki/Yandex_Search\" title=\"Yandex Search\">Yandex</a>) support a <code>Host</code> directive, allowing websites with multiple mirrors to specify their preferred domain:<sup class=\"reference\" id=\"cite_ref-33\"><a href=\"#cite_note-33\">[33]</a></sup>\n",
       "</p>\n",
       "<pre>Host: hosting.example.com\n",
       "</pre>\n",
       "<p><b>Note</b>: This is not supported by all crawlers and if used, it should be inserted at the bottom of the <link href=\"mw-data:TemplateStyles:r854393789\" rel=\"mw-deduplicated-inline-style\"/><span class=\"monospaced\">robots.txt</span> file after <code>Crawl-delay</code> directive.\n",
       "</p>\n",
       "<h3><span id=\"Universal_.22.2A.22_match\"></span><span class=\"mw-headline\" id='Universal_\"*\"_match'>Universal \"*\" match</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Robots_exclusion_standard&amp;action=edit&amp;section=11\" title='Edit section: Universal \"*\" match'>edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n",
       "<p>The <i>Robot Exclusion Standard</i> does not mention anything about the \"*\" character in the <code>Disallow:</code> statement. Some crawlers like Googlebot recognize strings containing \"*\", while MSNbot and Teoma interpret it in different ways.<sup class=\"noprint Inline-Template Template-Fact\" style=\"white-space:nowrap;\">[<i><a href=\"/wiki/Wikipedia:Citation_needed\" title=\"Wikipedia:Citation needed\"><span title=\"This claim needs references to reliable sources. (November 2016)\">citation needed</span></a></i>]</sup>\n",
       "</p>\n",
       "<h2><span class=\"mw-headline\" id=\"Meta_tags_and_headers\">Meta tags and headers</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Robots_exclusion_standard&amp;action=edit&amp;section=12\" title=\"Edit section: Meta tags and headers\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n",
       "<p>In addition to root-level robots.txt files, robots exclusion directives can be applied at a more granular level through the use of <a class=\"mw-redirect\" href=\"/wiki/Robots_meta_tag\" title=\"Robots meta tag\">Robots meta tags</a> and X-Robots-Tag HTTP headers. The robots meta tag cannot be used for non-HTML files such as images, text files, or PDF documents. On the other hand, the X-Robots-Tag can be added to non-HTML files by using <a href=\"/wiki/.htaccess\" title=\".htaccess\">.htaccess</a> and <a class=\"mw-redirect\" href=\"/wiki/Httpd.conf\" title=\"Httpd.conf\">httpd.conf</a> files.<sup class=\"reference\" id=\"cite_ref-google-meta_34-0\"><a href=\"#cite_note-google-meta-34\">[34]</a></sup>\n",
       "</p>\n",
       "<dl><dt>A \"noindex\" meta tag</dt></dl>\n",
       "<div class=\"mw-highlight mw-content-ltr\" dir=\"ltr\"><pre><span></span><span class=\"p\">&lt;</span><span class=\"nt\">meta</span> <span class=\"na\">name</span><span class=\"o\">=</span><span class=\"s\">\"robots\"</span> <span class=\"na\">content</span><span class=\"o\">=</span><span class=\"s\">\"noindex\"</span> <span class=\"p\">/&gt;</span>\n",
       "</pre></div>\n",
       "<dl><dt>A \"noindex\" HTTP response header</dt></dl>\n",
       "<div class=\"mw-highlight mw-content-ltr\" dir=\"ltr\"><pre><span></span>X-Robots-Tag: noindex\n",
       "</pre></div>\n",
       "<p>The X-Robots-Tag is only effective after the page has been requested and the server responds, and the robots meta tag is only effective after the page has loaded, whereas robots.txt is effective before the page is requested. Thus if a page is excluded by a robots.txt file, any robots meta tags or X-Robots-Tag headers are effectively ignored because the robot will not see them in the first place.<sup class=\"reference\" id=\"cite_ref-google-meta_34-1\"><a href=\"#cite_note-google-meta-34\">[34]</a></sup>\n",
       "</p>\n",
       "<h2><span class=\"mw-headline\" id=\"See_also\">See also</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Robots_exclusion_standard&amp;action=edit&amp;section=13\" title=\"Edit section: See also\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n",
       "<div class=\"div-col columns column-width\" style=\"-moz-column-width: 30em; -webkit-column-width: 30em; column-width: 30em;\">\n",
       "<ul><li><code><a href=\"/wiki/Ads.txt\" title=\"Ads.txt\">ads.txt</a></code>, a standard for listing authorized ad sellers</li>\n",
       "<li><a href=\"/wiki/Automated_Content_Access_Protocol\" title=\"Automated Content Access Protocol\">Automated Content Access Protocol</a> – a failed proposal to extend robots.txt</li>\n",
       "<li><a href=\"/wiki/BotSeer\" title=\"BotSeer\">BotSeer</a> – now inactive search engine for robots.txt files</li>\n",
       "<li><a href=\"/wiki/Distributed_web_crawling\" title=\"Distributed web crawling\">Distributed web crawling</a></li>\n",
       "<li><a href=\"/wiki/Focused_crawler\" title=\"Focused crawler\">Focused crawler</a></li>\n",
       "<li><a href=\"/wiki/Internet_Archive\" title=\"Internet Archive\">Internet Archive</a></li>\n",
       "<li><a href=\"/wiki/National_Digital_Library_Program\" title=\"National Digital Library Program\">National Digital Library Program</a> (NDLP)</li>\n",
       "<li><a href=\"/wiki/National_Digital_Information_Infrastructure_and_Preservation_Program\" title=\"National Digital Information Infrastructure and Preservation Program\">National Digital Information Infrastructure and Preservation Program</a> (NDIIPP)</li>\n",
       "<li><a href=\"/wiki/Nofollow\" title=\"Nofollow\">Nofollow</a></li>\n",
       "<li><a href=\"/wiki/Perma.cc\" title=\"Perma.cc\">Perma.cc</a></li>\n",
       "<li><a class=\"mw-redirect\" href=\"/wiki/Robots_meta_tag\" title=\"Robots meta tag\">Meta elements</a> for search engines</li>\n",
       "<li><a href=\"/wiki/Sitemaps\" title=\"Sitemaps\">Sitemaps</a></li>\n",
       "<li><a href=\"/wiki/Spider_trap\" title=\"Spider trap\">Spider trap</a></li>\n",
       "<li><a href=\"/wiki/Web_archiving\" title=\"Web archiving\">Web archiving</a></li>\n",
       "<li><a href=\"/wiki/Web_crawler\" title=\"Web crawler\">Web crawler</a></li></ul>\n",
       "</div>\n",
       "<h2><span class=\"mw-headline\" id=\"References\">References</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Robots_exclusion_standard&amp;action=edit&amp;section=14\" title=\"Edit section: References\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n",
       "<div class=\"reflist columns references-column-width\" style=\"-moz-column-width: 30em; -webkit-column-width: 30em; column-width: 30em; list-style-type: decimal;\">\n",
       "<ol class=\"references\">\n",
       "<li id=\"cite_note-1\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-1\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"http://www.greenhills.co.uk/historical.html\" rel=\"nofollow\">\"Historical\"</a>. <i>Greenhills.co.uk</i><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2017-03-03</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Greenhills.co.uk&amp;rft.atitle=Historical&amp;rft_id=http%3A%2F%2Fwww.greenhills.co.uk%2Fhistorical.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-2\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-2\">^</a></b></span> <span class=\"reference-text\">\n",
       "<cite class=\"citation web\">Fielding, Roy (1994). <a class=\"external text\" href=\"http://www94.web.cern.ch/WWW94/PapersWWW94/fielding.ps\" rel=\"nofollow\">\"Maintaining Distributed Hypertext Infostructures: Welcome to MOMspider's Web\"</a> <span style=\"font-size:85%;\">(PostScript)</span>. <i>First International Conference on the World Wide Web</i>. Geneva<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">September 25,</span> 2013</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=First+International+Conference+on+the+World+Wide+Web&amp;rft.atitle=Maintaining+Distributed+Hypertext+Infostructures%3A+Welcome+to+MOMspider%27s+Web&amp;rft.date=1994&amp;rft.aulast=Fielding&amp;rft.aufirst=Roy&amp;rft_id=http%3A%2F%2Fwww94.web.cern.ch%2FWWW94%2FPapersWWW94%2Ffielding.ps&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-3\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-3\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"http://www.robotstxt.org/orig.html#status\" rel=\"nofollow\">\"The Web Robots Pages\"</a>. Robotstxt.org. 1994-06-30<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2013-12-29</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=The+Web+Robots+Pages&amp;rft.pub=Robotstxt.org&amp;rft.date=1994-06-30&amp;rft_id=http%3A%2F%2Fwww.robotstxt.org%2Forig.html%23status&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-4\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-4\">^</a></b></span> <span class=\"reference-text\">\n",
       "<cite class=\"citation web\">Koster, Martijn (25 February 1994). <a class=\"external text\" href=\"https://web.archive.org/web/20131029200350/http://inkdroid.org/tmp/www-talk/4113.html\" rel=\"nofollow\">\"Important: Spiders, Robots and Web Wanderers\"</a>. <i>www-talk mailing list</i>. Archived from <a class=\"external text\" href=\"http://inkdroid.org/tmp/www-talk/4113.html\" rel=\"nofollow\">the original</a> <span style=\"font-size:85%;\">(<a href=\"/wiki/Hypermail\" title=\"Hypermail\">Hypermail</a> archived message)</span> on October 29, 2013.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=www-talk+mailing+list&amp;rft.atitle=Important%3A+Spiders%2C+Robots+and+Web+Wanderers&amp;rft.date=1994-02-25&amp;rft.aulast=Koster&amp;rft.aufirst=Martijn&amp;rft_id=http%3A%2F%2Finkdroid.org%2Ftmp%2Fwww-talk%2F4113.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-5\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-5\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"http://www.antipope.org/charlie/blog-static/2009/06/how_i_got_here_in_the_end_part_3.html\" rel=\"nofollow\">\"How I got here in the end, part five: \"things can only get better!<span style=\"padding-right:0.2em;\">\"</span>\"</a>. <i>Charlie's Diary</i>. 19 June 2006<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">19 April</span> 2014</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Charlie%27s+Diary&amp;rft.atitle=How+I+got+here+in+the+end%2C+part+five%3A+%22things+can+only+get+better%21%22&amp;rft.date=2006-06-19&amp;rft_id=http%3A%2F%2Fwww.antipope.org%2Fcharlie%2Fblog-static%2F2009%2F06%2Fhow_i_got_here_in_the_end_part_3.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-sear_Robo-6\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-sear_Robo_6-0\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\">Barry Schwartz (30 June 2014). <a class=\"external text\" href=\"http://searchengineland.com/robots-txt-celebrates-20-years-blocking-search-engines-195479\" rel=\"nofollow\">\"Robots.txt Celebrates 20 Years Of Blocking Search Engines\"</a>. <i>Search Engine Land</i><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2015-11-19</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Search+Engine+Land&amp;rft.atitle=Robots.txt+Celebrates+20+Years+Of+Blocking+Search+Engines&amp;rft.date=2014-06-30&amp;rft.au=Barry+Schwartz&amp;rft_id=http%3A%2F%2Fsearchengineland.com%2Frobots-txt-celebrates-20-years-blocking-search-engines-195479&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-7\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-7\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"https://www.youtube.com/watch?v=KBdEwpRQRD0#t=196s\" rel=\"nofollow\">\"Uncrawled URLs in search results\"</a>. YouTube. Oct 5, 2009<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2013-12-29</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Uncrawled+URLs+in+search+results&amp;rft.pub=YouTube&amp;rft.date=2009-10-05&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DKBdEwpRQRD0%23t%3D196s&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-ask-webmasters-8\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-ask-webmasters_8-0\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"http://about.ask.com/docs/about/webmasters.shtml\" rel=\"nofollow\">\"About Ask.com: Webmasters\"</a>. <i>About.ask.com</i><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">16 February</span> 2013</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=About.ask.com&amp;rft.atitle=About+Ask.com%3A+Webmasters&amp;rft_id=http%3A%2F%2Fabout.ask.com%2Fdocs%2Fabout%2Fwebmasters.shtml&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-about-aol-search-9\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-about-aol-search_9-0\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"http://search.aol.com/aol/about\" rel=\"nofollow\">\"About AOL Search\"</a>. <i>Search.aol.com</i><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">16 February</span> 2013</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Search.aol.com&amp;rft.atitle=About+AOL+Search&amp;rft_id=http%3A%2F%2Fsearch.aol.com%2Faol%2Fabout&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-baidu-spider-10\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-baidu-spider_10-0\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"http://www.baidu.com/search/spider_english.html\" rel=\"nofollow\">\"Baiduspider\"</a>. <i>Baidu.com</i><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">16 February</span> 2013</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Baidu.com&amp;rft.atitle=Baiduspider&amp;rft_id=http%3A%2F%2Fwww.baidu.com%2Fsearch%2Fspider_english.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-bing-blog-robots-11\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-bing-blog-robots_11-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-bing-blog-robots_11-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"https://blogs.bing.com/webmaster/2008/06/03/robots-exclusion-protocol-joining-together-to-provide-better-documentation/\" rel=\"nofollow\">\"Robots Exclusion Protocol: joining together to provide better documentation\"</a>. <i>Blogs.bing.com</i><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">16 February</span> 2013</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Blogs.bing.com&amp;rft.atitle=Robots+Exclusion+Protocol%3A+joining+together+to+provide+better+documentation&amp;rft_id=https%3A%2F%2Fblogs.bing.com%2Fwebmaster%2F2008%2F06%2F03%2Frobots-exclusion-protocol-joining-together-to-provide-better-documentation%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-duckduckgo-bot-12\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-duckduckgo-bot_12-0\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"https://duckduckgo.com/duckduckbot\" rel=\"nofollow\">\"DuckDuckGo Bot\"</a>. <i>DuckDuckGo.com</i><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">25 April</span> 2017</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=DuckDuckGo.com&amp;rft.atitle=DuckDuckGo+Bot&amp;rft_id=https%3A%2F%2Fduckduckgo.com%2Fduckduckbot&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-google-webmasters-spec-13\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-google-webmasters-spec_13-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-google-webmasters-spec_13-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"https://developers.google.com/webmasters/control-crawl-index/docs/robots_txt\" rel=\"nofollow\">\"Webmasters: Robots.txt Specifications\"</a>. <i>Google Developers</i><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">16 February</span> 2013</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Google+Developers&amp;rft.atitle=Webmasters%3A+Robots.txt+Specifications&amp;rft_id=https%3A%2F%2Fdevelopers.google.com%2Fwebmasters%2Fcontrol-crawl-index%2Fdocs%2Frobots_txt&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-yahoo-search-is-bing-14\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-yahoo-search-is-bing_14-0\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"http://help.yahoo.com/kb/index?page=content&amp;y=PROD_SRCH&amp;locale=en_US&amp;id=SLN2217&amp;impressions=true\" rel=\"nofollow\">\"Submitting your website to Yahoo! Search\"</a><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">16 February</span> 2013</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Submitting+your+website+to+Yahoo%21+Search&amp;rft_id=http%3A%2F%2Fhelp.yahoo.com%2Fkb%2Findex%3Fpage%3Dcontent%26y%3DPROD_SRCH%26locale%3Den_US%26id%3DSLN2217%26impressions%3Dtrue&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-yandex-robots-15\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-yandex-robots_15-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-yandex-robots_15-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"http://help.yandex.com/webmaster/?id=1113851\" rel=\"nofollow\">\"Using robots.txt\"</a>. <i>Help.yandex.com</i><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">16 February</span> 2013</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Help.yandex.com&amp;rft.atitle=Using+robots.txt&amp;rft_id=http%3A%2F%2Fhelp.yandex.com%2Fwebmaster%2F%3Fid%3D1113851&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-16\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-16\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a href=\"/wiki/Jason_Scott\" title=\"Jason Scott\">Jason Scott</a>. <a class=\"external text\" href=\"http://www.archiveteam.org/index.php?title=Robots.txt\" rel=\"nofollow\">\"Robots.txt is a suicide note\"</a>. Archive Team<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">18 February</span> 2017</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Robots.txt+is+a+suicide+note&amp;rft.pub=Archive+Team&amp;rft.au=Jason+Scott&amp;rft_id=http%3A%2F%2Fwww.archiveteam.org%2Findex.php%3Ftitle%3DRobots.txt&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-Internet_Archive-17\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-Internet_Archive_17-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-Internet_Archive_17-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\"><cite class=\"citation news\">Jones, Brad (24 April 2017). <a class=\"external text\" href=\"https://www.digitaltrends.com/computing/internet-archive-robots-txt/#ixzz4gQYOqpUi\" rel=\"nofollow\">\"The Internet Archive Will Ignore Robots.txt Files to Maintain Accuracy\"</a>. <i><a href=\"/wiki/Digital_Trends\" title=\"Digital Trends\">Digital Trends</a></i><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">8 May</span> 2017</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Digital+Trends&amp;rft.atitle=The+Internet+Archive+Will+Ignore+Robots.txt+Files+to+Maintain+Accuracy&amp;rft.date=2017-04-24&amp;rft.aulast=Jones&amp;rft.aufirst=Brad&amp;rft_id=https%3A%2F%2Fwww.digitaltrends.com%2Fcomputing%2Finternet-archive-robots-txt%2F%23ixzz4gQYOqpUi&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-18\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-18\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"https://support.google.com/webmasters/answer/6062608\" rel=\"nofollow\">\"Block URLs with robots.txt: Learn about robots.txt files\"</a>. Google<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2015-08-10</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Block+URLs+with+robots.txt%3A+Learn+about+robots.txt+files&amp;rft.pub=Google&amp;rft_id=https%3A%2F%2Fsupport.google.com%2Fwebmasters%2Fanswer%2F6062608&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-19\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-19\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"https://www.theregister.co.uk/2015/05/19/robotstxt/\" rel=\"nofollow\">\"Robots.txt tells hackers the places you don't want them to look\"</a>. <i>The Register</i><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">August 12,</span> 2015</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Register&amp;rft.atitle=Robots.txt+tells+hackers+the+places+you+don%27t+want+them+to+look&amp;rft_id=https%3A%2F%2Fwww.theregister.co.uk%2F2015%2F05%2F19%2Frobotstxt%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-20\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-20\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"http://csrc.nist.gov/publications/nistpubs/800-123/SP800-123.pdf\" rel=\"nofollow\">\"Guide to General Server Security\"</a> <span style=\"font-size:85%;\">(PDF)</span>. National Institute of Standards and Technology. July 2008<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">August 12,</span> 2015</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Guide+to+General+Server+Security&amp;rft.pub=National+Institute+of+Standards+and+Technology&amp;rft.date=2008-07&amp;rft_id=http%3A%2F%2Fcsrc.nist.gov%2Fpublications%2Fnistpubs%2F800-123%2FSP800-123.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-21\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-21\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation book\">Sverre H. Huseby (2004). <a class=\"external text\" href=\"https://books.google.com/books?id=RjVjgPQsKogC&amp;pg=PA92\" rel=\"nofollow\"><i>Innocent Code: A Security Wake-Up Call for Web Programmers</i></a>. John Wiley &amp; Sons,. pp. 91–92. <a href=\"/wiki/International_Standard_Book_Number\" title=\"International Standard Book Number\">ISBN</a> <a href=\"/wiki/Special:BookSources/9780470857472\" title=\"Special:BookSources/9780470857472\">9780470857472</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Innocent+Code%3A+A+Security+Wake-Up+Call+for+Web+Programmers&amp;rft.pages=91-92&amp;rft.pub=John+Wiley+%26+Sons%2C&amp;rft.date=2004&amp;rft.isbn=9780470857472&amp;rft.au=Sverre+H.+Huseby&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DRjVjgPQsKogC%26pg%3DPA92&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-22\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-22\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"http://www.user-agents.org/\" rel=\"nofollow\">\"List of User-Agents (Spiders, Robots, Browser)\"</a>. User-agents.org<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2013-12-29</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=List+of+User-Agents+%28Spiders%2C+Robots%2C+Browser%29&amp;rft.pub=User-agents.org&amp;rft_id=http%3A%2F%2Fwww.user-agents.org%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-23\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-23\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"https://httpd.apache.org/docs/2.2/howto/access.html\" rel=\"nofollow\">\"Access Control - Apache HTTP Server\"</a>. Httpd.apache.org<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2013-12-29</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Access+Control+-+Apache+HTTP+Server&amp;rft.pub=Httpd.apache.org&amp;rft_id=https%3A%2F%2Fhttpd.apache.org%2Fdocs%2F2.2%2Fhowto%2Faccess.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-24\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-24\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"http://www.iis.net/configreference/system.webserver/security/requestfiltering/filteringrules/filteringrule/denystrings\" rel=\"nofollow\">\"Deny Strings for Filtering Rules : The Official Microsoft IIS Site\"</a>. Iis.net. 2013-11-06<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2013-12-29</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Deny+Strings+for+Filtering+Rules+%3A+The+Official+Microsoft+IIS+Site&amp;rft.pub=Iis.net&amp;rft.date=2013-11-06&amp;rft_id=http%3A%2F%2Fwww.iis.net%2Fconfigreference%2Fsystem.webserver%2Fsecurity%2Frequestfiltering%2Ffilteringrules%2Ffilteringrule%2Fdenystrings&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-25\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-25\">^</a></b></span> <span class=\"reference-text\"><a class=\"external free\" href=\"https://www.google.com/humans.txt\" rel=\"nofollow\">https://www.google.com/humans.txt</a></span>\n",
       "</li>\n",
       "<li id=\"cite_note-26\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-26\">^</a></b></span> <span class=\"reference-text\"><a class=\"external free\" href=\"https://github.com/humans.txt\" rel=\"nofollow\">https://github.com/humans.txt</a></span>\n",
       "</li>\n",
       "<li id=\"cite_note-27\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-27\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"https://web.archive.org/web/20180110160916/https://www.google.com/killer-robots.txt\" rel=\"nofollow\">\"Wayback Machine\"</a>. 2018-01-10<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2018-05-25</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Wayback+Machine&amp;rft.date=2018-01-10&amp;rft_id=https%3A%2F%2Fweb.archive.org%2Fweb%2F20180110160916%2Fhttps%3A%2F%2Fwww.google.com%2Fkiller-robots.txt&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-bing-crawl-delay-28\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-bing-crawl-delay_28-0\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"https://blogs.bing.com/webmaster/2012/05/03/to-crawl-or-not-to-crawl-that-is-bingbots-question/\" rel=\"nofollow\">\"To crawl or not to crawl, that is BingBot's question\"</a>. 3 May 2012<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">9 February</span> 2016</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=To+crawl+or+not+to+crawl%2C+that+is+BingBot%E2%80%99s+question&amp;rft.date=2012-05-03&amp;rft_id=https%3A%2F%2Fblogs.bing.com%2Fwebmaster%2F2012%2F05%2F03%2Fto-crawl-or-not-to-crawl-that-is-bingbots-question%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-29\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-29\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"http://www.google.com/support/webmasters/bin/answer.py?hl=en&amp;answer=156449&amp;from=40364\" rel=\"nofollow\">\"Webmaster Help Center - How do I block Googlebot?\"</a><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2007-11-20</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Webmaster+Help+Center+-+How+do+I+block+Googlebot%3F&amp;rft_id=http%3A%2F%2Fwww.google.com%2Fsupport%2Fwebmasters%2Fbin%2Fanswer.py%3Fhl%3Den%26answer%3D156449%26from%3D40364&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-30\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-30\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"http://help.yahoo.com/l/us/yahoo/search/webcrawler/slurp-02.html\" rel=\"nofollow\">\"How do I prevent my site or certain subdirectories from being crawled? - Yahoo Search Help\"</a><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2007-11-20</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=How+do+I+prevent+my+site+or+certain+subdirectories+from+being+crawled%3F+-+Yahoo+Search+Help&amp;rft_id=http%3A%2F%2Fhelp.yahoo.com%2Fl%2Fus%2Fyahoo%2Fsearch%2Fwebcrawler%2Fslurp-02.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-31\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-31\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"http://blog.semetrical.com/googles-secret-approach-to-robots-txt/\" rel=\"nofollow\">\"Google's Hidden Interpretation of Robots.txt\"</a><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2010-11-15</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Google%27s+Hidden+Interpretation+of+Robots.txt&amp;rft_id=http%3A%2F%2Fblog.semetrical.com%2Fgoogles-secret-approach-to-robots-txt%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-32\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-32\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"http://ysearchblog.com/2007/04/11/webmasters-can-now-auto-discover-with-sitemaps/\" rel=\"nofollow\">\"Yahoo! Search Blog - Webmasters can now auto-discover with Sitemaps\"</a><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2009-03-23</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Yahoo%21+Search+Blog+-+Webmasters+can+now+auto-discover+with+Sitemaps&amp;rft_id=http%3A%2F%2Fysearchblog.com%2F2007%2F04%2F11%2Fwebmasters-can-now-auto-discover-with-sitemaps%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-33\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-33\">^</a></b></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"http://help.yandex.com/webmaster/?id=1113851\" rel=\"nofollow\">\"Yandex - Using robots.txt\"</a><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2013-05-13</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Yandex+-+Using+robots.txt&amp;rft_id=http%3A%2F%2Fhelp.yandex.com%2Fwebmaster%2F%3Fid%3D1113851&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "<li id=\"cite_note-google-meta-34\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-google-meta_34-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-google-meta_34-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\"><cite class=\"citation web\"><a class=\"external text\" href=\"https://developers.google.com/webmasters/control-crawl-index/docs/robots_meta_tag\" rel=\"nofollow\">\"Robots meta tag and X-Robots-Tag HTTP header specifications - Webmasters — Google Developers\"</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Robots+meta+tag+and+X-Robots-Tag+HTTP+header+specifications+-+Webmasters+%E2%80%94+Google+Developers&amp;rft_id=https%3A%2F%2Fdevelopers.google.com%2Fwebmasters%2Fcontrol-crawl-index%2Fdocs%2Frobots_meta_tag&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARobots+exclusion+standard\"><span style=\"display:none;\"> </span></span></span>\n",
       "</li>\n",
       "</ol></div>\n",
       "<h2><span class=\"mw-headline\" id=\"External_links\">External links</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Robots_exclusion_standard&amp;action=edit&amp;section=15\" title=\"Edit section: External links\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n",
       "<ul><li><span class=\"official-website\"><span class=\"url\"><a class=\"external text\" href=\"http://www.robotstxt.org\" rel=\"nofollow\">Official website</a></span></span></li>\n",
       "<li><a class=\"external text\" href=\"http://www.robotstxt.org/db.html\" rel=\"nofollow\">Robots Database (list of bot names)</a></li></ul>\n",
       "<div aria-label=\"Portals\" class=\"noprint metadata navbox\" role=\"navigation\" style=\"font-weight:bold;padding:0.4em 2em\"><ul style=\"margin:0.1em 0 0\"><li style=\"display:inline\"><span style=\"display:inline-block;white-space:nowrap\"><span style=\"margin:0 0.5em\"><a class=\"image\" href=\"/wiki/File:Crystal_Clear_app_linneighborhood.svg\"><img alt=\"Crystal Clear app linneighborhood.svg\" data-file-height=\"407\" data-file-width=\"407\" height=\"21\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/f/f9/Crystal_Clear_app_linneighborhood.svg/21px-Crystal_Clear_app_linneighborhood.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/f/f9/Crystal_Clear_app_linneighborhood.svg/32px-Crystal_Clear_app_linneighborhood.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/f9/Crystal_Clear_app_linneighborhood.svg/42px-Crystal_Clear_app_linneighborhood.svg.png 2x\" width=\"21\"/></a></span><a href=\"/wiki/Portal:Internet\" title=\"Portal:Internet\">Internet portal</a></span></li></ul></div>\n",
       "\n",
       "<!-- \n",
       "NewPP limit report\n",
       "Parsed by mw1324\n",
       "Cached time: 20180812161330\n",
       "Cache expiry: 1900800\n",
       "Dynamic content: false\n",
       "CPU time usage: 0.384 seconds\n",
       "Real time usage: 0.689 seconds\n",
       "Preprocessor visited node count: 1638/1000000\n",
       "Preprocessor generated node count: 0/1500000\n",
       "Post‐expand include size: 50199/2097152 bytes\n",
       "Template argument size: 1273/2097152 bytes\n",
       "Highest expansion depth: 11/40\n",
       "Expensive parser function count: 1/500\n",
       "Unstrip recursion depth: 0/20\n",
       "Unstrip post‐expand size: 37571/5000000 bytes\n",
       "Number of Wikibase entities loaded: 1/400\n",
       "Lua time usage: 0.183/10.000 seconds\n",
       "Lua memory usage: 4.48 MB/50 MB\n",
       "-->\n",
       "<!--\n",
       "Transclusion expansion time report (%,ms,calls,template)\n",
       "100.00%  612.397      1 -total\n",
       " 31.99%  195.892      1 Template:Reflist\n",
       " 24.04%  147.211     30 Template:Cite_web\n",
       "  7.67%   46.992      1 Template:Citation_needed\n",
       "  6.65%   40.717      1 Template:Fix\n",
       "  4.48%   27.446      2 Template:Category_handler\n",
       "  4.48%   27.408      1 Template:Official_website\n",
       "  4.10%   25.084      1 Template:Selfref\n",
       "  3.73%   22.818      1 Template:Hatnote\n",
       "  2.74%   16.780      1 Template:Authority_control\n",
       "-->\n",
       "</div>\n",
       "<!-- Saved in parser cache with key enwiki:pcache:idhash:101673-0!canonical and timestamp 20180812161330 and revision id 853666262\n",
       " -->\n",
       "<noscript>&lt;img src=\"//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1\" alt=\"\" title=\"\" width=\"1\" height=\"1\" style=\"border: none; position: absolute;\" /&gt;</noscript></div>\t\t\t\t\t<div class=\"printfooter\">\n",
       "\t\t\t\t\t\tRetrieved from \"<a dir=\"ltr\" href=\"https://en.wikipedia.org/w/index.php?title=Robots_exclusion_standard&amp;oldid=853666262\">https://en.wikipedia.org/w/index.php?title=Robots_exclusion_standard&amp;oldid=853666262</a>\"\t\t\t\t\t</div>\n",
       "\t\t\t\t<div class=\"catlinks\" data-mw=\"interface\" id=\"catlinks\"><div class=\"mw-normal-catlinks\" id=\"mw-normal-catlinks\"><a href=\"/wiki/Help:Category\" title=\"Help:Category\">Categories</a>: <ul><li><a href=\"/wiki/Category:World_Wide_Web\" title=\"Category:World Wide Web\">World Wide Web</a></li></ul></div><div class=\"mw-hidden-catlinks mw-hidden-cats-hidden\" id=\"mw-hidden-catlinks\">Hidden categories: <ul><li><a href=\"/wiki/Category:All_articles_with_unsourced_statements\" title=\"Category:All articles with unsourced statements\">All articles with unsourced statements</a></li><li><a href=\"/wiki/Category:Articles_with_unsourced_statements_from_November_2016\" title=\"Category:Articles with unsourced statements from November 2016\">Articles with unsourced statements from November 2016</a></li></ul></div></div>\t\t\t\t<div class=\"visualClear\"></div>\n",
       "\t\t\t\t\t\t\t</div>\n",
       "\t\t</div>\n",
       "\t\t<div id=\"mw-navigation\">\n",
       "\t\t\t<h2>Navigation menu</h2>\n",
       "\t\t\t<div id=\"mw-head\">\n",
       "\t\t\t\t\t\t\t\t\t<div aria-labelledby=\"p-personal-label\" class=\"\" id=\"p-personal\" role=\"navigation\">\n",
       "\t\t\t\t\t\t<h3 id=\"p-personal-label\">Personal tools</h3>\n",
       "\t\t\t\t\t\t<ul>\n",
       "\t\t\t\t\t\t\t<li id=\"pt-anonuserpage\">Not logged in</li><li id=\"pt-anontalk\"><a accesskey=\"n\" href=\"/wiki/Special:MyTalk\" title=\"Discussion about edits from this IP address [n]\">Talk</a></li><li id=\"pt-anoncontribs\"><a accesskey=\"y\" href=\"/wiki/Special:MyContributions\" title=\"A list of edits made from this IP address [y]\">Contributions</a></li><li id=\"pt-createaccount\"><a href=\"/w/index.php?title=Special:CreateAccount&amp;returnto=Robots+exclusion+standard\" title=\"You are encouraged to create an account and log in; however, it is not mandatory\">Create account</a></li><li id=\"pt-login\"><a accesskey=\"o\" href=\"/w/index.php?title=Special:UserLogin&amp;returnto=Robots+exclusion+standard\" title=\"You're encouraged to log in; however, it's not mandatory. [o]\">Log in</a></li>\t\t\t\t\t\t</ul>\n",
       "\t\t\t\t\t</div>\n",
       "\t\t\t\t\t\t\t\t\t<div id=\"left-navigation\">\n",
       "\t\t\t\t\t\t\t\t\t\t<div aria-labelledby=\"p-namespaces-label\" class=\"vectorTabs\" id=\"p-namespaces\" role=\"navigation\">\n",
       "\t\t\t\t\t\t<h3 id=\"p-namespaces-label\">Namespaces</h3>\n",
       "\t\t\t\t\t\t<ul>\n",
       "\t\t\t\t\t\t\t<li class=\"selected\" id=\"ca-nstab-main\"><span><a accesskey=\"c\" href=\"/wiki/Robots_exclusion_standard\" title=\"View the content page [c]\">Article</a></span></li><li id=\"ca-talk\"><span><a accesskey=\"t\" href=\"/wiki/Talk:Robots_exclusion_standard\" rel=\"discussion\" title=\"Discussion about the content page [t]\">Talk</a></span></li>\t\t\t\t\t\t</ul>\n",
       "\t\t\t\t\t</div>\n",
       "\t\t\t\t\t\t\t\t\t\t<div aria-labelledby=\"p-variants-label\" class=\"vectorMenu emptyPortlet\" id=\"p-variants\" role=\"navigation\">\n",
       "\t\t\t\t\t\t\t\t\t\t\t\t<input aria-labelledby=\"p-variants-label\" class=\"vectorMenuCheckbox\" type=\"checkbox\"/>\n",
       "\t\t\t\t\t\t<h3 id=\"p-variants-label\">\n",
       "\t\t\t\t\t\t\t<span>Variants</span>\n",
       "\t\t\t\t\t\t</h3>\n",
       "\t\t\t\t\t\t<div class=\"menu\">\n",
       "\t\t\t\t\t\t\t<ul>\n",
       "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</ul>\n",
       "\t\t\t\t\t\t</div>\n",
       "\t\t\t\t\t</div>\n",
       "\t\t\t\t\t\t\t\t\t</div>\n",
       "\t\t\t\t<div id=\"right-navigation\">\n",
       "\t\t\t\t\t\t\t\t\t\t<div aria-labelledby=\"p-views-label\" class=\"vectorTabs\" id=\"p-views\" role=\"navigation\">\n",
       "\t\t\t\t\t\t<h3 id=\"p-views-label\">Views</h3>\n",
       "\t\t\t\t\t\t<ul>\n",
       "\t\t\t\t\t\t\t<li class=\"collapsible selected\" id=\"ca-view\"><span><a href=\"/wiki/Robots_exclusion_standard\">Read</a></span></li><li class=\"collapsible\" id=\"ca-edit\"><span><a accesskey=\"e\" href=\"/w/index.php?title=Robots_exclusion_standard&amp;action=edit\" title=\"Edit this page [e]\">Edit</a></span></li><li class=\"collapsible\" id=\"ca-history\"><span><a accesskey=\"h\" href=\"/w/index.php?title=Robots_exclusion_standard&amp;action=history\" title=\"Past revisions of this page [h]\">View history</a></span></li>\t\t\t\t\t\t</ul>\n",
       "\t\t\t\t\t</div>\n",
       "\t\t\t\t\t\t\t\t\t\t<div aria-labelledby=\"p-cactions-label\" class=\"vectorMenu emptyPortlet\" id=\"p-cactions\" role=\"navigation\">\n",
       "\t\t\t\t\t\t<input aria-labelledby=\"p-cactions-label\" class=\"vectorMenuCheckbox\" type=\"checkbox\"/>\n",
       "\t\t\t\t\t\t<h3 id=\"p-cactions-label\"><span>More</span></h3>\n",
       "\t\t\t\t\t\t<div class=\"menu\">\n",
       "\t\t\t\t\t\t\t<ul>\n",
       "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</ul>\n",
       "\t\t\t\t\t\t</div>\n",
       "\t\t\t\t\t</div>\n",
       "\t\t\t\t\t\t\t\t\t\t<div id=\"p-search\" role=\"search\">\n",
       "\t\t\t\t\t\t<h3>\n",
       "\t\t\t\t\t\t\t<label for=\"searchInput\">Search</label>\n",
       "\t\t\t\t\t\t</h3>\n",
       "\t\t\t\t\t\t<form action=\"/w/index.php\" id=\"searchform\">\n",
       "\t\t\t\t\t\t\t<div id=\"simpleSearch\">\n",
       "\t\t\t\t\t\t\t\t<input accesskey=\"f\" id=\"searchInput\" name=\"search\" placeholder=\"Search Wikipedia\" title=\"Search Wikipedia [f]\" type=\"search\"/><input name=\"title\" type=\"hidden\" value=\"Special:Search\"/><input class=\"searchButton mw-fallbackSearchButton\" id=\"mw-searchButton\" name=\"fulltext\" title=\"Search Wikipedia for this text\" type=\"submit\" value=\"Search\"/><input class=\"searchButton\" id=\"searchButton\" name=\"go\" title=\"Go to a page with this exact name if it exists\" type=\"submit\" value=\"Go\"/>\t\t\t\t\t\t\t</div>\n",
       "\t\t\t\t\t\t</form>\n",
       "\t\t\t\t\t</div>\n",
       "\t\t\t\t\t\t\t\t\t</div>\n",
       "\t\t\t</div>\n",
       "\t\t\t<div id=\"mw-panel\">\n",
       "\t\t\t\t<div id=\"p-logo\" role=\"banner\"><a class=\"mw-wiki-logo\" href=\"/wiki/Main_Page\" title=\"Visit the main page\"></a></div>\n",
       "\t\t\t\t\t\t<div aria-labelledby=\"p-navigation-label\" class=\"portal\" id=\"p-navigation\" role=\"navigation\">\n",
       "\t\t\t<h3 id=\"p-navigation-label\">Navigation</h3>\n",
       "\t\t\t<div class=\"body\">\n",
       "\t\t\t\t\t\t\t\t<ul>\n",
       "\t\t\t\t\t<li id=\"n-mainpage-description\"><a accesskey=\"z\" href=\"/wiki/Main_Page\" title=\"Visit the main page [z]\">Main page</a></li><li id=\"n-contents\"><a href=\"/wiki/Portal:Contents\" title=\"Guides to browsing Wikipedia\">Contents</a></li><li id=\"n-featuredcontent\"><a href=\"/wiki/Portal:Featured_content\" title=\"Featured content – the best of Wikipedia\">Featured content</a></li><li id=\"n-currentevents\"><a href=\"/wiki/Portal:Current_events\" title=\"Find background information on current events\">Current events</a></li><li id=\"n-randompage\"><a accesskey=\"x\" href=\"/wiki/Special:Random\" title=\"Load a random article [x]\">Random article</a></li><li id=\"n-sitesupport\"><a href=\"https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en\" title=\"Support us\">Donate to Wikipedia</a></li><li id=\"n-shoplink\"><a href=\"//shop.wikimedia.org\" title=\"Visit the Wikipedia store\">Wikipedia store</a></li>\t\t\t\t</ul>\n",
       "\t\t\t\t\t\t\t</div>\n",
       "\t\t</div>\n",
       "\t\t\t<div aria-labelledby=\"p-interaction-label\" class=\"portal\" id=\"p-interaction\" role=\"navigation\">\n",
       "\t\t\t<h3 id=\"p-interaction-label\">Interaction</h3>\n",
       "\t\t\t<div class=\"body\">\n",
       "\t\t\t\t\t\t\t\t<ul>\n",
       "\t\t\t\t\t<li id=\"n-help\"><a href=\"/wiki/Help:Contents\" title=\"Guidance on how to use and edit Wikipedia\">Help</a></li><li id=\"n-aboutsite\"><a href=\"/wiki/Wikipedia:About\" title=\"Find out about Wikipedia\">About Wikipedia</a></li><li id=\"n-portal\"><a href=\"/wiki/Wikipedia:Community_portal\" title=\"About the project, what you can do, where to find things\">Community portal</a></li><li id=\"n-recentchanges\"><a accesskey=\"r\" href=\"/wiki/Special:RecentChanges\" title=\"A list of recent changes in the wiki [r]\">Recent changes</a></li><li id=\"n-contactpage\"><a href=\"//en.wikipedia.org/wiki/Wikipedia:Contact_us\" title=\"How to contact Wikipedia\">Contact page</a></li>\t\t\t\t</ul>\n",
       "\t\t\t\t\t\t\t</div>\n",
       "\t\t</div>\n",
       "\t\t\t<div aria-labelledby=\"p-tb-label\" class=\"portal\" id=\"p-tb\" role=\"navigation\">\n",
       "\t\t\t<h3 id=\"p-tb-label\">Tools</h3>\n",
       "\t\t\t<div class=\"body\">\n",
       "\t\t\t\t\t\t\t\t<ul>\n",
       "\t\t\t\t\t<li id=\"t-whatlinkshere\"><a accesskey=\"j\" href=\"/wiki/Special:WhatLinksHere/Robots_exclusion_standard\" title=\"List of all English Wikipedia pages containing links to this page [j]\">What links here</a></li><li id=\"t-recentchangeslinked\"><a accesskey=\"k\" href=\"/wiki/Special:RecentChangesLinked/Robots_exclusion_standard\" rel=\"nofollow\" title=\"Recent changes in pages linked from this page [k]\">Related changes</a></li><li id=\"t-upload\"><a accesskey=\"u\" href=\"/wiki/Wikipedia:File_Upload_Wizard\" title=\"Upload files [u]\">Upload file</a></li><li id=\"t-specialpages\"><a accesskey=\"q\" href=\"/wiki/Special:SpecialPages\" title=\"A list of all special pages [q]\">Special pages</a></li><li id=\"t-permalink\"><a href=\"/w/index.php?title=Robots_exclusion_standard&amp;oldid=853666262\" title=\"Permanent link to this revision of the page\">Permanent link</a></li><li id=\"t-info\"><a href=\"/w/index.php?title=Robots_exclusion_standard&amp;action=info\" title=\"More information about this page\">Page information</a></li><li id=\"t-wikibase\"><a accesskey=\"g\" href=\"https://www.wikidata.org/wiki/Special:EntityPage/Q80776\" title=\"Link to connected data repository item [g]\">Wikidata item</a></li><li id=\"t-cite\"><a href=\"/w/index.php?title=Special:CiteThisPage&amp;page=Robots_exclusion_standard&amp;id=853666262\" title=\"Information on how to cite this page\">Cite this page</a></li>\t\t\t\t</ul>\n",
       "\t\t\t\t\t\t\t</div>\n",
       "\t\t</div>\n",
       "\t\t\t<div aria-labelledby=\"p-coll-print_export-label\" class=\"portal\" id=\"p-coll-print_export\" role=\"navigation\">\n",
       "\t\t\t<h3 id=\"p-coll-print_export-label\">Print/export</h3>\n",
       "\t\t\t<div class=\"body\">\n",
       "\t\t\t\t\t\t\t\t<ul>\n",
       "\t\t\t\t\t<li id=\"coll-create_a_book\"><a href=\"/w/index.php?title=Special:Book&amp;bookcmd=book_creator&amp;referer=Robots+exclusion+standard\">Create a book</a></li><li id=\"coll-download-as-rdf2latex\"><a href=\"/w/index.php?title=Special:ElectronPdf&amp;page=Robots+exclusion+standard&amp;action=show-download-screen\">Download as PDF</a></li><li id=\"t-print\"><a accesskey=\"p\" href=\"/w/index.php?title=Robots_exclusion_standard&amp;printable=yes\" title=\"Printable version of this page [p]\">Printable version</a></li>\t\t\t\t</ul>\n",
       "\t\t\t\t\t\t\t</div>\n",
       "\t\t</div>\n",
       "\t\t\t<div aria-labelledby=\"p-lang-label\" class=\"portal\" id=\"p-lang\" role=\"navigation\">\n",
       "\t\t\t<h3 id=\"p-lang-label\">Languages</h3>\n",
       "\t\t\t<div class=\"body\">\n",
       "\t\t\t\t\t\t\t\t<ul>\n",
       "\t\t\t\t\t<li class=\"interlanguage-link interwiki-ar\"><a class=\"interlanguage-link-target\" href=\"https://ar.wikipedia.org/wiki/%D9%85%D8%B9%D9%8A%D8%A7%D8%B1_%D8%A7%D8%B3%D8%AA%D8%A8%D8%B9%D8%A7%D8%AF_%D8%A7%D9%84%D8%B1%D9%88%D8%A8%D9%88%D8%AA%D8%A7%D8%AA\" hreflang=\"ar\" lang=\"ar\" title=\"معيار استبعاد الروبوتات – Arabic\">العربية</a></li><li class=\"interlanguage-link interwiki-bar\"><a class=\"interlanguage-link-target\" href=\"https://bar.wikipedia.org/wiki/Robots_Exclusion_Standard\" hreflang=\"bar\" lang=\"bar\" title=\"Robots Exclusion Standard – Bavarian\">Boarisch</a></li><li class=\"interlanguage-link interwiki-ca\"><a class=\"interlanguage-link-target\" href=\"https://ca.wikipedia.org/wiki/Protocol_d%27exclusi%C3%B3_de_robots\" hreflang=\"ca\" lang=\"ca\" title=\"Protocol d'exclusió de robots – Catalan\">Català</a></li><li class=\"interlanguage-link interwiki-cs\"><a class=\"interlanguage-link-target\" href=\"https://cs.wikipedia.org/wiki/Protokol_pro_zak%C3%A1z%C3%A1n%C3%AD_p%C5%99%C3%ADstupu_robot%C5%AFm\" hreflang=\"cs\" lang=\"cs\" title=\"Protokol pro zakázání přístupu robotům – Czech\">Čeština</a></li><li class=\"interlanguage-link interwiki-da\"><a class=\"interlanguage-link-target\" href=\"https://da.wikipedia.org/wiki/Robot_Exclusion_Standard\" hreflang=\"da\" lang=\"da\" title=\"Robot Exclusion Standard – Danish\">Dansk</a></li><li class=\"interlanguage-link interwiki-de\"><a class=\"interlanguage-link-target\" href=\"https://de.wikipedia.org/wiki/Robots_Exclusion_Standard\" hreflang=\"de\" lang=\"de\" title=\"Robots Exclusion Standard – German\">Deutsch</a></li><li class=\"interlanguage-link interwiki-es\"><a class=\"interlanguage-link-target\" href=\"https://es.wikipedia.org/wiki/Est%C3%A1ndar_de_exclusi%C3%B3n_de_robots\" hreflang=\"es\" lang=\"es\" title=\"Estándar de exclusión de robots – Spanish\">Español</a></li><li class=\"interlanguage-link interwiki-fa\"><a class=\"interlanguage-link-target\" href=\"https://fa.wikipedia.org/wiki/%D8%A7%D8%B3%D8%AA%D8%A7%D9%86%D8%AF%D8%A7%D8%B1%D8%AF_%D8%A7%D8%B3%D8%AA%D8%AB%D9%86%D8%A7%D8%A1_%DA%A9%D8%B1%D8%AF%D9%86_%D8%B1%D8%A8%D8%A7%D8%AA%E2%80%8C%D9%87%D8%A7\" hreflang=\"fa\" lang=\"fa\" title=\"استاندارد استثناء کردن ربات‌ها – Persian\">فارسی</a></li><li class=\"interlanguage-link interwiki-fr\"><a class=\"interlanguage-link-target\" href=\"https://fr.wikipedia.org/wiki/Protocole_d%27exclusion_des_robots\" hreflang=\"fr\" lang=\"fr\" title=\"Protocole d'exclusion des robots – French\">Français</a></li><li class=\"interlanguage-link interwiki-ko\"><a class=\"interlanguage-link-target\" href=\"https://ko.wikipedia.org/wiki/%EB%A1%9C%EB%B4%87_%EB%B0%B0%EC%A0%9C_%ED%91%9C%EC%A4%80\" hreflang=\"ko\" lang=\"ko\" title=\"로봇 배제 표준 – Korean\">한국어</a></li><li class=\"interlanguage-link interwiki-id\"><a class=\"interlanguage-link-target\" href=\"https://id.wikipedia.org/wiki/Robots.txt\" hreflang=\"id\" lang=\"id\" title=\"Robots.txt – Indonesian\">Bahasa Indonesia</a></li><li class=\"interlanguage-link interwiki-it\"><a class=\"interlanguage-link-target\" href=\"https://it.wikipedia.org/wiki/Protocollo_di_esclusione_robot\" hreflang=\"it\" lang=\"it\" title=\"Protocollo di esclusione robot – Italian\">Italiano</a></li><li class=\"interlanguage-link interwiki-he\"><a class=\"interlanguage-link-target\" href=\"https://he.wikipedia.org/wiki/%D7%A4%D7%A8%D7%95%D7%98%D7%95%D7%A7%D7%95%D7%9C_%D7%90%D7%99_%D7%94%D7%9B%D7%9C%D7%9C%D7%AA_%D7%A8%D7%95%D7%91%D7%95%D7%98%D7%99%D7%9D\" hreflang=\"he\" lang=\"he\" title=\"פרוטוקול אי הכללת רובוטים – Hebrew\">עברית</a></li><li class=\"interlanguage-link interwiki-nl\"><a class=\"interlanguage-link-target\" href=\"https://nl.wikipedia.org/wiki/Robots_Exclusion_Protocol\" hreflang=\"nl\" lang=\"nl\" title=\"Robots Exclusion Protocol – Dutch\">Nederlands</a></li><li class=\"interlanguage-link interwiki-ja\"><a class=\"interlanguage-link-target\" href=\"https://ja.wikipedia.org/wiki/Robots_Exclusion_Standard\" hreflang=\"ja\" lang=\"ja\" title=\"Robots Exclusion Standard – Japanese\">日本語</a></li><li class=\"interlanguage-link interwiki-pl\"><a class=\"interlanguage-link-target\" href=\"https://pl.wikipedia.org/wiki/Robots_Exclusion_Protocol\" hreflang=\"pl\" lang=\"pl\" title=\"Robots Exclusion Protocol – Polish\">Polski</a></li><li class=\"interlanguage-link interwiki-pt\"><a class=\"interlanguage-link-target\" href=\"https://pt.wikipedia.org/wiki/Protocolo_de_Exclus%C3%A3o_de_Rob%C3%B4s\" hreflang=\"pt\" lang=\"pt\" title=\"Protocolo de Exclusão de Robôs – Portuguese\">Português</a></li><li class=\"interlanguage-link interwiki-ru\"><a class=\"interlanguage-link-target\" href=\"https://ru.wikipedia.org/wiki/%D0%A1%D1%82%D0%B0%D0%BD%D0%B4%D0%B0%D1%80%D1%82_%D0%B8%D1%81%D0%BA%D0%BB%D1%8E%D1%87%D0%B5%D0%BD%D0%B8%D0%B9_%D0%B4%D0%BB%D1%8F_%D1%80%D0%BE%D0%B1%D0%BE%D1%82%D0%BE%D0%B2\" hreflang=\"ru\" lang=\"ru\" title=\"Стандарт исключений для роботов – Russian\">Русский</a></li><li class=\"interlanguage-link interwiki-simple\"><a class=\"interlanguage-link-target\" href=\"https://simple.wikipedia.org/wiki/Robots_exclusion_standard\" hreflang=\"simple\" lang=\"simple\" title=\"Robots exclusion standard – Simple English\">Simple English</a></li><li class=\"interlanguage-link interwiki-sr\"><a class=\"interlanguage-link-target\" href=\"https://sr.wikipedia.org/wiki/Standard_isklju%C4%8Denja_robota\" hreflang=\"sr\" lang=\"sr\" title=\"Standard isključenja robota – Serbian\">Српски / srpski</a></li><li class=\"interlanguage-link interwiki-fi\"><a class=\"interlanguage-link-target\" href=\"https://fi.wikipedia.org/wiki/Robotin_rajausstandardi\" hreflang=\"fi\" lang=\"fi\" title=\"Robotin rajausstandardi – Finnish\">Suomi</a></li><li class=\"interlanguage-link interwiki-sv\"><a class=\"interlanguage-link-target\" href=\"https://sv.wikipedia.org/wiki/Robots_Exclusion_Standard\" hreflang=\"sv\" lang=\"sv\" title=\"Robots Exclusion Standard – Swedish\">Svenska</a></li><li class=\"interlanguage-link interwiki-tr\"><a class=\"interlanguage-link-target\" href=\"https://tr.wikipedia.org/wiki/Robot_engelleme_standard%C4%B1\" hreflang=\"tr\" lang=\"tr\" title=\"Robot engelleme standardı – Turkish\">Türkçe</a></li><li class=\"interlanguage-link interwiki-uk\"><a class=\"interlanguage-link-target\" href=\"https://uk.wikipedia.org/wiki/Robots.txt\" hreflang=\"uk\" lang=\"uk\" title=\"Robots.txt – Ukrainian\">Українська</a></li><li class=\"interlanguage-link interwiki-zh\"><a class=\"interlanguage-link-target\" href=\"https://zh.wikipedia.org/wiki/Robots.txt\" hreflang=\"zh\" lang=\"zh\" title=\"Robots.txt – Chinese\">中文</a></li>\t\t\t\t</ul>\n",
       "\t\t\t\t<div class=\"after-portlet after-portlet-lang\"><span class=\"wb-langlinks-edit wb-langlinks-link\"><a class=\"wbc-editpage\" href=\"https://www.wikidata.org/wiki/Special:EntityPage/Q80776#sitelinks-wikipedia\" title=\"Edit interlanguage links\">Edit links</a></span></div>\t\t\t</div>\n",
       "\t\t</div>\n",
       "\t\t\t\t</div>\n",
       "\t\t</div>\n",
       "\t\t\t\t<div id=\"footer\" role=\"contentinfo\">\n",
       "\t\t\t\t\t\t<ul id=\"footer-info\">\n",
       "\t\t\t\t\t\t\t\t<li id=\"footer-info-lastmod\"> This page was last edited on 6 August 2018, at 06:39<span class=\"anonymous-show\"> (UTC)</span>.</li>\n",
       "\t\t\t\t\t\t\t\t<li id=\"footer-info-copyright\">Text is available under the <a href=\"//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License\" rel=\"license\">Creative Commons Attribution-ShareAlike License</a><a href=\"//creativecommons.org/licenses/by-sa/3.0/\" rel=\"license\" style=\"display:none;\"></a>;\n",
       "additional terms may apply.  By using this site, you agree to the <a href=\"//wikimediafoundation.org/wiki/Terms_of_Use\">Terms of Use</a> and <a href=\"//wikimediafoundation.org/wiki/Privacy_policy\">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a href=\"//www.wikimediafoundation.org/\">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>\n",
       "\t\t\t\t\t\t\t</ul>\n",
       "\t\t\t\t\t\t<ul id=\"footer-places\">\n",
       "\t\t\t\t\t\t\t\t<li id=\"footer-places-privacy\"><a class=\"extiw\" href=\"https://foundation.wikimedia.org/wiki/Privacy_policy\" title=\"wmf:Privacy policy\">Privacy policy</a></li>\n",
       "\t\t\t\t\t\t\t\t<li id=\"footer-places-about\"><a href=\"/wiki/Wikipedia:About\" title=\"Wikipedia:About\">About Wikipedia</a></li>\n",
       "\t\t\t\t\t\t\t\t<li id=\"footer-places-disclaimer\"><a href=\"/wiki/Wikipedia:General_disclaimer\" title=\"Wikipedia:General disclaimer\">Disclaimers</a></li>\n",
       "\t\t\t\t\t\t\t\t<li id=\"footer-places-contact\"><a href=\"//en.wikipedia.org/wiki/Wikipedia:Contact_us\">Contact Wikipedia</a></li>\n",
       "\t\t\t\t\t\t\t\t<li id=\"footer-places-developers\"><a href=\"https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute\">Developers</a></li>\n",
       "\t\t\t\t\t\t\t\t<li id=\"footer-places-cookiestatement\"><a href=\"https://foundation.wikimedia.org/wiki/Cookie_statement\">Cookie statement</a></li>\n",
       "\t\t\t\t\t\t\t\t<li id=\"footer-places-mobileview\"><a class=\"noprint stopMobileRedirectToggle\" href=\"//en.m.wikipedia.org/w/index.php?title=Robots_exclusion_standard&amp;mobileaction=toggle_view_mobile\">Mobile view</a></li>\n",
       "\t\t\t\t\t\t\t</ul>\n",
       "\t\t\t\t\t\t\t\t\t\t<ul class=\"noprint\" id=\"footer-icons\">\n",
       "\t\t\t\t\t\t\t\t\t\t<li id=\"footer-copyrightico\">\n",
       "\t\t\t\t\t\t<a href=\"https://wikimediafoundation.org/\"><img alt=\"Wikimedia Foundation\" height=\"31\" src=\"/static/images/wikimedia-button.png\" srcset=\"/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x\" width=\"88\"/></a>\t\t\t\t\t</li>\n",
       "\t\t\t\t\t\t\t\t\t\t<li id=\"footer-poweredbyico\">\n",
       "\t\t\t\t\t\t<a href=\"//www.mediawiki.org/\"><img alt=\"Powered by MediaWiki\" height=\"31\" src=\"/static/images/poweredby_mediawiki_88x31.png\" srcset=\"/static/images/poweredby_mediawiki_132x47.png 1.5x, /static/images/poweredby_mediawiki_176x62.png 2x\" width=\"88\"/></a>\t\t\t\t\t</li>\n",
       "\t\t\t\t\t\t\t\t\t</ul>\n",
       "\t\t\t\t\t\t<div style=\"clear: both;\"></div>\n",
       "\t\t</div>\n",
       "\t\t\n",
       "<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({\"wgPageParseReport\":{\"limitreport\":{\"cputime\":\"0.384\",\"walltime\":\"0.689\",\"ppvisitednodes\":{\"value\":1638,\"limit\":1000000},\"ppgeneratednodes\":{\"value\":0,\"limit\":1500000},\"postexpandincludesize\":{\"value\":50199,\"limit\":2097152},\"templateargumentsize\":{\"value\":1273,\"limit\":2097152},\"expansiondepth\":{\"value\":11,\"limit\":40},\"expensivefunctioncount\":{\"value\":1,\"limit\":500},\"unstrip-depth\":{\"value\":0,\"limit\":20},\"unstrip-size\":{\"value\":37571,\"limit\":5000000},\"entityaccesscount\":{\"value\":1,\"limit\":400},\"timingprofile\":[\"100.00%  612.397      1 -total\",\" 31.99%  195.892      1 Template:Reflist\",\" 24.04%  147.211     30 Template:Cite_web\",\"  7.67%   46.992      1 Template:Citation_needed\",\"  6.65%   40.717      1 Template:Fix\",\"  4.48%   27.446      2 Template:Category_handler\",\"  4.48%   27.408      1 Template:Official_website\",\"  4.10%   25.084      1 Template:Selfref\",\"  3.73%   22.818      1 Template:Hatnote\",\"  2.74%   16.780      1 Template:Authority_control\"]},\"scribunto\":{\"limitreport-timeusage\":{\"value\":\"0.183\",\"limit\":\"10.000\"},\"limitreport-memusage\":{\"value\":4697171,\"limit\":52428800}},\"cachereport\":{\"origin\":\"mw1324\",\"timestamp\":\"20180812161330\",\"ttl\":1900800,\"transientcontent\":false}}});mw.config.set({\"wgBackendResponseTime\":798,\"wgHostname\":\"mw1324\"});});</script>\n",
       "\t\n",
       "\n",
       "</body></html>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw2(\"https://en.wikipedia.org/wiki/Robots_exclusion_standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw3(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    req_for_robot = requests.get(url)\n",
    "    req_for_robot_html = req_for_robot.text\n",
    "    req_for_robot_html = BeautifulSoup(req_for_robot_html, \"html5lib\")\n",
    "    req_for_robot = req_for_robot_html.findAll('p')\n",
    "    output_text = []\n",
    "    for text in req_for_robot:\n",
    "        text = text.text.strip()\n",
    "        if len(text)>0:\n",
    "            output_text.append(text)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Here you will find data, tools, and resources to conduct research, develop web and mobile applications, design data visualizations, and more.',\n",
       " 'The U.S. Coast Guard (USCG)\\xa0is responsible for investigating reportable marine casualties, accidents, and serious marine incidents.\\xa0 The relevant mission statement and\\xa0specific\\xa0regulations\\xa0can be found on the USCG Investigations Division homepage.\\xa0 After an incident has been reported, it is entered into a national database of all marine casualty and pollution incidents.\\xa0 These important historical records can then\\xa0be accessed by researchers interested in understanding\\xa0maritime safety, accident prevention, or trends in certain types of maritime incidents through time.\\xa0 Other agencies interested in maritime transportation performance measures rely on the USCG\\xa0data to examine incident trends on U.S. waterways.\\xa0 Files for the Marine Casualty and Pollution Data for Researchers datasets can be downloaded directly from the U.S. Coast Guard Homeport website by following the drop-down menu options on the homepage\\xa0Missions: Investigations: Marine Casualty Pollution Investigations page at https://homeport.uscg.mil/missions/investigations/marine-casualty-pollution-investigations.',\n",
       " 'As described by the USCG,\\xa0“the Marine Casualty and Pollution Data files provide details about marine casualty and pollution incidents investigated by Coast Guard Offices throughout the United States. The database can be used to analyze marine accidents and pollution incidents by a variety of factors including vessel or facility type, injuries, fatalities, pollutant details, location, and date.\\xa0 The data collection period began in 1982 for marine casualties and 1973 for polluting incidents, and is ongoing. Documentation includes entity and attribute descriptions along with suggested solutions to general marine pollution, vessel casualty, and personnel injury and death questions.”',\n",
       " 'Visitors to the USCG Homeport data download site should note that there are three files available fore download, but it is the\\xa0second file on the list (named MISLE_DATA.zip) that contains all available marine casualty data from January 2002 – July 2015.\\xa0 The files extracted from MISLE_DATA.zip\\xa0can be opened with most standard spreadsheet editing software programs.',\n",
       " 'Source: USCG Marine Casualty and Pollution Data, https://homeport.uscg.mil/missions/investigations/marine-casualty-pollution-investigations',\n",
       " 'Data.Gov Links Related to this topic:',\n",
       " 'USCG Marine Safety Information Data, https://catalog.data.gov/dataset/marine-safety-information-data',\n",
       " 'USCG Facility Pollution Database, https://catalog.data.gov/dataset/uscg-facility-pollution',\n",
       " 'In recognition of the important role birds play in natural ecosystems and in our culture, we join World Migratory Bird Day (second Saturday in May for U.S. and Canada – May 12, 2018) and the Year of the Bird (2018) in bringing attention to birds and their conservation. … Continued',\n",
       " 'During National Invasive Species Awareness Week (February 26 – March 2, 2018), we highlight the importance of increasing awareness about the threat invasive species pose to loss of biodiversity and ecosystem function. Invasive species are non-native plants, animals and pathogens whose introductions cause or are … Continued',\n",
       " 'The North Atlantic ocean is a busy place, full of sea life, ships, and – fortunately – a slew of data.\\xa0 Anyone interested in local, state, or regional marine planning efforts in New England\\xa0can visit the Northeast Ocean Data portal  (http://www.northeastoceandata.org/), which provides ocean-related … Continued',\n",
       " '@alexford @GPHemsley please contact https://t.co/NGVoOGIMWp @ https://t.co/1G3CxGazD7\\n#OpenData',\n",
       " 'Calling all data lovers! The public comment period for the Federal Data Strategy has been extended.',\n",
       " 'Comment on dra… https://t.co/yHStLiwENw',\n",
       " 'The U.S. Open Data Toolkit helps federal data providers and data users better understand and harness the strategic… https://t.co/L2N6axSmUw']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw3(\"https://www.data.gov/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Write a Python program to convert an address (like \"1600 Amphitheatre Parkway, Mountain View, CA\") into geographic coordinates (like latitude 37.423021 and longitude -122.083739)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw4(address):\n",
    "    import requests\n",
    "    url = 'https://maps.googleapis.com/maps/api/geocode/json'\n",
    "    params = {'sensor': 'false', 'address': address}\n",
    "    r = requests.get(url, params=params)\n",
    "    results = r.json()['results']\n",
    "    location = results[0]['geometry']['location']\n",
    "    return location['lat'], location['lng']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37.4231972, -122.0840662)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw4('1600 Amphitheatre Parkway, Mountain View, CA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Write a Python program to display the name of the most recently added dataset on data.gov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw5(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    req_for_robot = requests.get(url)\n",
    "    req_for_robot_html = req_for_robot.text\n",
    "    req_for_robot_html = BeautifulSoup(req_for_robot_html, \"html5lib\")\n",
    "    req_for_robot = req_for_robot_html.findAll('h2')\n",
    "    output_text = []\n",
    "    for text in req_for_robot:\n",
    "        text = text.text.strip()\n",
    "        if len(text)>0:\n",
    "            output_text.append(text)\n",
    "    return output_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bird Data & Information for Research, Management and Conservation of Birds'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw5(\"https://www.data.gov/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Write a Python program to extract h1 tag from example.com. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw6(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    req_for_robot = requests.get(url)\n",
    "    req_for_robot_html = req_for_robot.text\n",
    "    req_for_robot_html = BeautifulSoup(req_for_robot_html, \"html5lib\")\n",
    "    req_for_robot = req_for_robot_html.findAll('h1')\n",
    "    output_text = []\n",
    "    for text in req_for_robot:\n",
    "        text = text.text.strip()\n",
    "        if len(text)>0:\n",
    "            output_text.append(text)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Example Domain']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw6(\"http://www.example.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Write a Python program to extract and display all the header tags from en.wikipedia.org/wiki/Main_Page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw7(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    req_for_robot = requests.get(url)\n",
    "    req_for_robot_html = req_for_robot.text\n",
    "    req_for_robot_html = BeautifulSoup(req_for_robot_html, \"html5lib\")\n",
    "    all_headers=[]\n",
    "    req_for_h1 = req_for_robot_html.findAll('h1')\n",
    "    all_headers.append(req_for_h1)\n",
    "    req_for_h2 = req_for_robot_html.findAll('h2')\n",
    "    all_headers.append(req_for_h2)\n",
    "    req_for_h3 = req_for_robot_html.findAll('h3')\n",
    "    all_headers.append(req_for_h3)\n",
    "    output_text =[]\n",
    "    for header in all_headers:\n",
    "        for text in header:\n",
    "            text = text.text.strip()\n",
    "            if len(text)>0:\n",
    "                output_text.append(text)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Main Page',\n",
       " \"From today's featured article\",\n",
       " 'Did you know...',\n",
       " 'In the news',\n",
       " 'On this day',\n",
       " \"Today's featured picture\",\n",
       " 'Other areas of Wikipedia',\n",
       " \"Wikipedia's sister projects\",\n",
       " 'Wikipedia languages',\n",
       " 'Navigation menu',\n",
       " 'Personal tools',\n",
       " 'Namespaces',\n",
       " 'Variants',\n",
       " 'Views',\n",
       " 'More',\n",
       " 'Search',\n",
       " 'Navigation',\n",
       " 'Interaction',\n",
       " 'Tools',\n",
       " 'Print/export',\n",
       " 'In other projects',\n",
       " 'Languages']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw7(\"https://en.wikipedia.org/wiki/Main_Page\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Write a Python program to extract and display all the image links from en.wikipedia.org/wiki/Peter_Jeffrey_(RAAF_officer). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw8(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    requests = requests.get(url)\n",
    "    requests = requests.text\n",
    "    requests = BeautifulSoup(requests, \"html5lib\")\n",
    "    all_photos = []\n",
    "    requests = requests.findAll('img', {'src':re.compile('.jpg')})\n",
    "    for img in requests:\n",
    "        print(img['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//upload.wikimedia.org/wikipedia/commons/thumb/a/af/NlaJeffrey1942-43.jpg/220px-NlaJeffrey1942-43.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/c/c5/008315JeffreyTurnbull1941.jpg/260px-008315JeffreyTurnbull1941.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/e/ea/021807CameronJeffrey1941.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/9/92/AC0072JeffreyTruscottKittyhawks1942.jpg/280px-AC0072JeffreyTruscottKittyhawks1942.jpg\n",
      "//upload.wikimedia.org/wikipedia/commons/thumb/2/26/VIC1689Jeffrey1945.jpg/280px-VIC1689Jeffrey1945.jpg\n"
     ]
    }
   ],
   "source": [
    "cw8(\"https://en.wikipedia.org/wiki/Peter_Jeffrey_(RAAF_officer)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Write a Python program to get 90 days of visits broken down by browser for all sites on data.gov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw9(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    requests = requests.get(url)\n",
    "    return requests.json()['totals']['browser']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Chrome': 1148610875,\n",
       " 'Safari': 738908766,\n",
       " 'Internet Explorer': 301919802,\n",
       " 'Firefox': 125578246,\n",
       " 'Edge': 105576673,\n",
       " 'Samsung Internet': 57708769,\n",
       " 'Android Webview': 23389080,\n",
       " 'Safari (in-app)': 23667995,\n",
       " 'Amazon Silk': 7771905,\n",
       " 'Opera': 7150144,\n",
       " 'Opera Mini': 3457759,\n",
       " 'UC Browser': 1836127,\n",
       " 'Android Browser': 1281735,\n",
       " 'YaBrowser': 501858,\n",
       " 'Mozilla Compatible Agent': 477759,\n",
       " 'Puffin': 290383,\n",
       " 'BlackBerry': 240945,\n",
       " 'Coc Coc': 205814,\n",
       " 'SeaMonkey': 191175,\n",
       " 'Maxthon': 143790,\n",
       " 'Mozilla': 150444,\n",
       " 'UCWEB': 47612,\n",
       " 'Amazon.com': 54235,\n",
       " 'MRCHROME': 16587,\n",
       " 'Nintendo Browser': 25148,\n",
       " 'Nokia Browser': 13904,\n",
       " 'HRB-MOBILE-IOS-PHONE-MYBLOCK-TOUCHID-6.2.0-Mozilla': 1840,\n",
       " 'HubSpot inbound link reporting check': 5213,\n",
       " 'BestBuy': 20086,\n",
       " 'Playstation 3': 12558,\n",
       " 'Iron': 16855,\n",
       " 'ThousandEyes': 29892,\n",
       " 'osee2unifiedRelease': 7834,\n",
       " 'ios-app': 12782,\n",
       " 'Playstation Vita Browser': 7649,\n",
       " 'Carousel': 19408,\n",
       " 'NetFront': 4083,\n",
       " 'Netscape': 4103,\n",
       " 'Mercari_d': 4528,\n",
       " 'Google-Test2': 6589,\n",
       " 'Nintendo 3DS Browser': 3651,\n",
       " 'iPhone': 2348,\n",
       " 'Android Runtime': 2988,\n",
       " 'HRB-MOBILE-IOS-PHONE-MYBLOCK-FACEID-6.2.0-Mozilla': 213,\n",
       " 'Sephora 18.3.2': 286,\n",
       " 'HRB-MOBILE-IOS-PHONE-MYBLOCK-6.2.0-Mozilla': 264,\n",
       " 'DDG-Android-3.1.1': 2140,\n",
       " 'Seznam': 3886,\n",
       " '+Simple Browser': 2007,\n",
       " 'Uzbl': 7670,\n",
       " 'IE with Chrome Frame': 4084,\n",
       " 'Outlook-iOS': 2035,\n",
       " 'YE': 2486,\n",
       " 'Lunascape': 1630,\n",
       " '(not set)': 16163,\n",
       " 'HRB-MOBILE-IOS-PHONE-TAXES-TOUCHID-7.7.1-Mozilla': 506,\n",
       " 'AdobeAIR': 4935,\n",
       " 'DDG-Android-3.1.0': 907,\n",
       " 'Safari Mozilla': 2086,\n",
       " 'BrowserNG': 1109,\n",
       " 'com.seekingalpha.webwrapper': 1661,\n",
       " 'Bluebeam Revu Browser - cef version: 57.0.0.0': 1294,\n",
       " 'LG-B470': 795,\n",
       " 'LiveSlides': 678,\n",
       " 'Snowball iPhone 2.2.0': 25,\n",
       " 'liip': 182,\n",
       " 'Mobile IOS 8.5.1.1; Mozilla': 197,\n",
       " 'HRB-MOBILE-IOS-PHONE-MYBLOCK-TOUCHID-6.3.0-Mozilla': 548,\n",
       " 'Automation_Chrome_54.0.2840.59': 44,\n",
       " 'One Drop Web Agent': 35,\n",
       " 'Camino': 201,\n",
       " 'HRB-MOBILE-IOS-PHONE-MYBLOCK-6.3.0-Mozilla': 95,\n",
       " 'HRB-MOBILE-IOS-PHONE-MYBLOCK-FACEID-6.3.0-Mozilla': 92,\n",
       " 'Grailed': 718,\n",
       " 'Ratatata': 50,\n",
       " 'Emb': 929,\n",
       " 'Optional': 207,\n",
       " 'Nichrome': 90,\n",
       " 'pa11y': 759,\n",
       " 'RTLNieuws': 95,\n",
       " 'HRB-MOBILE-IOS-PHONE-MYBLOCK-TOUCHID-6.4.0-Mozilla': 5736,\n",
       " 'HRB-MOBILE-IOS-PHONE-TAXES-7.7.1-Mozilla': 11,\n",
       " 'HRB-MOBILE-IOS-PHONE-MYBLOCK-6.4.0-Mozilla': 1080,\n",
       " 'HRB-MOBILE-IOS-PHONE-MYBLOCK-FACEID-6.4.0-Mozilla': 841,\n",
       " 'ScooperBot': 357,\n",
       " 'Android': 120,\n",
       " 'something': 13,\n",
       " 'FAZDERTAG FAZNETAPPS': 68,\n",
       " 'HackeroneBot 1.0': 346,\n",
       " 'Browser': 57,\n",
       " 'Airbnb': 50,\n",
       " 'Snowball iPhone 2.3.1': 119,\n",
       " 'Mobile IOS 8.5.0.2; Mozilla': 12,\n",
       " '\"Mozilla': 1339,\n",
       " 'Konqueror': 65,\n",
       " 'Sephora 18.4.1': 1336,\n",
       " 'Android ExpediaBookings': 85,\n",
       " 'InteriaFakty': 109,\n",
       " 'OPS_WATCHER': 4392,\n",
       " 'stash-invest-android': 262,\n",
       " 'Caremark iPhone': 119,\n",
       " 'Empty': 60,\n",
       " 'Snowball': 13,\n",
       " 'S40 Ovi Browser': 13,\n",
       " 'RpZd': 16,\n",
       " 'rauS': 16,\n",
       " 'vaxi': 16,\n",
       " '27qF': 15,\n",
       " 'A9CX': 15,\n",
       " 'Gsdg': 15,\n",
       " 'aKga': 15,\n",
       " 'iGdt': 15,\n",
       " 'kLfh': 15,\n",
       " 's2S4': 15,\n",
       " 'vEKQ': 15,\n",
       " 'zEds': 15,\n",
       " 'FqHC': 14,\n",
       " 'Y44w': 14,\n",
       " 'FHLx': 13,\n",
       " 'aPNw': 13,\n",
       " 'rZtr': 13,\n",
       " 'AnXM': 12,\n",
       " 'Snowball iPhone 2.4.1': 47,\n",
       " 'mcpm': 12,\n",
       " 'qd26': 12,\n",
       " 'KDZs': 13,\n",
       " 'bEYM': 13,\n",
       " '9tSG': 11,\n",
       " 'CBC': 175,\n",
       " 'DirectorInsight Autosourcing www.directorinsight.com': 819,\n",
       " 'whater_useragent': 11,\n",
       " 'iGotcha': 24,\n",
       " 'android.webview': 12,\n",
       " 'Snowball iPhone 2.5.0': 44,\n",
       " 'DDG-Android-3.0.14': 111,\n",
       " 'User-Agent:Mozilla': 267,\n",
       " 'iCab': 17,\n",
       " 'CareDroidMedications': 194,\n",
       " 'Web Science and Digital Libraries Group': 5800,\n",
       " 'LeapPadPlatinum': 17858,\n",
       " 'LeapPad3Explorer': 2617,\n",
       " 'LeapPadUltimate': 17969,\n",
       " 'UP.Browser': 157,\n",
       " 'DoCoMo': 101,\n",
       " 'BlackBerry8330': 67,\n",
       " 'BlackBerry8320': 66,\n",
       " 'Cricket-A200': 67,\n",
       " 'YelpWebView': 28,\n",
       " 'Vodafone': 72,\n",
       " 'AU-MIC': 34,\n",
       " 'BenQ-CF61': 34,\n",
       " 'BlackBerry7100i': 36,\n",
       " 'BlackBerry7250': 34,\n",
       " 'BlackBerry8110': 34,\n",
       " 'BlackBerry8130': 34,\n",
       " 'BlackBerry8310': 33,\n",
       " 'BlackBerry8703e': 34,\n",
       " 'BlackBerry8820': 34,\n",
       " 'BlackBerry8830': 34,\n",
       " 'BlackBerry9000': 34,\n",
       " 'BlackBerry9630': 35,\n",
       " 'BlackBerry9650': 34,\n",
       " 'BlackBerry9700': 45,\n",
       " 'Cricket-A310': 34,\n",
       " 'Cricket-A410': 34,\n",
       " 'HTC_HD2_T8585': 17,\n",
       " 'HTC_Touch_HD_T8282': 17,\n",
       " 'J-PHONE': 33,\n",
       " 'MAUI': 17,\n",
       " 'OPENWAVE': 17,\n",
       " 'OPWV-SDK': 17,\n",
       " 'PDXGW': 33,\n",
       " 'ReqwirelessWeb': 34,\n",
       " 'SEC-SGH600': 34,\n",
       " 'SEC-SGHD410': 34,\n",
       " 'SIE-ME45': 33,\n",
       " 'SIE-S55': 34,\n",
       " 'SIE-S65': 34,\n",
       " 'SonyEricssonP1i': 17,\n",
       " 'SonyEricssonT200': 34,\n",
       " 'UPG1': 17,\n",
       " 'Xiino': 34,\n",
       " 'iTunes': 34,\n",
       " 'Astel': 33,\n",
       " 'BlackBerry7130e': 33,\n",
       " 'SEC-SGHE900': 16,\n",
       " 'WM5': 16,\n",
       " 'NokiaE52-1': 11,\n",
       " 'Blazer': 152,\n",
       " 'Nokia7610': 68,\n",
       " 'Nokia2700c-2': 51,\n",
       " 'WebPro': 67,\n",
       " 'Dolfin': 34,\n",
       " 'LGE-LG290C': 68,\n",
       " 'Links': 34,\n",
       " 'MobileExplorer': 34,\n",
       " 'Nokia3120Classic': 34,\n",
       " 'Nokia3200': 34,\n",
       " 'Nokia3510i': 34,\n",
       " 'Nokia3650': 34,\n",
       " 'Nokia5130c-2': 34,\n",
       " 'Nokia5140': 34,\n",
       " 'Nokia6230': 34,\n",
       " 'Nokia6600': 34,\n",
       " 'Nokia6630': 34,\n",
       " 'Nokia6680': 34,\n",
       " 'Nokia6800': 34,\n",
       " 'Nokia7250': 34,\n",
       " 'Nokia7250I': 34,\n",
       " 'Nokia8310': 34,\n",
       " 'NokiaN-Gage': 34,\n",
       " 'NokiaN80-3': 34,\n",
       " 'NokiaN90-1': 34,\n",
       " 'NokiaX3-02': 34,\n",
       " 'Profile': 34,\n",
       " 'Nokia2760': 33,\n",
       " 'NokiaN70-1': 33,\n",
       " 'SAGEM-myX5-2': 33,\n",
       " 'Palm680': 32,\n",
       " 'HTC-P4600': 34,\n",
       " 'HTC-ST7377': 17,\n",
       " 'HTC_Dream': 17,\n",
       " 'HTC_Smart_F3188': 17,\n",
       " 'HTC_Smart_F3188 Mozilla': 17,\n",
       " 'HTC_Touch_Pro_T7272': 17,\n",
       " 'LG': 33,\n",
       " 'LG-CT810': 34,\n",
       " 'LG-GS290': 33,\n",
       " 'LG-GT400': 33,\n",
       " 'LG-LG260': 17,\n",
       " 'LG-LX550': 17,\n",
       " 'LGE-MX380': 34,\n",
       " 'LGE-VM510': 17,\n",
       " 'MOT': 17,\n",
       " 'MOT-A-1C': 34,\n",
       " 'MOT-COOL0': 34,\n",
       " 'MOT-E398': 34,\n",
       " 'MOT-EX431G': 34,\n",
       " 'MOT-V3i': 34,\n",
       " 'MOT-V3r': 34,\n",
       " 'MOT-V600': 34,\n",
       " 'MOT-V620': 34,\n",
       " 'MOT-V9mm': 34,\n",
       " 'Modzilla': 34,\n",
       " 'Nokia6212 classic': 17,\n",
       " 'Nokia6300': 17,\n",
       " 'NokiaC3-00': 17,\n",
       " 'POLARIS': 34,\n",
       " 'PalmCentro': 17,\n",
       " 'PalmSource': 17,\n",
       " 'PantechP7040': 17,\n",
       " 'SAMSUNG-GT-S3653W': 17,\n",
       " 'SAMSUNG-S8003': 17,\n",
       " 'SAMSUNG-SGH-i900': 17,\n",
       " 'SCH-U350': 17,\n",
       " 'XV6850': 17,\n",
       " 'htc_touch_pro2_t7373': 17,\n",
       " 'mot-V3': 34,\n",
       " 'nook': 17,\n",
       " 'nook browser': 17,\n",
       " 'sam-r380 UP.Browser': 17,\n",
       " 'samr810 Netfront': 17,\n",
       " 'samsung-gt-s5620': 17,\n",
       " 'MOT-L6': 33,\n",
       " 'Nokia6212': 16,\n",
       " 'Opera 6.0[en]Nokia': 16,\n",
       " 'sam-r350 UP.Browser': 16,\n",
       " 'EudoraWeb': 34,\n",
       " 'SAMSUNG-SGH-D900': 34,\n",
       " 'mwb-db-client Opera': 34,\n",
       " 'sonyericssonk800i': 34,\n",
       " 'Roku': 33,\n",
       " 'ActiveVideo H5 HbbTV': 17,\n",
       " 'Apple TV': 17,\n",
       " 'HTC_HD2_T8585 Opera': 17,\n",
       " 'HTC_Touch_HD_T8282 Mozilla': 17,\n",
       " 'HTC_Touch_Pro_T7272 Opera': 17,\n",
       " 'LG-BDP Linux': 17,\n",
       " 'LG-LG260 POLARIS-LG260': 17,\n",
       " 'LG-LX550 AU-MIC-LX550': 17,\n",
       " 'LGE-VM510 NetFront': 17,\n",
       " 'MOT 24.1 _': 17,\n",
       " 'OPENWAVE UNTRUSTED': 17,\n",
       " 'OPWV-SDK UP.Browser': 17,\n",
       " 'Playstation Portable': 17,\n",
       " 'Presto': 17,\n",
       " 'SCH-A950+UP.Browser': 17,\n",
       " 'SEC-SGHE600 UP.Link': 17,\n",
       " 'SHARP-TQ-GX10i': 17,\n",
       " 'Samsung-SPHM800 AU-MIC-M800': 17,\n",
       " 'SonyEricssonK700i': 17,\n",
       " 'SonyEricssonT280i': 17,\n",
       " 'TELECA-': 17,\n",
       " 'WM5 PIE': 17,\n",
       " 'htc_touch_pro2_t7373 opera': 17,\n",
       " 'iTunes-AppleTV': 17,\n",
       " 'samsung sgh-e900': 17,\n",
       " '\"Opera': 16,\n",
       " 'MAUI WAP Browser': 16,\n",
       " 'NOKIAN95': 16,\n",
       " 'SonyEricssonK608i': 16,\n",
       " 'XV6850 Opera': 16,\n",
       " 'QZONEJSSDK': 31,\n",
       " 'Snowball iPhone 2.6.0': 36,\n",
       " 'MagentaNews': 14978,\n",
       " '--ignore-ssl-errors=true': 29,\n",
       " 'NIH': 23,\n",
       " 'AncestryAndroid': 11,\n",
       " 'NNLM': 62,\n",
       " 'NokiaC7-00': 11,\n",
       " 'SalesforceMobileSDK': 22,\n",
       " 'HRB-MOBILE-IOS-PHONE-MYBLOCK-TOUCHID-6.6.0-Mozilla': 1368,\n",
       " 'Windowshop': 20,\n",
       " 'Sephora 18.5': 927,\n",
       " 'chrome-Selenium': 21,\n",
       " 'HRB-MOBILE-IOS-PHONE-MYBLOCK-FACEID-6.6.0-Mozilla': 98,\n",
       " 'HRB-MOBILE-IOS-PHONE-MYBLOCK-6.6.0-Mozilla': 260,\n",
       " 'Digg': 175,\n",
       " 'StatusCake_Pagespeed_Indev': 4066,\n",
       " 'Snowball iPhone 2.7.0': 48,\n",
       " 'LeapPadUltra': 11,\n",
       " 'iPad': 127,\n",
       " 'Snowball iPhone 2.8.0': 130,\n",
       " 'SureFox': 11,\n",
       " 'None': 697,\n",
       " 'MSIE 11.0': 11,\n",
       " 'ELinks': 29,\n",
       " 'CoolNovo': 12,\n",
       " 'Papers': 26,\n",
       " 'HRB-MOBILE-IOS-PHONE-MYBLOCK-TOUCHID-6.8.0-Mozilla': 97,\n",
       " 'Snowball iPhone 2.9.0': 24}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw9(\"https://analytics.usa.gov/data/live/browsers.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Write a Python program to that retrieves an arbitary Wikipedia page of \"Python\" and creates a list of links on that page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw10(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    requests = requests.get(url)\n",
    "    requests = requests.text\n",
    "    requests = BeautifulSoup(requests, \"html5lib\")\n",
    "    requests = requests.findAll('a')\n",
    "    for request in requests:\n",
    "        if 'href' in request.attrs:\n",
    "            print(request.attrs['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#mw-head\n",
      "#p-search\n",
      "/wiki/Wikipedia\n",
      "/wiki/Free_content\n",
      "/wiki/Encyclopedia\n",
      "/wiki/Wikipedia:Introduction\n",
      "/wiki/Special:Statistics\n",
      "/wiki/English_language\n",
      "/wiki/Portal:Arts\n",
      "/wiki/Portal:Biography\n",
      "/wiki/Portal:Geography\n",
      "/wiki/Portal:History\n",
      "/wiki/Portal:Mathematics\n",
      "/wiki/Portal:Science\n",
      "/wiki/Portal:Society\n",
      "/wiki/Portal:Technology\n",
      "/wiki/Portal:Contents/Portals\n",
      "/wiki/File:Bret_08-22-1999_1431Z.png\n",
      "/wiki/Hurricane_Bret\n",
      "/wiki/1999_Atlantic_hurricane_season\n",
      "/wiki/Tropical_cyclone\n",
      "/wiki/Hurricane_Jerry\n",
      "/wiki/Tropical_wave\n",
      "/wiki/Rapid_intensification\n",
      "/wiki/Barometric_pressure\n",
      "/wiki/Landfall\n",
      "/wiki/Padre_Island\n",
      "/wiki/Hurricane_Bret\n",
      "/wiki/Golden_jackal\n",
      "/wiki/Evita_(1996_film)\n",
      "/wiki/Stephen_I_of_Hungary\n",
      "/wiki/Wikipedia:Today%27s_featured_article/August_2018\n",
      "https://lists.wikimedia.org/mailman/listinfo/daily-article-l\n",
      "/wiki/Wikipedia:Featured_articles\n",
      "/wiki/File:Snuffbox_MET_DP168997_(cropped).jpg\n",
      "/wiki/Capodimonte_porcelain\n",
      "/wiki/Vicars_Bell\n",
      "/wiki/Little_Gaddesden\n",
      "/wiki/Stanwood,_Washington\n",
      "/wiki/Sewage_treatment\n",
      "/wiki/Mindy_Alper\n",
      "/wiki/Heaven_Is_a_Traffic_Jam_on_the_405\n",
      "/wiki/Mary_Stuart_Masterson\n",
      "/wiki/Benny_%26_Joon\n",
      "/wiki/Leucadendron_salignum\n",
      "/wiki/Jenny_Sabin\n",
      "/wiki/Roguelike\n",
      "/wiki/Wizard_of_Legend\n",
      "/wiki/Kickstarter\n",
      "/wiki/Hurricane_Aircat\n",
      "/wiki/Viet_Cong\n",
      "/wiki/Wikipedia:Recent_additions\n",
      "/wiki/Wikipedia:Your_first_article\n",
      "/wiki/Template_talk:Did_you_know\n",
      "/wiki/File:Aretha_Franklin_on_January_20,_2009.jpg\n",
      "/wiki/Soul_(music)\n",
      "/wiki/Aretha_Franklin\n",
      "/wiki/Taliban\n",
      "/wiki/Ghazni_offensive\n",
      "/wiki/Ghazni\n",
      "/wiki/Ponte_Morandi\n",
      "/wiki/Genoa\n",
      "/wiki/NASA\n",
      "/wiki/Parker_Solar_Probe\n",
      "/wiki/Corona\n",
      "/wiki/2018_Kerala_floods\n",
      "/wiki/Kerala\n",
      "/wiki/Deaths_in_2018\n",
      "/wiki/Atal_Bihari_Vajpayee\n",
      "/wiki/Yelena_Shushunova\n",
      "/wiki/John_Shipley_Rowlinson\n",
      "/wiki/V._S._Naipaul\n",
      "/wiki/Portal:Current_events\n",
      "/wiki/Wikipedia:In_the_news/Candidates\n",
      "/wiki/August_18\n",
      "/wiki/File:Margot_001.jpg\n",
      "/wiki/1572\n",
      "/wiki/French_Wars_of_Religion\n",
      "/wiki/Margaret_of_Valois\n",
      "/wiki/Huguenot\n",
      "/wiki/Henry_IV_of_France\n",
      "/wiki/1868\n",
      "/wiki/Pierre_Janssen\n",
      "/wiki/Helium\n",
      "/wiki/Chromosphere\n",
      "/wiki/Solar_eclipse_of_August_18,_1868\n",
      "/wiki/Guntur\n",
      "/wiki/1920\n",
      "/wiki/Nineteenth_Amendment_to_the_United_States_Constitution\n",
      "/wiki/United_States_Constitution\n",
      "/wiki/Women%27s_suffrage_in_the_United_States\n",
      "/wiki/1948\n",
      "/wiki/Fifth_Test,_1948_Ashes_series\n",
      "/wiki/Test_cricket\n",
      "/wiki/Australian_cricket_team_in_England_in_1948\n",
      "/wiki/2008\n",
      "/wiki/President_of_Pakistan\n",
      "/wiki/Pervez_Musharraf\n",
      "/wiki/Movement_to_impeach_Pervez_Musharraf\n",
      "/wiki/Knut_Alvsson\n",
      "/wiki/Baji_Rao_I\n",
      "/wiki/Ruth_Norman\n",
      "/wiki/August_17\n",
      "/wiki/August_18\n",
      "/wiki/August_19\n",
      "/wiki/Wikipedia:Selected_anniversaries/August\n",
      "https://lists.wikimedia.org/mailman/listinfo/daily-article-l\n",
      "/wiki/List_of_historical_anniversaries\n",
      "/wiki/File:5000_rupiah_bill,_2001_series_(2009_date),_processed,_obverse%2Breverse.jpg\n",
      "/wiki/Indonesian_rupiah\n",
      "/wiki/Indonesian_National_Revolution\n",
      "/wiki/Netherlands_Indies_gulden\n",
      "/wiki/Japanese_occupation_of_the_Dutch_East_Indies\n",
      "/wiki/World_War_II\n",
      "/wiki/History_of_the_Indonesian_rupiah\n",
      "//en.wikipedia.org/w/index.php?title=Main_Page&action=edit\n",
      "/wiki/Bank_Indonesia\n",
      "/wiki/United_States_dollar\n",
      "/wiki/Tuanku_Imam_Bonjol\n",
      "/wiki/National_Hero_of_Indonesia\n",
      "/wiki/West_Sumatra\n",
      "/wiki/Template:POTD/2018-08-18/1\n",
      "/wiki/Template:POTD/2018-08-18/2\n",
      "/wiki/Template:POTD/2018-08-18/4\n",
      "/wiki/Template:POTD/2018-08-18/5\n",
      "/wiki/Template:POTD/2018-08-18/6\n",
      "/wiki/Template:POTD/2018-08-18/7\n",
      "/wiki/Bank_Indonesia\n",
      "/wiki/Template:POTD/2018-08-17\n",
      "/wiki/Template:POTD/2018-08-16\n",
      "/wiki/Template:POTD/2018-08-15\n",
      "/wiki/Wikipedia:Picture_of_the_day/August_2018\n",
      "/wiki/Wikipedia:Featured_pictures\n",
      "/wiki/Wikipedia:Community_portal\n",
      "/wiki/Wikipedia:Help_desk\n",
      "/wiki/Wikipedia:Local_Embassy\n",
      "/wiki/Wikipedia:Reference_desk\n",
      "/wiki/Wikipedia:News\n",
      "/wiki/Wikipedia:Village_pump\n",
      "/wiki/Wikimedia_Foundation\n",
      "https://foundation.wikimedia.org/wiki/Our_projects\n",
      "https://commons.wikimedia.org/wiki/\n",
      "//commons.wikimedia.org/\n",
      "https://www.mediawiki.org/wiki/\n",
      "//mediawiki.org/\n",
      "https://meta.wikimedia.org/wiki/\n",
      "//meta.wikimedia.org/\n",
      "https://en.wikibooks.org/wiki/\n",
      "//en.wikibooks.org/\n",
      "https://www.wikidata.org/wiki/\n",
      "//www.wikidata.org/\n",
      "https://en.wikinews.org/wiki/\n",
      "//en.wikinews.org/\n",
      "https://en.wikiquote.org/wiki/\n",
      "//en.wikiquote.org/\n",
      "https://en.wikisource.org/wiki/\n",
      "//en.wikisource.org/\n",
      "https://species.wikimedia.org/wiki/\n",
      "//species.wikimedia.org/\n",
      "https://en.wikiversity.org/wiki/\n",
      "//en.wikiversity.org/\n",
      "https://en.wikivoyage.org/wiki/\n",
      "//en.wikivoyage.org/\n",
      "https://en.wiktionary.org/wiki/\n",
      "//en.wiktionary.org/\n",
      "/wiki/English_language\n",
      "/wiki/Special:Statistics\n",
      "https://de.wikipedia.org/wiki/\n",
      "https://es.wikipedia.org/wiki/\n",
      "https://fr.wikipedia.org/wiki/\n",
      "https://it.wikipedia.org/wiki/\n",
      "https://nl.wikipedia.org/wiki/\n",
      "https://ja.wikipedia.org/wiki/\n",
      "https://pl.wikipedia.org/wiki/\n",
      "https://pt.wikipedia.org/wiki/\n",
      "https://ru.wikipedia.org/wiki/\n",
      "https://sv.wikipedia.org/wiki/\n",
      "https://vi.wikipedia.org/wiki/\n",
      "https://zh.wikipedia.org/wiki/\n",
      "https://ar.wikipedia.org/wiki/\n",
      "https://id.wikipedia.org/wiki/\n",
      "https://ms.wikipedia.org/wiki/\n",
      "https://ca.wikipedia.org/wiki/\n",
      "https://cs.wikipedia.org/wiki/\n",
      "https://eu.wikipedia.org/wiki/\n",
      "https://fa.wikipedia.org/wiki/\n",
      "https://ko.wikipedia.org/wiki/\n",
      "https://hu.wikipedia.org/wiki/\n",
      "https://no.wikipedia.org/wiki/\n",
      "https://ro.wikipedia.org/wiki/\n",
      "https://sr.wikipedia.org/wiki/\n",
      "https://sh.wikipedia.org/wiki/\n",
      "https://fi.wikipedia.org/wiki/\n",
      "https://tr.wikipedia.org/wiki/\n",
      "https://uk.wikipedia.org/wiki/\n",
      "https://bs.wikipedia.org/wiki/\n",
      "https://bg.wikipedia.org/wiki/\n",
      "https://da.wikipedia.org/wiki/\n",
      "https://et.wikipedia.org/wiki/\n",
      "https://el.wikipedia.org/wiki/\n",
      "https://simple.wikipedia.org/wiki/\n",
      "https://eo.wikipedia.org/wiki/\n",
      "https://gl.wikipedia.org/wiki/\n",
      "https://he.wikipedia.org/wiki/\n",
      "https://hr.wikipedia.org/wiki/\n",
      "https://lv.wikipedia.org/wiki/\n",
      "https://lt.wikipedia.org/wiki/\n",
      "https://ml.wikipedia.org/wiki/\n",
      "https://nn.wikipedia.org/wiki/\n",
      "https://sk.wikipedia.org/wiki/\n",
      "https://sl.wikipedia.org/wiki/\n",
      "https://th.wikipedia.org/wiki/\n",
      "https://meta.wikimedia.org/wiki/List_of_Wikipedias\n",
      "https://en.wikipedia.org/w/index.php?title=Main_Page&oldid=847600508\n",
      "/wiki/Category:Articles_containing_potentially_dated_statements_from_August_2018\n",
      "/wiki/Category:All_articles_containing_potentially_dated_statements\n",
      "/wiki/Special:MyTalk\n",
      "/wiki/Special:MyContributions\n",
      "/w/index.php?title=Special:CreateAccount&returnto=Main+Page\n",
      "/w/index.php?title=Special:UserLogin&returnto=Main+Page\n",
      "/wiki/Main_Page\n",
      "/wiki/Talk:Main_Page\n",
      "/wiki/Main_Page\n",
      "/w/index.php?title=Main_Page&action=edit\n",
      "/w/index.php?title=Main_Page&action=history\n",
      "/wiki/Main_Page\n",
      "/wiki/Main_Page\n",
      "/wiki/Portal:Contents\n",
      "/wiki/Portal:Featured_content\n",
      "/wiki/Portal:Current_events\n",
      "/wiki/Special:Random\n",
      "https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en\n",
      "//shop.wikimedia.org\n",
      "/wiki/Help:Contents\n",
      "/wiki/Wikipedia:About\n",
      "/wiki/Wikipedia:Community_portal\n",
      "/wiki/Special:RecentChanges\n",
      "//en.wikipedia.org/wiki/Wikipedia:Contact_us\n",
      "/wiki/Special:WhatLinksHere/Main_Page\n",
      "/wiki/Special:RecentChangesLinked/Main_Page\n",
      "/wiki/Wikipedia:File_Upload_Wizard\n",
      "/wiki/Special:SpecialPages\n",
      "/w/index.php?title=Main_Page&oldid=847600508\n",
      "/w/index.php?title=Main_Page&action=info\n",
      "https://www.wikidata.org/wiki/Special:EntityPage/Q5296\n",
      "/w/index.php?title=Special:CiteThisPage&page=Main_Page&id=847600508\n",
      "/w/index.php?title=Special:Book&bookcmd=book_creator&referer=Main+Page\n",
      "/w/index.php?title=Special:ElectronPdf&page=Main+Page&action=show-download-screen\n",
      "/w/index.php?title=Main_Page&printable=yes\n",
      "https://commons.wikimedia.org/wiki/Main_Page\n",
      "https://www.mediawiki.org/wiki/MediaWiki\n",
      "https://meta.wikimedia.org/wiki/Main_Page\n",
      "https://species.wikimedia.org/wiki/Main_Page\n",
      "https://en.wikibooks.org/wiki/Main_Page\n",
      "https://www.wikidata.org/wiki/Wikidata:Main_Page\n",
      "https://en.wikinews.org/wiki/Main_Page\n",
      "https://en.wikiquote.org/wiki/Main_Page\n",
      "https://en.wikisource.org/wiki/Main_Page\n",
      "https://en.wikiversity.org/wiki/Wikiversity:Main_Page\n",
      "https://en.wikivoyage.org/wiki/Main_Page\n",
      "https://en.wiktionary.org/wiki/Wiktionary:Main_Page\n",
      "https://ar.wikipedia.org/wiki/\n",
      "https://bg.wikipedia.org/wiki/\n",
      "https://bs.wikipedia.org/wiki/\n",
      "https://ca.wikipedia.org/wiki/\n",
      "https://cs.wikipedia.org/wiki/\n",
      "https://da.wikipedia.org/wiki/\n",
      "https://de.wikipedia.org/wiki/\n",
      "https://et.wikipedia.org/wiki/\n",
      "https://el.wikipedia.org/wiki/\n",
      "https://es.wikipedia.org/wiki/\n",
      "https://eo.wikipedia.org/wiki/\n",
      "https://eu.wikipedia.org/wiki/\n",
      "https://fa.wikipedia.org/wiki/\n",
      "https://fr.wikipedia.org/wiki/\n",
      "https://gl.wikipedia.org/wiki/\n",
      "https://ko.wikipedia.org/wiki/\n",
      "https://hr.wikipedia.org/wiki/\n",
      "https://id.wikipedia.org/wiki/\n",
      "https://it.wikipedia.org/wiki/\n",
      "https://he.wikipedia.org/wiki/\n",
      "https://ka.wikipedia.org/wiki/\n",
      "https://lv.wikipedia.org/wiki/\n",
      "https://lt.wikipedia.org/wiki/\n",
      "https://hu.wikipedia.org/wiki/\n",
      "https://ms.wikipedia.org/wiki/\n",
      "https://nl.wikipedia.org/wiki/\n",
      "https://ja.wikipedia.org/wiki/\n",
      "https://no.wikipedia.org/wiki/\n",
      "https://nn.wikipedia.org/wiki/\n",
      "https://pl.wikipedia.org/wiki/\n",
      "https://pt.wikipedia.org/wiki/\n",
      "https://ro.wikipedia.org/wiki/\n",
      "https://ru.wikipedia.org/wiki/\n",
      "https://simple.wikipedia.org/wiki/\n",
      "https://sk.wikipedia.org/wiki/\n",
      "https://sl.wikipedia.org/wiki/\n",
      "https://sr.wikipedia.org/wiki/\n",
      "https://sh.wikipedia.org/wiki/\n",
      "https://fi.wikipedia.org/wiki/\n",
      "https://sv.wikipedia.org/wiki/\n",
      "https://th.wikipedia.org/wiki/\n",
      "https://tr.wikipedia.org/wiki/\n",
      "https://uk.wikipedia.org/wiki/\n",
      "https://vi.wikipedia.org/wiki/\n",
      "https://zh.wikipedia.org/wiki/\n",
      "//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License\n",
      "//creativecommons.org/licenses/by-sa/3.0/\n",
      "//wikimediafoundation.org/wiki/Terms_of_Use\n",
      "//wikimediafoundation.org/wiki/Privacy_policy\n",
      "//www.wikimediafoundation.org/\n",
      "https://foundation.wikimedia.org/wiki/Privacy_policy\n",
      "/wiki/Wikipedia:About\n",
      "/wiki/Wikipedia:General_disclaimer\n",
      "//en.wikipedia.org/wiki/Wikipedia:Contact_us\n",
      "https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute\n",
      "https://foundation.wikimedia.org/wiki/Cookie_statement\n",
      "//en.m.wikipedia.org/w/index.php?title=Main_Page&mobileaction=toggle_view_mobile\n",
      "https://wikimediafoundation.org/\n",
      "//www.mediawiki.org/\n"
     ]
    }
   ],
   "source": [
    "cw10(\"https://en.wikipedia.org/wiki/Main_Page\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Write a Python program to check whether a page contains a title or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw11(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    requests = requests.get(url)\n",
    "    requests = requests.text\n",
    "    requests = BeautifulSoup(requests, \"html5lib\")\n",
    "    requests = requests.findAll('title')\n",
    "    if not requests:\n",
    "        print(\"no title on page\")\n",
    "    if requests:\n",
    "        print(\"title on page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title on page\n"
     ]
    }
   ],
   "source": [
    "cw11(\"https://pl.wikipedia.org/wiki/Wikipedia:Strona_g%C5%82%C3%B3wna\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Write a Python program to list all language names and number of related articles in the order they appear in wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw12(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    requests = requests.get(url)\n",
    "    requests = requests.text\n",
    "    requests = BeautifulSoup(requests, \"html5lib\")\n",
    "    numbers = requests.findAll('bdi', {'dir' : \"ltr\"})[:10]\n",
    "    output =[]\n",
    "    for i in range(1,11):\n",
    "        class_adress =  'central-featured-lang lang'+str(i)\n",
    "        text = requests.findAll('strong')\n",
    "        output.append(text)\n",
    "    output = output[:1]\n",
    "    return output ,numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[<strong class=\"jsl10n localized-slogan\" data-jsl10n=\"slogan\">The Free Encyclopedia</strong>,\n",
       "   <strong>English</strong>,\n",
       "   <strong>æ¥æ¬èª</strong>,\n",
       "   <strong>EspaÃ±ol</strong>,\n",
       "   <strong>Deutsch</strong>,\n",
       "   <strong>Ð ÑÑÑÐºÐ¸Ð¹</strong>,\n",
       "   <strong>FranÃ§ais</strong>,\n",
       "   <strong>Italiano</strong>,\n",
       "   <strong>ä¸­æ</strong>,\n",
       "   <strong>PortuguÃªs</strong>,\n",
       "   <strong>Polski</strong>,\n",
       "   <strong class=\"jsl10n\" data-jsl10n=\"app-links.title\">Wikipedia apps are now available:</strong>]],\n",
       " [<bdi dir=\"ltr\">5 696 000+</bdi>,\n",
       "  <bdi dir=\"ltr\">1 116 000+</bdi>,\n",
       "  <bdi dir=\"ltr\">1 453 000+</bdi>,\n",
       "  <bdi dir=\"ltr\">2 209 000+</bdi>,\n",
       "  <bdi dir=\"ltr\">1 489 000+</bdi>,\n",
       "  <bdi dir=\"ltr\">2 031 000+</bdi>,\n",
       "  <bdi dir=\"ltr\">1 454 000+</bdi>,\n",
       "  <bdi dir=\"ltr\">1 017 000+</bdi>,\n",
       "  <bdi dir=\"ltr\">1 002 000+</bdi>,\n",
       "  <bdi dir=\"ltr\">1 294 000+</bdi>])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw12(\"https://www.wikipedia.org/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Write a Python program to get the number of people visiting a U.S. government website right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw12(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    requests = requests.get(url)\n",
    "    return requests.json()['query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"https://analytics.usa.gov/data/live/realtime.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metrics': ['rt:activeUsers'], 'max-results': 10000}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw12(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
